<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sin-coder</title>
    <link>https://sin-coder.github.io/</link>
    <description>Recent content on sin-coder</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Feb 2020 20:44:56 +0800</lastBuildDate>
    
	<atom:link href="https://sin-coder.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>搭建自己的VPN服务器实现科学上网</title>
      <link>https://sin-coder.github.io/post/skipwall/</link>
      <pubDate>Thu, 20 Feb 2020 22:31:32 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/skipwall/</guid>
      <description>搭建自己的VPN服务器实现科学上网  最近不知道怎么了，自己原先够买的VPN服务莫名其妙的无法使用了，自己部署在github上的网站也无
 法访问了，这日子真的过不下去了，VPN不断地被墙也不是一天两天的事了。因此自己便一直想着能否搭建
自己的VPN服务，只供自己使用被墙的风险不就是大大降低了嘛！
 在写这篇博客之前，自己也想到一个笑话，在Git问世之前，Linux社区的开发人员由于私自破解由
 BitMover开发的版本控制软件，致使BitMover公司收回了Linux社区对版本控制软件的使用权。本来觉
得由Linux之父Linus之父向BitMover公司道个谦，这事就过去了，可实际上是不可能的。大神终究是大神
，Linus自己花了两周的时间就用C写了一个分布式的版本控制系统，就是Git，之后Linux的内核代码已经
开始由Git进行管理了。所以对于技术领域而言，哪里有压迫，哪里就有反抗
 好了，废话少说，进入正题
 一、前期准备  要想搭建一个专属VPN服务来实现翻墙，首先必须要有一台海外的服务器（香港的也可以），否则你服
 务的流量也出不去啊！那么问题来了，国内的云服务商对于海外的服务器卖的还都是挺贵的，恐怕经济上
难以承受。那有没有白嫖的海外服务器呢，有！请看下图
 百度的广告有时还是挺好的，让我发现了AWS还提供免费的云主机服务，但是哪有天上掉馅饼的，提供免费
 服务的前提是你要先注册吧，注册的时候竟然需要VISA或者Master的卡号（就是那种能付美元的银行卡了），这
种卡我还真的没有。然后发现某宝上有卖卡号的，自己就去买了一个（大概30元，相比于VPN的费用算是便宜了）
。注册使用银行卡号不是需要扣费，而是需要检测银行卡中是否有剩余的1$，从而验证卡号的可用性
 在这里简要说明一下，AWS为每个用户提供了每月750小时的运行实例时间，持续12个月。也就是说我们
 在一个账户上可以运行多个虚拟机的实例，总共时间不能超过750个小时，这足够我们持续使用一年的了
二、创建虚拟主机 1.切换地理区域  在具体创建实例之前，需要将区域设置为东京（推荐，网络延迟最小），当然也可以设置为其他的地区
 2.创建实例  选择EC2服务后就可以开始创建实例了，可以看到免费套餐中可选的系统类型是比较多的，Linux的各种
 版本、Windows Server等，这里我们就选用推荐的第一个吧（放在第一个肯定有它的理由）。选择第一个进
入即可
 然后是选择一个实例类型，审核并启动即可，其他的先不需要配置
  点击启动后，会有一个创建密钥对的界面，这里选择创建新的密钥对即可，再输入密钥对名称后一定注意要
 下载保存密钥对（非常重要，不然你用客户端就登不上去了），之后选择启动实例即可；
 启动完成后点击实例号即可进入虚拟机控制台界面，注意这时我们需要关注的虚拟机信息: 公有DNS，
 这个就相当于这台虚拟机的公网地址，由于IP地址经常会变动，所以可以用公有DNS来指向IP地址，实现
一个动态的绑定
 那么这时我们可以ping通这个ip地址吗？来试一下，可以发现是ping不同的
  具体原因就是我们还未对虚拟机的安全策略配置，它是拒绝被ping的。我们进入安全组，编辑入栈规则，
 添加一条放通规则保存即可
 这时我们再进行ping测试，就发现可以ping通了
 三、连接虚拟主机  这里我们使用MobaXterm客户端连接虚拟机，其他工具像Xshell、Putty客户端均可，在新建会话中，将刚才</description>
    </item>
    
    <item>
      <title>分布式一致性</title>
      <link>https://sin-coder.github.io/post/consistency/</link>
      <pubDate>Mon, 17 Feb 2020 08:04:41 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/consistency/</guid>
      <description>分布式一致性概述 一、什么是分布式一致性 1.CAP 理论  对于分布式一致性，最直观的理解就是分布式系统中的不同节点不能产生矛盾。比较著名的理论就是
 CAP Theorem，即在一个分布式系统中，不能同时满足以下三点：一致性（Consistency）、可用性
（Availability）、分区容错性（Partition Tolerance）
 一致性（C）：在分布式系统中的所有数据备份，同一时刻是否有同样的值
 可用性（A）：在集群中一部分节点故障后，集群整体能否响应客户端的读写请求
 分区容忍性（P）：大多数的分布式系统都分布在多个子网络，每个网络都叫做一个区，分区容错的意思即是
    区间通信可能失败；比如一个分布式系统有5个节点，有3个在美国，有两个在中国，这就是两个区
它们之间可能无法通信
   CAP原则的核心就是只能实现AP、CP、AC，不会存在CAP，从上图中也可以看到典型的一些数据库
 产品也只是满足了CAP的部分特性
2.一致性模型  （1）弱一致性（最终一致性）
关于弱一致性，通俗的解释就是当一个节点向数据库写入数据时，其他的节点可能无法立即读到该数据，
 但是它们最终一定会读到该数据，下面是一些典型的实例
 DNS （Domain Name System）
 Gossip（Cassandra 的通讯协议）
   （2）强一致性
对于分布式系统的容错性最关注的问题就是数据不能存储在单个的节点上，一般的解决方案就是state
 machine replication（状态机复制共识算法）,具体的实现算法有以下几种：
 同步
 Paxos
 Raft（multi-paxos）
 ZAB（multi-paxos）
  二、强一致性算法 1.主从同步  主从同步复制的工作过程如下，Master接受写请求、Master复制日志到slave、Master等待，直到
 所有从库返回；但是这样存在一个问题：一个节点失败，Master阻塞，导致整个集群不可用，保证了
一致性，但是可用性却大大降低了
 解决上述问题的方法：多数派的算法，每次写都保证写入大于N/2个节点，每次读保证从大于N/2个</description>
    </item>
    
    <item>
      <title>基于Ubuntu系统安装Docker</title>
      <link>https://sin-coder.github.io/post/%E5%9F%BA%E4%BA%8Eubuntu%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85docker/</link>
      <pubDate>Mon, 03 Feb 2020 21:50:14 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/%E5%9F%BA%E4%BA%8Eubuntu%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85docker/</guid>
      <description> Docker的安装  Docker的兼容性是比较好的，在主流的操作系统Windows、Linux和Mac上都能运行，但是也有一些不尽
 如人意的地方，比如只支持Windows 10的专业版和企业版安装，可怜我的家庭版只能默默哭泣；只能在Linux
内核版本3.10及以上且为64位操作系统才能安装。
 为了追求最佳的原生体验，我选择了使用Linux来安装Docker，但是Linux的发行版本众多，我便又有了
 选择恐惧症。平时使用CentOS比较多一些，Docker目前支持CentOS7以后的版本，但是看官方推荐说对
Ubuntu的支持更好一些，我还是脱离自己的舒适区去用Ubuntu吧
一、准备工作 二、安装过程 </description>
    </item>
    
    <item>
      <title>Docker 镜像详解</title>
      <link>https://sin-coder.github.io/post/docker-image/</link>
      <pubDate>Sun, 02 Feb 2020 22:17:53 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/docker-image/</guid>
      <description>Docker 镜像详解  镜像是Docker三大核心概念中最为重要的。Docker运行容器前需要本地存在对应的镜像，如果镜像不
 存在，Docker会从Docker Hub中下载，当然用户也可以配置自定义的镜像仓库
关键问题  使用pull命令从Docker Hub中下载镜像到本地 查看本地已有的镜像信息、管理镜像标签 使用search命令在远端仓库进行搜索和过滤 删除镜像标签和镜像文件 创建用户定制的镜像并保存为外部文件 向Docker Hub仓库中推送自己的镜像s  一、获取镜像  docker [image] pull NAME[:TAG] #直接从Docker Hub镜像源来下载镜像  其中 [] 中的内容为可选项，NAME为镜像仓库名称（用来区分镜像），TAG为镜像的标签，一般用来
 表示版本信息，描述一个镜像需要“名称+标签”；如果不显式地指定TAG，则默认会选择latest标签，会下
载仓库中的最新镜像。不过，镜像的仓库名称中还应该添加仓库地址（即注册服务器）作为前缀，默认情
况下使用官方的Docker Hub服务（前缀可以忽略的），如果从非官方的仓库下载，则必须指定完整的仓库
地址
 从下载镜像的过程中，可以看到镜像文件一般是由若干层组成的，Docker下载中会获取并输出镜像
 的各层信息，每一层都有一个简写的唯一id。当不同的镜像包括相同的层时，本地仅存储了层的一份内
容，这样可以减少存储空间
 $ docker pull ubuntu Using default tag: latest latest: Pulling from library/ubuntu 5c939e3a4d10: Pull complete c63719cdbe7a: Pull complete 19a861ea6baf: Pull complete 651c9d2d6c4f: Pull complete Digest: sha256:8d31dad0c58f552e890d68bbfb735588b6b820a46e459672d96e585871acc110 Status: Downloaded newer image for ubuntu:latest docker.</description>
    </item>
    
    <item>
      <title>容器技术的前世今生</title>
      <link>https://sin-coder.github.io/post/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E7%9A%84%E5%8F%91%E5%B1%95/</link>
      <pubDate>Sat, 01 Feb 2020 03:23:01 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E7%9A%84%E5%8F%91%E5%B1%95/</guid>
      <description>容器技术的前世今生 概述  什么是容器，在Docker官方网站中，特地地对这个名词进行了定义，容器是一个标准化的软件单元。
 进一步的解释为容器是打包代码及其所有依赖项的软件的标准单元，它将软件和其运行环境隔离开来，
因此应用程序可以从一个计算环境快速可靠地运行到另一个计算环境。
 可以说Docker是当今最知名的容器平台之一，它于2013年开源，但是容器化和隔离的技术却有很长
 的历史，了解这部分的历史将有助于我们对容器技术的理解
容器发展简史  1979年，Unix7在开发过程中引入了Chroot Jail和Chroot系统调用，它允许用户将进程及其子进程与操作   系统的其余部分隔离开来。但是这种隔离未考虑安全机制，根进程可以轻松地退出chroot
那问题便来了，chroot jail是什么，jail为监狱的意思，似乎要把什么东西锁起来。在类UNIX的操作系统
 上，默认的根目录均为“ / ”，而chroot的作用就是改变正在运行的进程及它的子进程的根目录。例如，将某
个程序的根目录从原先的默认的系统根目录更改为“ /home/ ”，则这个/home目录就变成了这个程序的逻辑
根目录，与此同时，这个被修改了根目录环境的程序就不能再进入这个逻辑根目录之外的路径了。所以这就
相当于限制某个程序能进入的目录树，称为监狱也是情有可原了
 2000年，FreeBSD Jail被引入到FreeBSD OS中，旨在为简单的Chroot文件隔离带来更多的安全性，此   外FreeBSD还实现了将进程及其活动隔离到文件系统的特定视图中（不懂，暂时略过）
  2001年，Linux VServer被推出，它使用了类似chroot的机制与“安全上下文”及操作系统虚拟化来提供虚   拟化解决方案，相比于chroot进步了许多，允许在单个Linux发行版（VPS）上运行多个Linux的发行版
VPS (Virtual Private Servers) ：虚拟专用服务器
  2004年，Oracle推出了Solaris Containers，这是一个用于X86和SPARC处理器的Linux-VServer版本   Solaris Containers是由系统资源控制和“区域”提供的边界隔离组合而成
SPARC是一套RISC（精简指令集）架构
  2005年，OpenVZ推出，它和Linux-VServer一样，使用操作系统级虚拟化，但是这样有一定的限制，容器   共享相同的体系结构和内核版本，当客户需要不同于主机的内核版本时就有点力不从心了；而且
OpenVZ未将一些用于创建隔离的控制机制的补丁集成到内核中
  2007年，Google发布了CGroups，这是一种机制，它能限制和隔离一系列进程的资源使用（如：CPU、   内存、磁盘I/O和网络等），而且被集成到了Linux内核中</description>
    </item>
    
    <item>
      <title>Learn Docker with a picture</title>
      <link>https://sin-coder.github.io/post/docker%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Sat, 01 Feb 2020 03:22:01 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/docker%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/</guid>
      <description> 一张图入门Docker  关于Docker我们在云计算、虚拟化基础概念和容器技术的前世今生两篇文章中已经介绍过其应用的场景
 和优点，在本篇文章我们将学习Docker的一些基础概念和用法，话不多说，赶紧上图
Docker三大基础概念：镜像、容器和仓库 一、镜像（Image）  镜像就类似于我们使用Virtual Box或者VMware创建虚拟机之前需要下载的系统镜像文件，比如iso文件、
 img文件之类的都称为镜像文件。我们可以将Docker镜像理解为一个面向Docker引擎的只读模板，它自身即
包含了文件系统
 镜像与容器的关系就类似于印钞模板与钞票之间的关系，当然我们可以通过Dockerfile来制作自己的镜像。
 制作好的镜像可以被封装在一个盒子中（保存为tar文件），当需要在另一个环境中使用镜像时，只需将盒子
搬过去，重新取出（Load）镜像即可。当然这些比喻并不十分严格，只是帮助理解而已。
 通过版本管理和增量的文件系统，Docker提供了一套十分简单的机制来创建和更新现有的镜像。用户在
 对容器进行修改并提交（commit）后，重新运行依然可以保持这个变化
 有关Docker镜像的操作详解，请参看Docker入门学习--镜像
 二、容器（Container）  容器是从镜像创建的运行实例，可以将其启动（run）、开始、停止和删除，而且这些容器都是相互隔离
 的，互相不可见的。用户可以将容器看做一个简易版的Linux系统环境（包括root用户权限、进程空间、用户
空间和网络空间），以及运行在其中的应用程序打包而成的应用盒子
 镜像本身是可读的，容器从镜像启动的时候，Docker会在镜像的最上层创建一个可写层，镜像本身并没
 有发生改变
 有关Docker镜像的操作详解，请参看Docker入门学习--容器
 三、仓库（Repository）  Docker仓库类似于代码的仓库，是Docker集中存放镜像文件的场所。Docker利用仓库来管理镜像，这
 种设计理念与Git十分相似。用户可以直接从仓库中拉取（pull）镜像来供自己使用，也可以将自行制作镜像
并上传（pull）到仓库中，等到在另外一台机器上使用该镜像时，再pull下来即可
 Docker仓库和注册服务器（Registry）不是同一个概念，注册服务器是存放仓库的地方，其上往往存
 放着多个仓库。每个仓库集中存放某一类的镜像，这些镜像通过Tag进行区分。
 根据所存储镜像的公开与否，Docker仓库可以分为公开仓库和私有仓库。Docker Hub是目前最大的公
 开仓库；当然Docker也支持用户在本地的网络内创建 一个只能自己访问的仓库
 有关Docker镜像的操作详解，请参看Docker入门学习--仓库
当然Docker的内容远不止这些，接下来会 一 一 介绍
 </description>
    </item>
    
    <item>
      <title>云计算和虚拟化基础概念简介</title>
      <link>https://sin-coder.github.io/post/%E4%BA%91%E8%AE%A1%E7%AE%97%E5%92%8C%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/</link>
      <pubDate>Fri, 31 Jan 2020 19:21:17 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/%E4%BA%91%E8%AE%A1%E7%AE%97%E5%92%8C%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/</guid>
      <description>云计算和虚拟化基础概念 一、虚拟化  虚拟化技术是一种资源管理优化技术，它是将计算机的各种物理资源（CPU、内存、磁盘、网卡）
 等I/O设备予以抽象、转换，然后呈现出来一个可供分割并任意组合为一个或多个（虚拟）计算机的配置
环境。虚拟化技术打破了计算机内部实体结构间不可切割的障碍，使得用户以比原来更好的方式来应用
这些计算机的硬件资源。
 虚拟化是一个广义的术语，具体可细分为以下三种：
  平台虚拟化（Platform Virtualization）：操作系统级别的虚拟化
 资源虚拟化（Resouce Virtualization）：特定系统资源的虚拟化，如CPU、内存、存储或者网络等
 应用程序虚拟化（Applocation Virtualization) ：仿真、模拟和解释技术等，如Java虚拟机
  二、虚拟机  虚拟机是一台计算机转换为多台计算机的基于物理硬件的抽象。虚拟机管理程序允许多个虚拟机
 在单台计算机上运行，它可以创建虚拟化硬件，其中包括虚拟磁盘、虚拟网络接口、虚拟CPU等，同
时它还具有可以与此虚拟硬件通信的内核。每个虚拟机都包含着操作系统、应用程序，这些文件可能
占用数十GB的存储空间。管理程序可以进行托管，这就意味着它是可以在主机操作系统上运行的软件、
还可以运行在裸机上，即直接在机器硬件上运行，替换真实的操作系统。
 虚拟机可以分为系统虚拟机或者是过程虚拟机，我们通常所说的是系统虚拟机，它是通过主机硬件
 来模拟整个操作系统的；而“进程虚拟机”是用于模拟执行单个进程的编程环境的，Java虚拟机便是这样
三、容器 1.问题背景  在过去的几年中，让运维人员最为头疼就是需要为各种迥异的开发语言安装相应的运行环境。
 但是Docker的横空出现解决了这一问题，Docker提供了让开发工程师可以将应用和依赖封装到一
个可移植的容器中的能力，这种集装箱式的封装方式，让运维人员和开发人员都能够以Docker所
提供的镜像分发的标准化方式发布应用，打破了异构语言在团队中形成的壁垒
2.容器简介  容器是包含应用程序代码、配置和依赖关系的软件包；它是通过在操作系统级别进行虚拟
 化来使应用程序可移植，从而创建基于内核的隔离的封装系统。容器化运行的应用程序可以放在
任何地方，消除了依赖关系
 当然，作为独立的单元，容器能够在任何操作系统，如Linux、Mac、甚至像Windows这样
 的非UNIX系统中运行。容器还可充当标准化的工作或者计算单元，比如每个容器运行单个Web
服务器、数据库的分片或者单个Spark工作程序，只需要扩展容器的数量就能够便捷地扩展应用
 每个容器都有一个固定的资源配置（CPU、内存、线程数），并且扩展应用程序只需要扩展
 容器的数量即可。容器也是实现微服务架构的一个很好的工具，每个微服务只是一组协作容器
3.容器和虚拟机的区别  容器和虚拟机具有相似的资源隔离和分配优势，但具体功能不同，因为容器虚拟化了操作系统，
 而不是硬件；容器的创建和停止十分迅速，而且对自身资源的需求十分有限，远远低于虚拟机，很
很多时候直接把容器当做应用本身也是没有任何问题的。传统意义上如果说在一台主机上运行一百
个虚拟机那肯定是天方夜谭，可是一台主机运行上千个容器却已经成为了现实
 二者关键性能的区别如下表格：
  容器和虚拟机架构的区别：</description>
    </item>
    
    <item>
      <title>消息队列简介</title>
      <link>https://sin-coder.github.io/post/messagequ/</link>
      <pubDate>Tue, 28 Jan 2020 01:22:22 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/messagequ/</guid>
      <description>消息队列简介 一、消息队列简介 1.概述  消息是指在应用间传送数据，消息可以只包含文本字符串、或者包含嵌入式对象。
消息队列是一种应用程序对应用程序的通信方法。它是是生产者-消费者模型的一个典型的代表，一端往消息
 队列中不断地写入消息，而另一端则可以读取队列中的消息。这样发布者和接受者都不知道对方的存在。
 消息队列也可以简单理解为：把要传输的数据放在队列中
 2.消息获取模式  消费者获取消息时有两种模式，点对点模式和发布订阅模式
 （1）点对点模式  点对点模型通常是一个基于拉取或者轮询的消息传递模型，这种模型从队列中请求消息，而不是将消息推送
 到客户端。这种模式的特点是一对一，发送到队列的消息被一个且只有一个接受者接收处理，即使有多
个消息监听者也是如此，消息被收到后即可清除
 点对点模式的优点是队列发送数据和客户端接收数据的速度是相匹配的，缺点是客户端需要实时监控队列中
 是否有消息存在
（2）发布/订阅模式  发布订阅模型是一个基于推送的消息传送模型，该种模型下订阅者有临时订阅者和持久订阅者之分，临时订
 阅者只在主动监听主题时才接收消息；而持久订阅者则监听主题的所有消息，即使当前订阅者不可用，
处于离线状态。这种模型的特点是一对多，数据生产后，推送给所有的订阅者
 发布/订阅模式的优点是客户端不需要实时监控队列中是否有消息存在，缺点是队列发送数据的速度无法和多
 个客户端接收数据的速度是相匹配
二、消息队列作用  解耦：客户端与客户端之间或者客户端和服务器 之间不需要直接连接，而是通过中间件来进行连接。而且允许你    独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束
  冗余：消息队列可以对数据进行持久化（本地备份）直到它们已经被处理，这样就规避了数据的丢失。许多消息   队列均采用“插入-获取-删除”的范式，即在把一个消息从队列中删除之前，需要你的系统明确的指出该消息已
经被处理完毕
  峰值处理：可以组建集群，进而增大消息入队和处理的频率。在访问量剧增的情况下，应用仍然需要继续发挥作   用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的
浪费。消息队列基于它的可扩展性使其本身可以顶住突发的访问压力，而不会因为突发的超负荷的请求而使
系统完全崩溃
  数据可恢复：当系统的一部分组件失效时，不会影响到整个的系统 。消息队列降低了进程间的耦合度，即使一个   处理消息的进程挂掉，加入队列中的消息仍可在系统恢复后被处理
  顺序保证：消息队列本来就是排好序的，并且也能够保证数据按照特定的顺序来进行处理
 缓冲：消息队列可以控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况</description>
    </item>
    
    <item>
      <title>Git&amp;Github 学习笔记</title>
      <link>https://sin-coder.github.io/post/git/</link>
      <pubDate>Mon, 27 Jan 2020 00:52:28 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/git/</guid>
      <description>一、版本控制 1.版本控制工具的功能  协同修改：多人互不影响地修改服务器端的同一个文件
 数据备份：不仅要保存文件的当前状态，还能够保存每一个提交过的历史状态
 版本管理：在保存每一个版本的文件信息时，能够做到不保存重复的数据，节省存储空间，提高运行效率;
     SVN采取的是增量式管理的方式，Git采取了文件系统快照的方式
    权限控制：对团队中参与开发的人员进行权限控制，Git还可以对团队外开发者贡献的代码进行审核
 历史记录：查看修改人、修改时间、修改内容、日志信息；将本地文件恢复至某一个历史状态
 分支管理：允许开发团队在工作过程中多条生产线同时推进任务，提高效率
  2.常见版本控制工具  （1）集中式版本控制工具：CVS、SVN、VSS等
 集中式的版本控制中每个开发者是一个客户端，文件和版本信息存储在服务端，开发者们都直接与
 服务器进行交互，集中式的版本控制具有单点故障的问题
（2）分布式版本控制工具：Git、Mercurial、Bazaar等
 分布式版本控制相比于集中式最大的优点就是能够避免单点故障的问题
  二、Git 简介 1.Git的发展历史  Git是一个免费、开源的分布式版本控制工具。在2005年，由Linus基于C语言开发完成，开发的初衷是
 管理Linux社区中提交的代码, 而这位Linus正是是开发Linux系统内核的大神，它的个人语录也是我的座右铭
&amp;quot;Talk is cheap, Show me the Code&amp;quot;，少废话我只看代码。
2.Git的特性简介  从Git的图标中就可以看到分支是其最引以为傲的特点，实际上Git的优点还有很多
  大部分操作在本地完成版本控制，不需要联网
 对数据进行完整性保证，基于Hash算法
 尽可能添加数据而不是删除或者修改数据
 与Linux命令全面兼容，这个当然了，都是由Linus开发的
    3.Git 的结构  Git的本地结构图</description>
    </item>
    
    <item>
      <title>分布式系统学习笔记</title>
      <link>https://sin-coder.github.io/post/distri/</link>
      <pubDate>Mon, 27 Jan 2020 00:44:13 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/distri/</guid>
      <description>一、分布式系统概述 1.什么是分布式系统？ ​ 分布式系统主要由网络、分布式存储与分布式计算等部分构成的，分布式存储侧重于数据的读写存取及一致性等方面，而分布式计算则侧重于资源、任务的编排和调度
2.分布式系统的特点 ​ 没有强制性的中心控制、次级单位具有自治的特质、次级单位之间彼此高度链接、点对点之间的影响通过网络形成了非线性的因果关系
3.传统架构面临的难题: 系统的扩展 ​ 高并发的访问要求我们的后端系统架构弹性且可扩展
​ 三维扩展：
​ X轴扩展：水平复制，即在负载均衡服务器后增加多个Web服务器，
​ Y轴扩展：对数据库的扩展，即进行分库分表，分库是将关系紧密的表放在一台数据库服务器上，分表是因为一张表的数据太多，需要将一张表的数据通过hash放在不同的数据库服务器上
​ Z轴扩展：业务方向的扩展，才能将巨型应用分解为一组不同的服务，将应用进一步分解为微服务
​ 4.CAP定理
​ 在分布式系统中，系统的一致性(Consistency)、可用性（Availability）、分区容忍性(Partion tolerance)。这三者不能同时保证，由于网络通信的不确定性，分区的容忍性是必须要保证的，而且互联网应用比企业级应用更加偏向于保持可用性，通常用最终一致性代替传统事务的ACID强一致性
​
二、分布式计算 1.概述 ​ 分布式计算核心的思路就是系统架构无单点，让整个系统可以扩展。分布式计算环境下的节点分为有状态存储节点和无状态存储节点。
​ 无状态存储节点，不存储数据，请求分发可以采取很简单的随机算法或者是轮询的算法就可以了，如果需要增加机器，则只需要把对应的运算代码部署到一些机器上然后启动起来，引导流量到那些机器即可实现动态的扩展了。简单来说就是某台机器承担了某种角色后，能够快速的广播给需要这个角色提供服务的机器。
​ 而针对有状态节点，扩容难度较大，因为每台Server中均有数据，所以请求分发的算法不能够随机或者轮询，一般来说常见算法就是哈希或者使用Tree来做一层映射，增加机器时需要经历一个复杂的数据迁移过程------》自动化扩容和迁移的工具
2.数据处理的发展过程
GFS-------------》HDFS
BigTable--------》HBase
​ MapReduce----》MapReduce
​ （Hadoop技术栈）
MapReduce(离线处理)-----》Spark(高性能批处理技术)------》Storm(流处理)----》Flink
3.批处理（Batch Processing）与流处理（Stream Processing） 主要区别：每一条数据在到达时是被处理的（流处理），还是作为一组新数据的一部分稍后进行处理（批处理）
批处理：在批处理中新到达的数据元素被收集到一个组中，整个组在未来的时间内进行处理。至于何时处理每个组可以选择多种方式来确定，可以基于预定的时间间隔（如每隔5分钟）、或者在某些触发的条件下（只要包含5个元素/拥有超过1MB的数据）。传统的数据仓库和Hadoop就是专注于批处理的。批处理示意图如下：
缺点：具有延迟性、新数据的到达与该数据的处理之间的延迟将取决于直到下一批处理窗口的时间
流处理：流处理设计的目的是为了在数据到达时对其进行响应，这就要求它们实现一个由事件驱动的体系架构，也可以说是在系统的内部工作流在接收到数据后立即连续监视新数据和调度处理。
应用：Flink、Beam等都支持“流式处理优先，将批处理视为流式处理的特殊情况”，但是流式处理器的出现并没有让批处
​ 理器变得过时。因为纯流式处理系统在批处理工作负载时其实是非常慢的。
​ Apache Beam: 这样统一的API通常会根据数据是持续的（无界）、还是固定的（有界）将工作负载委托给不同的
​ 运行机制
​ Flink: 提供的流式API，可以处理有界或者无界的场景，同时任然提供了单独的DataSet API用于批处理
​
三、分布式调度 1.概述
经典资源调度器（Yarn）-----》数据调度（Data Placement）、资源任务调度（Resource Management）、计算调度（Application Manager）、本地微（自治）调度
2.资源调度</description>
    </item>
    
    <item>
      <title>同步/异步、阻塞/非阻塞辨析</title>
      <link>https://sin-coder.github.io/post/syn/</link>
      <pubDate>Sun, 26 Jan 2020 21:35:45 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/syn/</guid>
      <description>关键词：同步、异步、阻塞、非阻塞 相关概念：网络编程、进程与线程、I/O模型 一、问题背景  同步和异步，以及阻塞和非阻塞都是网络编程中经常遇到的概念，单看文字上的解释确实有些晦涩
 难懂。接下来我们将从一个通俗的例子出发阐述它们的区别与联系
二、一个简单的例子  隔壁老王爱好茶艺，每天都会煮开水来泡茶
 场景一：老王将水壶放在火上，坐在旁边等待水开 （同步阻塞）
 但是这样很耽搁时间，又不自由，效率很低，老王想换种方法
 场景二：老王将水壶放在火上，自已去隔壁了，每隔3分钟来看下水开没有 （同步非阻塞）
 但是这样依旧很麻烦，老王就买了一个自动报警的水壶
 场景三： 老王用新买的水壶进行烧水，坐在旁边等待水开 （异步阻塞）
 老王便想没有必要在水壶旁边坐着啊
 场景四： 老王新买的水壶放在火上，自己去隔壁了，等着报警再回来 （异步非阻塞）
 这种方式是最让老王省心的
 小结： 同步和异步关注的焦点在于我们是否需要不断地去看水壶是否开了，同步时，需要老王不断
地去轮询水壶是否开了，效率是比较低下的。而异步时，水壶告警提醒老王它开了
 阻塞和非阻塞 关注的焦点在于老王是否需要坐在水壶旁边等待，在水壶旁边等待老王就是阻
 塞的，去做其他事的老王就是非阻塞的
 这个例子可以帮助我们初步地理解同步异步、阻塞和非阻塞之间的联系和区别，但是如果详细
 的“追究”起来，还有许多未解释的细节
三、理论阐述 1.同步与异步  同步和异步（syn &amp;amp; asyn），描述的是在单线程中一次方法调用后，执行者是否具备主动通知
 的功能。同步时调用者会等到方法调用返回后才能继续后面的行为，异步时调用者不需要等到方法返回，
方法执行完毕后会主动通知调用者
2.阻塞和非阻塞  阻塞和非阻塞关注是调用者是否可以执行多个任务，描述的是调用者的多个线程是否可以同时执
 行。阻塞时，多个线程不能同时进行；非阻塞时，多个线程可以同时进行
3.二者的区别与联系  同步和阻塞完全是在单线程和多线程这两个维度上的概念，它们之间并没有强制的联系。但是从
 实际的意义来看确实有一定的绑定关系，比如对于单线程来说，不管是同步还是异步，肯定是阻塞的，非
阻塞只有多线程而且异步的时候才能发挥作用。
 回来继续看烧水的例子，老王在烧水的同时去隔壁，也即在烧水这个线程之中，又开启了去隔壁
 这个线程，所以使用异步非阻塞才更加有意义</description>
    </item>
    
    <item>
      <title>虚拟机的网络连接方式</title>
      <link>https://sin-coder.github.io/post/virtualnetwork/</link>
      <pubDate>Fri, 31 Jan 2020 12:00:31 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/virtualnetwork/</guid>
      <description> 虚拟机和主机的网络连接方式  最近在使用VirtualBox安装虚拟机组建集群时，总是会遇到各种网络问题，具体包括虚拟机
 之间的访问、虚拟机和主机之间的访问、虚拟机访问外网等，搞得晕头转向的，所以在此总结
一下虚拟机和主机之间的网络连接方式，以便更进一步的画出集群的网络拓扑图
 在VirtualBox的配置界面，可以看到虚拟机和主机间的网络连接方式有以下几种：网络地址
 转换（NAT）、NAT网络、桥接网卡、内部网络、仅主机（Host-only）网络、通用驱动等，下
面便一一详解
1. NAT模式  NAT方式借助网络地址转换的功能，通过宿主机所在的网络来访问互联网。此种方式下，虚拟
 机的网卡和物理网卡的网络不是在同一个网络中。虚拟机的网卡只是VirtualBox所提供的一个
虚拟网络，并不真实存在于网络中，所以宿主机无法ping通虚拟机，虚拟机彼此间也不通，但
是通过NAT虚拟机可以访问主机、和主机同网络的其他主机和互联网
 不过这里的网络连接方式中有网络地址转换（NAT）和NAT网络，这二者之间又有什么区别呢？
 其实这二者本质是相同的，不过后者是提前创建好的网络，在主界面的管理---&amp;gt;全局设定--&amp;gt;网络
我们可以提前设置一个NAT网络供虚拟机来选用
 总结起来，NAT模式可以节省网段中的IP地址，适合仅需自己使用的虚拟机配置
 2.桥接模式  桥接方式下，虚拟机需要桥接到宿主机的一块网卡上（有线或者无线均可），虚拟机和宿主机
 处于同一网段，真实存在于网络中。虚拟机之间可以互通、虚拟机和网络中的主机也可以互通、
只要主机能上网，虚拟机也可上网，但是这样占用网络中的IP地址
3.host-only模式  host-only模式应该是最为复杂的网络连接模式了，其他几种网络的连接方式通过这种模式的合
 适配置均可实现。我们可以理解为VirtualBox在主机中模拟出一张专供虚拟机使用的网卡，所
有的虚拟机都是连接到网卡上的，我们可以通过设置这张网卡来实现上网和其他功能。
 虚拟机和主机关系，默认不能相互访问，因为不属于同一个IP地址段。但是通过网卡共享、网卡
 桥接等，可以实现虚拟机和主机的相互访问
 虚拟机和虚拟机的关系，默认同一个网段中的虚拟机是可以相互访问的
 4.内部网络  内部网络模式，虚拟机与外网完全断开，虚拟机和主机之间无法相互访问只用于虚拟机
 与虚拟机之间的访问，但前提是在虚拟机在同一网络中，实际配置时两台虚拟机设置为
同一网络名称即可，如下图的配置中使用intnet
5.通用驱动  运行用于选择网卡驱动，实际上很少用到，可忽略
 6.未指定  相当于虚拟机有网卡，但是没有插线，只能ping自己才会通的
 </description>
    </item>
    
    <item>
      <title>基于Hugo框架搭建个人博客</title>
      <link>https://sin-coder.github.io/post/hugo/</link>
      <pubDate>Tue, 07 Jan 2020 14:08:20 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/hugo/</guid>
      <description>关键词：Hugo 、Git、Github、域名解析 概述 1.Hugo简介  Hugo是基于Go语言开发的静态网站生成器，简单、易用、快速部署，主要用于构建个人博客
 2.Git简介  Git是目前主流的分布式版本控制工具，有关Git的使用请查看Git的来龙去脉这篇文章
 3.Github简介  Github是在外网环境下的一个代码托管库，有关Github的介绍请查看开始玩起Github这篇文章
 具体过程 1.准备工作  下载Git并安装、配置环境变量   完成后在终端执行&amp;quot;git&amp;quot;命令来测试是否安装成功，有关git的安装请看Git的来龙去脉
  下载Hugo并安装、配置环境变量   完成后在终端执行&amp;quot;hugo version&amp;quot;命令来测试是否安装成功，终端提示如下信息表示安装成功
 C:\Users\Administrator&amp;gt;hugo version Hugo Static Site Generator v0.59.1-D5DAB232 windows/amd64 BuildDate: 2019-10-31T15:22:43Z   Hugo最好安装在英文目录下
下载时可能由于网络问题失败，附上Hugo、Git、主题m10c的下载包链接: 下载链接
  注册Github官网（已有账号请忽略）  2.生成个人站点 （1）在终端执行命令 C:\Users\Administrator&amp;gt;hugo new site E:\hugo\Sites\myblog   出现以下提示信息表示创建成功：
 C:\Users\Administrator&amp;gt;hugo new site E:\hugo\Sites\myblog Congratulations! Your new Hugo site is created in E:\hugo\Sites\myblog.</description>
    </item>
    
    <item>
      <title>Pycollect</title>
      <link>https://sin-coder.github.io/program/pycollect/</link>
      <pubDate>Tue, 25 Feb 2020 20:44:56 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/program/pycollect/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Git向Github push时，连接超时</title>
      <link>https://sin-coder.github.io/post/git%E8%BF%9E%E6%8E%A5github%E5%A4%B1%E8%B4%A5/</link>
      <pubDate>Tue, 28 Jan 2020 17:10:44 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/git%E8%BF%9E%E6%8E%A5github%E5%A4%B1%E8%B4%A5/</guid>
      <description>Failed to connect to github.com port 443: Timed out 问题背景  最近在使用Git向Github提交时总是会出现以下报错：
 E:\hugo\Sites\blog\public&amp;gt;git push -u origin master fatal: unable to access &#39;https://github.com/sin-coder/sin-coder.github.io.git/&#39;: Failed to connect to github.com port 443: Timed out   而且还是偶尔出现的，特别让人心烦，目测为网络问题，折腾了许久在StackOverflow找到了答案
 问题原因  为了访问Github更加流畅，本地使用了Shadowsocks进行代理，可是Git并没有走代理访问
只需将Git配置为代理访问Github即可
 解决措施  打开Windows下的cmd命令行，在命令行中直接输入以下命令（已经配置Git的环境变量），或者
切换到Git的安装目录下执行命令（未配置环境变量）即可解决该问题
 E:\Program Files\Git\Git 的目录 2019/11/27 13:19 &amp;lt;DIR&amp;gt; . 2019/11/27 13:19 &amp;lt;DIR&amp;gt; .. 2019/11/27 13:18 &amp;lt;DIR&amp;gt; bin 2019/11/27 13:19 &amp;lt;DIR&amp;gt; cmd 2019/11/27 13:19 &amp;lt;DIR&amp;gt; dev 2019/11/27 13:19 &amp;lt;DIR&amp;gt; etc 2019/02/26 19:48 149,784 git-bash.</description>
    </item>
    
    <item>
      <title>Mapreduce</title>
      <link>https://sin-coder.github.io/post/mapreduce/</link>
      <pubDate>Mon, 27 Jan 2020 00:54:15 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/mapreduce/</guid>
      <description>1.什么是Map? 什么是Reduce?
Map是拆解 Reduce是组装 本治就是分治法
Input --&amp;gt; Split--&amp;gt;Map---&amp;gt;Shuffle（组装）---&amp;gt;Reduce ----&amp;gt;Finalize（高度并行的）
实现代码：
MapReduce如何实现统计单词出现的次数的
Map（string key, string value） #key : the id of a line #value: the content of the line for each word in value: OutputTemp(word,1) # Reduce 的过程 Reduce(string key,list valueList) #key : the name of a word #valueList: the appearance of this world int sum = 0 for value in valueList: sum+=value OutputFinal(key,sum)  MapReduce 如何实现倒排索引的？
MapReduce的整体结构？
总结：Map就是一个disassemble Reduce 就是一个assemble</description>
    </item>
    
    <item>
      <title>Bigtable</title>
      <link>https://sin-coder.github.io/post/bigtable/</link>
      <pubDate>Mon, 27 Jan 2020 00:53:53 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/bigtable/</guid>
      <description>1.如何在文件内进行快速查询？
关键点： 从File 到 Table Table = a list of sorted 
2.如何保存一个很大的表？
关键点： A table = a list of tables (小表)
A tablet = a list of sorted 
使用MetaData的形式保存每一个小表的位置
3.如何保存一个超大的表？
关键点：A table = a list of tablets （小表）
​ A tablet = a list of SSTables （小小表）
​ A SSTables = a list of sorted 
4.如何向表中写数据？
关键点：通过写入memTable（内存表）来加速
A tablet = memTable + a list of SSTables
5.内存表过大怎么办？如何避免内存丢失数据？</description>
    </item>
    
    <item>
      <title>Google File System</title>
      <link>https://sin-coder.github.io/post/gfs/</link>
      <pubDate>Mon, 27 Jan 2020 00:53:42 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/gfs/</guid>
      <description>Google File System 一、概述 Google的三篇论文：Google File System 、BigTable 、MapReduce的发表彻底拉开了云计算时代的序幕，同时这三篇论文也是想要入门云计算的学习人员必读的。最近读了这三篇论文，再参考了一些资料后写下自己的总结
HDFS 、HBase 、MapReduce
 GFS BigTable MapReducd  Google系统整体的架构图如下
GFS系统的优点：高可用性、自动负载均衡
系统的结构：文件系统（GFS）、数据模型（Bigtable）、算法（MapReduce）、应用
在本篇文章中我们着重去描述GFS
二、GFS系统的设计 1.设计思路
​ （1）组件失效是一种常态，而不是意外；因此持续的监控、错误的侦测、灾难冗余等机制必须集成在GFS
​ （2）存储的文件非常巨大，基本上为TB级的，I/O操作和Block、Chunk的尺寸都需要规划
​ （3）对文件的修改以在文件尾部追加数据为主，数据的追加对系统性能有重要的影响
​ （4）应用程序和文件系统的API协同设计可以大幅度提高系统的灵活性
2.系统的工作负载分析
3.GFS系统架构
三、系统工作原理 设计原则：最小化所有的操作和Master节点的交互
系统具体的工作过程：
3.文件系统的操作
4.Master节点的操作
名称空间管理和锁
副本的位置
创建、重新复制、重新负载均衡、垃圾回收、过期失效的副本检测
5.容错和诊断
高可用性、数据完整性、诊断工具
四、总结 3.Linux文件系统工作原理：
​ 保存一个小文件
​ 保存的每一个文件都有一个元数据Metadata，其中包括filename文件信息 文件名 创建时间 文件大小 index组成文件的每一个Block的索引 关键点为1block = 1024 Byte
​ 保存一个大文件：
​ 关键点为chunk : 1chunk = 64MB =64*1024 =65536 blocks
​ 优点：减少元数据 减少流量 缺点：小文件会浪费较多空间</description>
    </item>
    
    <item>
      <title>Go语言学习总结（一）</title>
      <link>https://sin-coder.github.io/post/go/</link>
      <pubDate>Mon, 27 Jan 2020 00:53:21 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/go/</guid>
      <description>Go语言学习总结（一） 一、Go语言简介 1. Go语言用途 ​ 搭载Web服务器，存储集群或类似用途的巨型中央服务器的系统编程语言
​ 在高性能的分布式系统领域，Go语言比其他语言有着更高的开发效率
2. Go语言特点 ​ 自动垃圾回收、丰富的内置类型、函数多返回值、错误处理、数组安全
​ 匿名函数和闭包、类型和接口、并发编程、反射、语言交互性等
3. 设计思想 ​ 目前主流的编程思想主要有面向对象编程、面向过程编程，但是Go语言在设计的过程中吸收了一些
​ 小众的编程哲学思想，比如函数式编程思想（支持匿名函数与闭包）， 面向消息编程思想（支持 goroutine
​ 和通道），因此Go推荐使用消息而不是共享内存来进行并发编程
二、Go语言基础语法 1. 程序组成元素 （1）包声明 ​ 源文件中非注释的第一行指明这个文件属于哪个包，如package main, package main表示一个可独立执行的
​ 程序，Go程序是通过package来进行组织的，只有package名称为main的源码文件可以包含main函数
（2）引入包 ​ 导入程序所要使用的包 fmt包格式化的输入输出
​ 导入包时可以通过import关键字来单个导入，也可以同时导入多个，如：
//单个导入 import &amp;quot;fmt&amp;quot; import &amp;quot;io&amp;quot; //同时导入多个 import ( &amp;quot;fmt&amp;quot; &amp;quot;math&amp;quot; )  ​ 文件名与包名没有直接关系、同一个文件夹下只能有一个包名，否则编译报错
​ 导入包时一般为 import &amp;quot;项目名/包名&amp;quot;
​ 调用函数时则是通过PackageName.FunctionName() 来进行调用
（3）函数 ​ fun main()是程序开始执行的函数，该函数也是每一个可执行程序所必须的，每个函数后都会有{}，但是 &amp;quot; { &amp;quot;</description>
    </item>
    
    <item>
      <title>数据结构学习心得</title>
      <link>https://sin-coder.github.io/datastructure/summay/</link>
      <pubDate>Sat, 21 Dec 2019 14:01:10 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/datastructure/summay/</guid>
      <description>数据结构学习心得  学习数据结构和算法也有段时间了， 在此记录自己学习的过程，以及心得和体会
我不是计算机专业的，没有学过对应的课程，但我知道数据结构与算法是一个编程人员的核心能力。很
 长时间以来，我都因为自己不会这个而怀疑自己到底会不会编程。当然，从过往的经历来看，好像开发一个
实际的APP或者Web应用也没有用到很多相关的知识，我就一直在逃避学习，直到一次头条的面试彻底让我
清醒了过来
一、迷雾重重，被现实吊打  相比于数据结构来说，其他计算机的核心课程显然我要更熟悉一些，而且我也不觉得精通数据结构的人
 学习其他知识不吃力。但是从实际的面试中，遇到数据结构我就基本是卡住了，以至于有些时候似乎觉得
面试就无法聊下去了
 终于逃离了自己的舒适圈，开启一条煎熬之路，但我也很明确自己的目的，提高自己的逻辑思维和在面
 试中不会因为它被卡主，至于那些搞竞赛的同学我就只能投去羡慕的眼神了
 一开始，我找到了几个计算机的同学，问了一些课程的用书和一些推荐的学习资源。于是就从严蔚敏奶
 奶的那本紫皮书开始了，可以说看的一脸懵逼，找到了学习高数的那种感觉。而且书里面给出的都是一些伪
算法，没有具体的实现，感觉非常的苦恼。后来，又多方打听找到了高一凡大神写的数据结构算法实现，还
有点C/C++基础的我比着人家的思路开始把一些常用的数据结构实现了一遍，当然在这个过程中，自己也在
看B站上郝斌老师的视频课程，这一段时间总算把数组和链表给搞懂了，也认识了一些像队列、栈等一些更
级的数据结构
二、初现水面，站在数组和链表上眺望远方  其实这个时候，我还只是在学习数据结构，没有一点用它们解决实际问题的意识，似乎只是一些需要记住
 的知识点。但是从自己不断遇到的问题来看，如果只用数组和链表去存取数据的话，问题的解决方案会很麻烦
，但是也是可以解决的，所以应该得出第一个结论：
   数组和链表是数据结构中最底层的抽象
  为什么呢？数组和链表对于数据存储的结构逻辑和实际的物理逻辑是相关联的，那么后来学习到的队列、
 栈、哈希表、堆、树、图都跑哪去了呢？它们都可看做是数组或者链表的上层建筑，换用计算机语言来描述
就是对数组和链表进行封装。如果你需要的话，也可以自行封装，这就是我们常说的数据结构的设计。多样
化的数据结构本质上没什么差别，都是对数组和链表的不同操作而已
 很多高级的数据结构都可以用数组或链表来实现，但是具体用哪一种，就要从性能上考虑了，所以这个
 时候我又学习到了两个新的名词，时间复杂度和空间复杂度，从后来学习的情况来看，它们占据了数据结构
与算法的半壁江山。那就从数组和链表的特点来引入这复杂度的两个概念。
 数组在物理空间上是紧凑连续存储的，可以随机访问，通过索引很快的找到对应元素，而且数组中数据
 在物理空间中的密度是比较高的。但是正是因为是连续存储的，物理上的空间必须一次给够；如果不够的
话就要考虑扩容的问题，扩容时需要将原来的数据搬家到一个新的空间，从整体来说这样是比较复杂的。
此外，如果你想要在数组中进行插入或者删除，会惊动后面的许多元素，这样也是比较费劲的
 再来看看链表，似乎链表和数组是优劣互补的，比如数组元素连续，链表元素不连续，靠指针来保持自
 己前后同伴的关系；数组集中存储，链表则是分散存储，见缝插针，不会存在整体扩容的问题；当改动一个
元素时只会影响前后元素，不会像数组那样大动干戈。但是相比于数组的随机访问，链表则就显得吃力了许
多，它必须一个一个地找，同时由于多存储了地址，它占用的空间会更大
 所以复杂度最直观的理解就是对于数据结构的操作是否麻烦
 三、拨开乌云晴天日   应该用数组还是链表取决于数据结构具体的应用场景
 下面举一些典型的使用数组或者链表实现的数据结构</description>
    </item>
    
    <item>
      <title>技术博客分类目录</title>
      <link>https://sin-coder.github.io/category/content/</link>
      <pubDate>Fri, 20 Dec 2019 21:48:36 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/category/content/</guid>
      <description> 计算机网络  应用层协议、二层交换、三层路由、TCP/UDP，网络编程，运维  操作系统 数据结构与算法  leetcode、剑指offer；贪心、回溯、动态规划、分治、递归；树，图，堆、队列、栈、链表、数组；  数据库技术  MySQL、Redis、MongoDB  编程语言  Python、Java、Go  Linux  Shell、运维  云计算  Docker、K8s、云原生  分布式  6.824、分布式数据库、分布式消息队列、分布式计算  个人随笔  技术之路、个人经历、生活体会  </description>
    </item>
    
    <item>
      <title>技术成长之路</title>
      <link>https://sin-coder.github.io/personal/introduce/</link>
      <pubDate>Wed, 18 Dec 2019 21:47:34 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/personal/introduce/</guid>
      <description> 一个半路出家的怪孩子是如何折腾计算机的
 </description>
    </item>
    
    <item>
      <title>使用堆解决常见TOPK问题</title>
      <link>https://sin-coder.github.io/leetcode/topkheap/</link>
      <pubDate>Wed, 11 Dec 2019 14:01:10 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/leetcode/topkheap/</guid>
      <description>使用堆解决常见的TOK问题  关于常见的TOPK问题，都可以使用堆这种数据结构来巧妙的解决，除了去统计最大的或者最小的K个元素
 之外，还有一些变形的问题，比如统计出现频率TOPK的问题，这种问题一般需要进行排序。下面列出leetcode
上一些典型的例题：
 数组中的第K最大的元素
 根据字符出现的频率进行排序（堆排序）
 前K个高频元素 leetcode 347
 前K个高频单词 leetcode 692
   理解了堆的特点后，解决这些问题并不难，但是我们要熟悉一些堆的基本操作，比如如何生成一个堆、对
 堆中的元素进行排序等。此外，在满足复杂度要求的前提下，如何写出更加简练的代码也是一个关注点。毫无
疑问的是在对数据的处理上，python比Java有着先天的优势，在代码编写方面会更加简洁，下面是例题
一、前K个高频元素  给定一个非空的整数数组，返回其中出现频率前 *k* 高的元素
对于这种求TOPK频率的问题，与以往的求最大的K个元素不同，我们需要用哈希表来存放每个元素及其出
 现的频率，再用堆这种数据结构去按照升序排列，代码如下：
//构建一个哈希表用来存放每个元素及其出现的频率 private HashMap&amp;lt;Integer,Integer&amp;gt; map = new HashMap(); //构建一个小顶堆，并且该堆要对map中的元素出现的频率进行排序 private PriorityQueue&amp;lt;Integer&amp;gt; heap = new PriorityQueue&amp;lt;&amp;gt;((n1,n2) -&amp;gt; map.get(n1) map.get(n2)); //返回的列表 private List&amp;lt;Integer&amp;gt; topK = new LinkedList(); public List&amp;lt;Integer&amp;gt; topKFrequent(int[] nums, int k) { //先统计每个元素及其出现的频率，当然还有更简单的写法，请看拓展内容 for(int n : nums){ if(map.</description>
    </item>
    
    <item>
      <title>Java中的ArrayDeque和LinkedList的使用</title>
      <link>https://sin-coder.github.io/datastructure/deque_linked/</link>
      <pubDate>Tue, 10 Dec 2019 16:10:36 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/datastructure/deque_linked/</guid>
      <description> Java中的ArrayDeque和LinkedList的使用  在Java的集合框架中，ArrayDeque和LinkdedList是实现栈和队列的两种不同方式，那么应该如何使用，
 才能使自己构造的数据结构解决问题时性能更好呢，先上一张继承关系表 
 从上图中我们可以看到，ArrayDeque是继承于Deque接口，LinkedList继承于List接口和Deque接口，看
 起来功能要更加强大，那么我们从几个方面来进行比较
 从这张表格可以看出ArrayDeque和LinkedList的主要区别就是数组和链表的区别，二者都能用作双向队列、
 栈；但是使用ArrayDeque当数据不断插入时，底层数组可能扩容，对性能的影响是比较大的；LinkedList底层
是使用的双向链表，不存在扩容的问题，但由于链表，占用的存储空间更大。二者各有优劣，所以综合来看：
 当做队列或栈使用并且数据量比较少时，使用ArrayDeque，占用的存储空间更小
 当做队列或栈使用并且数据量很大时，使用LinkjedList，这样不用扩容对性能的影响
 当需要随机访问时，使用ArrayDeque，数组有先天的优势
  </description>
    </item>
    
    <item>
      <title>动态规划解题思想总结</title>
      <link>https://sin-coder.github.io/leetcode/dp/</link>
      <pubDate>Tue, 03 Dec 2019 22:26:15 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/leetcode/dp/</guid>
      <description>动态规划解题思想总结 一、动态规划和递归、分治的关系 1.递归  关于递归其实就是一个函数调用它自己，它和分治和回溯等算法没有完全隔离开来，它们都可以看做是
 描述一个问题的不同方面。使用递归方法解题时都是有模板的：
public void recur(int level,int param){ //terminator if(level &amp;gt; MAX_LEVEL){ //process result return; } //process current logic process(level,param); //drill down recur(level:level + 1,newParam) //restore current status }   这里上一道经典的使用递归解决的算法题来说明这个框架的使用
经典的汉诺塔问题：原题链接
 public void hanota(List&amp;lt;Integer&amp;gt; A, List&amp;lt;Integer&amp;gt; B, List&amp;lt;Integer&amp;gt; C) { int len = A.size(); //汉诺塔的数量 Hanota(len,A,B,C); } //递归函数 public void Hanota(int n,List&amp;lt;Integer&amp;gt; X,List&amp;lt;Integer&amp;gt; Y,List&amp;lt;Integer&amp;gt; Z){ if(n == 1){ //终止条件 Z.add(0,X.remove(0)); //处理结果 }else{ Hanota(n - 1,X,Z,Y); //向下递归 Z.</description>
    </item>
    
    <item>
      <title>Java和Python中如何使用大顶堆</title>
      <link>https://sin-coder.github.io/program/javapqueue/</link>
      <pubDate>Tue, 03 Dec 2019 21:14:28 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/program/javapqueue/</guid>
      <description>Java和Python中如何使用大顶堆  在数据结构之容器的那篇文章中，我们对于优先队列即堆这种数据结构的底层实现进行了剖析，在实际的
 应用中我们不必自己去实现一个堆，主流的编程语言都提供了相关的集合模块，比如Java中的PriorityQueue
类，Python中的heapq模块。但是这两种语言中实现的堆都是小顶堆（根节点的元素小于左右节点元素的值），
当需要使用大顶堆时该如何解决呢？比如典型的最大的K个元素需要用小顶堆解决，但是最小的K个元素不就
是需要使用一个大顶堆来解决了吗！
 具体的解决方案如下：
 一、通用的方法: 取反  通用的解决方法就是跟语言没有关系的解法，想要构造一个大顶堆，只要保证根节点大于左右节点即可，
 所以我们可以将数据取成相反数再添加到小顶堆中去，取出时再对数据进行取反即可实现大顶堆的效果
二、针对Java的方法  优先队列中存放的是基本数据类型的包装类（Integer、Long）或者自定义的包装类。对于基本数据类型
 的包装器类，优先队列中元素默认排列顺序是升序排列的，也就是说是小顶堆，但是既然是默认的就可以进
行更改。此外，对于自定义的类来说，需要自己定义比较器，比如：
//自定义比较器，降序排列 public static Comparator&amp;lt;Integer&amp;gt; cmp = new Comparator&amp;lt;Integer&amp;gt;(){ public int compare(Integer e1,Integer e2){ return e2 - e1; } } //声明对象时 Queue&amp;lt;Integer&amp;gt; pqueue = new PriorityQueue&amp;lt;Integer&amp;gt;(); //不使用比较器，默认升序排列，即小顶堆 Queue&amp;lt;Integer&amp;gt; pqueue = new PriorityQueue&amp;lt;Integer&amp;gt;(cmp); //使用比较器，降序排列，即为大顶堆 //比较器升降序的声明 Comparator&amp;lt;Object&amp;gt; cmp = new Comparator&amp;lt;Object&amp;gt;(){ public int compare(Object o1,Object o2){ return o1 - o2 //升序 return o2 - o1 //降序 } }   所以在实际解决问题的过程中如果需要使用大顶堆可以这样声明</description>
    </item>
    
    <item>
      <title>贪心算法集锦</title>
      <link>https://sin-coder.github.io/leetcode/greedy/</link>
      <pubDate>Mon, 02 Dec 2019 22:26:15 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/leetcode/greedy/</guid>
      <description>贪心算法解题总结 一、引例  某天你在超市购物后，总共消费了782元，这时假设你有1元、5元、10元、20元、100元和200元的钞票
 无穷多张，那么最少需要多少张钞票足够支付？
 直觉告诉我们：要尽可能多地使用面值较大的钞票，其实这就是一种贪心的思想
 二、贪心算法简介  由引例我们已经大概了解了什么是贪心，在这儿对它下个定义：贪心算法是指在对问题求解时，总是做
 出在当前看来是最好的选择；也就是说不从整体最优上加以考虑，它所做出的是在某种意义上的局部最优解
 贪心算法不是对所有的问题都能得到整体的最优解，关键是贪心策略的选择，具体的贪心策略中某个状
 态以前的过程不会影响以后的状态，只与当前的状态有关
三、Leetcode典型例题 1.455分发饼干  (1) 题目描述
假设你是一位很棒的家长，想要给你的孩子们一些小饼干。但是，每个孩子最多只能给一块饼干。对每
 个孩子 i ，都有一个胃口值 gi ，这是能让孩子们满足胃口的饼干的最小尺寸；并且每块饼干 j ，都有一个尺
寸 sj 。如果 sj &amp;gt;= gi ，我们可以将这个饼干 j 分配给孩子 i ，这个孩子会得到满足。你的目标是尽可能满足
越多数量的孩子，并输出这个最大数值。一个小朋友最多能拥有一块饼干
 (2)解题思想
根据让更多的孩子得到满足这个目标，可以分析出如下贪心规律：
  某块饼干不能满足某个孩子的胃口，则它也一定不能满足胃口更大的孩子
 某个孩子的胃口可以用更小的饼干来满足，则没有必要用更大的饼干满足，更大的饼干留给胃口更大的孩子
 孩子的胃口越小，则其更容易被满足，所以优先从胃口小的孩子尝试
   (3)算法思路
  按照胃口大小和饼干大小对两个数组进行从小到大的排序
 按照从小到大的顺序用饼干来尝试是否可以满足某个孩子的胃口，每个饼干只尝试一次，如能够满足，接着
   用下一块饼干继续尝试能否满足下一个孩子的胃口；否则，抛弃该饼干，用下一块饼干继续尝试满足当前
的孩子。直到没有更多的孩子或者没有更多的饼干，算法结束
(4)代码实现</description>
    </item>
    
    <item>
      <title>Python中的sort()和sorted</title>
      <link>https://sin-coder.github.io/program/sort_sorted/</link>
      <pubDate>Thu, 28 Nov 2019 21:14:28 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/program/sort_sorted/</guid>
      <description>Python中sort和sorted的区别和使用 一、函数介绍  sort函数和sorted函数的功能是非常强大的，在有些leetcode题目中，使用了这些函数，几行代码就可以
 搞定了（只要你不怕被面试官打死），下面我们先看看这两个函数的介绍吧
&amp;gt;&amp;gt;&amp;gt; help(list.sort) Help on method_descriptor: sort(self, /, *, key=None, reverse=False) Stable sort *IN PLACE*. #inplace &amp;gt;&amp;gt;&amp;gt; help(sorted) Help on built-in function sorted in module builtins: sorted(iterable, /, *, key=None, reverse=False) Return a new list containing all items from the iterable in ascending order. #new list A custom key function can be supplied to customize the sort order, and the reverse flag can be set to request the result in descending order.</description>
    </item>
    
    <item>
      <title>BFS &amp; DFS算法</title>
      <link>https://sin-coder.github.io/datastructure/bfs-dfs/</link>
      <pubDate>Thu, 28 Nov 2019 17:01:10 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/datastructure/bfs-dfs/</guid>
      <description>深度优先和广度优先算法详解 一、DFS 和 BFS 算法概述 1.什么是DFS和BFS？  DFS （Depth-First-Search）,称为深度优先搜索；BFS（Breadth-First-Search），称为广度优先搜索。
 这二者都是在树和图的遍历中应用非常广泛的算法，那么再来看下遍历的定义：从初始点出发，按照某种
搜索方法对树或图中的每个节点均做一次且仅做一次的访问，访问具体节点所做的操作依赖于具体的问题。
 在树的遍历算法中，我们经常会看到前序遍历、中序遍历、后续遍历、层序遍历等方法，其实前序遍历
 就是深度优先搜索的一种实现，层序遍历就是对广度优先搜索的一种实现。树也可以看做是一种特殊的图，
树和图的遍历主要的区别就是树有根节点（指定的），而图需要我们自身指定开始遍历的节点。
2.DFS和BFS算法的核心思想  BFS和DFS都是图的遍历方法。它们具有一些共性的问题，比如都要避免节点的重复访问，具体的实践
 中可以设置一个访问数组，数组中的每个元素代表一个节点，当节点被访问后数组中对应的元素赋一个特定
的值进行标记即可
 DFS的搜索过程是这样的：
  先访问初始节点V
 从V未被访问的邻接点中选取一个W，从W出发进行DFS
 重复上述步骤即可
   BFS的搜索过程是这样的：
  先访问图的初始节点V
 依次访问V节点的所有邻接节点V1，V2，V3...
 按照V1，V2，V3被访问的次序依次访问与它们相邻接的未被访问的节点
 重复上述过程
  3.DFS和BFS算法效率分析  DFS和BFS的时间复杂度只与数据的底层存储结构相关，而与搜索的路径无关。当使用邻接矩阵存
 储时，对于每一个被访问的节点，都要循环检测矩阵中的整整一行（n个元素），时间复杂度为O（n^2）
当使用邻接表来存储时，有2e个表节点，但只需要扫描e个节点即可完成遍历，加上访问n个头节点的
时间，时间复杂度为O（n+e）
 DFS和BFS算法的空间复杂度相同，都是借用了堆栈或队列，为O（n）。递归在本质上也属于栈
 二、DFS 和BFS 的算法实现  图在底层都是以邻接表或者邻接矩阵的方式来存储的，在Java、C++都可以使用表或者矩阵来进行定义
 的，Python中可以使用字典来进行定义。解决图的BFS问题就是利用队列的先进先出的思想，队列可以保存
图中未遍历的节点；解决图的DFS问题是利用栈这种数据结构，递归和非递归的实现本质上都是先进后出。
1.DFS的算法实现  假设有这样一张图：
  （1）Python的实现</description>
    </item>
    
    <item>
      <title>数据结构之容器</title>
      <link>https://sin-coder.github.io/datastructure/container/</link>
      <pubDate>Thu, 28 Nov 2019 17:01:10 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/datastructure/container/</guid>
      <description>一、概述 1.什么是数据结构中的容器？  容器是一种把多个元素组织在一起的数据结构，也可以理解为一种可以包含其他类型对象作为元素的
 的对象。容器是仅仅用来存放数据的，本身没有取出元素这种能力，大多数情况下是通过可迭代对象来
操作容器
 容器这种数据结构在各种编程语言中都有相应的实现，比如我们经常会比较熟悉的C++的标准模板库
 （Standard Template Library，STL）、Java的集合框架（Java Collections Framework，JCF）、而在
Python中更是将容器类型的数据结构作为其基本数据类型、Go语言也有内建的容器和相应的标准库，
本篇博客便是在总结各种容器使用及原理的基础上，对Java、Python中相同的类型的容器做一个横向的
对比，以便于日后的总结和复习
2.Java集合框架简介  （1）泛型的机制
Java中的容器就是可以容纳其他Java对象的对象，且Java容器中只能存放对象，对于一些基本的数据
 类型（比如int、long、float、double等），需要将其包装成对象类型之后（Interger、Long、Float、Double
等）才能放到容器里，很多时候拆包装和解包装使能够自动完成的
 Java容器能够容纳任何类型的对象，表面上是通过泛型机制完成的。事实上，所有容器的内部存放的都
 是Object类的对象，所有的对象都是Object类型的子类。泛型机制只是简化了编程，由编译器自动帮助我们
完成了强制类型的转换而已，示例代码如下
ArrayList&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;String&amp;gt;(); //参数化类型 list.add(new String(&amp;quot;csuyzz&amp;quot;)); String name = list,get(0); //容器中存放的Object类的对象隐式转换成为String类型的对象   此外，Java里的对象都在堆上，且对象只能通过引用（reference）来访问，容器里存放的其实是对
 象的引用而不是对象的本身
 （2）接口和实现（Interfaces and Implementations）
在Java 的集合框架中共定义了14种容器的接口，关系图如下所示，Map接口没有继承自Collection的
 接口，因为Map接口是关联式的容器而不是集合，但也可以从Map转换到Coolection；Stack已经被Deque
所取代

 接口的实现如下表所示
 ImplementationsHash TableResizable ArrayBalanced TreeLinked ListHash Table + Linked ListInterfacesSetHashSetTreeSetLinkedHashSetListArrayListLinkedListDequeArrayDequeLinkedListMapHashMapTreeMapLinkedHashMap &amp;gt; (3) 迭代器</description>
    </item>
    
    <item>
      <title>从尾到头打印链表</title>
      <link>https://sin-coder.github.io/leetcode/printlistreverse/</link>
      <pubDate>Fri, 15 Nov 2019 14:01:10 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/leetcode/printlistreverse/</guid>
      <description>反转链表专题 No.1 问题描述  输入一个链表，从尾到头的顺序返回一个ArrayList
 解题思路 1.使用递归法 //1.解法一 public ArrayList&amp;lt;Integer&amp;gt; printListReverse(ListNode listnode){ ArrayList&amp;lt;Integer&amp;gt; arrayList = new ArrayList&amp;lt;Integer&amp;gt;(); if(listnode != null){ arrayList.addAll(printListReverse(listnode.next)); arrayList.add(listnode.val); } return arrayList; } //分析：时间复杂度为O（n）,相当于将每个元素均遍历了一遍 //空间复杂度为O（n^2）,创建的列表的合计元素个数1+2+3+4+n-1 //拓展内容：ArrayList中的addAll(Collection&amp;lt;? extends E&amp;gt; c) 方法 按照指定collection容器返回元素的 //顺序将所有的元素添加到列表的尾部  2.使用栈（推荐解法） //Java实现 public ArrayList&amp;lt;Integer&amp;gt; printListReverse(ListNode listnode){ ArrayDeque&amp;lt;Integer&amp;gt; stack = ArrayDeque&amp;lt;Integer&amp;gt;(); while(listnode != null){ stack.addFirst(listnode.val); listnode = listnode.next; } ArrayList&amp;lt;Integer&amp;gt; arrayList = new ArrayList&amp;lt;Integer&amp;gt;(); while(stack.pollFirst()) arrayList.add(stack.pollFirst()) return arrayList; } //Java中推荐使用ArrayDeque来实现一个栈 //当压栈时，调用addFirst()方法; 出栈时调用pollFirst()方法 //分析：时间复杂度O(n)，空间复杂度也是O（n）  #基于Python的实现 class Solution: def printListReverse(self,listnode): if not listnode: return [] result = [] while listnode: result.</description>
    </item>
    
    <item>
      <title>常见数据结构的定义</title>
      <link>https://sin-coder.github.io/datastructure/defindatastructure/</link>
      <pubDate>Fri, 15 Nov 2019 14:01:10 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/datastructure/defindatastructure/</guid>
      <description>常见数据结构的定义 一、链表（以singly-linked list为例） 1.Java public class ListNode{ int val; ListNode next; //如果是双向链表，则会为left or right ListNode(int x) { val = x; next = null; } }  2.Python class ListNode: def __init__(self,x): self.val = x self.next = Node  3.C struct ListNode{ int val; struct ListNode *next; };  4.Go type ListNode struct{ Val int Next *ListNode }  二、二叉树（Binary Tree Node） 1.Java //Definition for a binary tree node public class TreeNode{ int val; TreeNode left; TreeNode right; TreeNode(int x){val = x;} }  2.</description>
    </item>
    
    <item>
      <title>环形链表</title>
      <link>https://sin-coder.github.io/leetcode/circlelist/</link>
      <pubDate>Fri, 15 Nov 2019 14:01:10 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/leetcode/circlelist/</guid>
      <description>环形链表专题 一、问题1  给定一个链表，判断一个链表中是否有环
 1.算法思路  （1）判断是否存在重复节点
通过检查一个节点此前是否被访问来判断是否为环形链表，可以使用哈希表来存储访问过的节点
（2）快慢指针
通过快慢指针遍历链表，慢指针每次移动一步，而快指针每次移动两步；如果链表中不存在环，最终快
 指针将会最先达到尾部，此时返回Fasle即可；如果链表中存在环，最终快慢指针一定会相遇
2.代码实现 //元素判重法 public boolean hasCycle(ListNode head) { Set&amp;lt;ListNode&amp;gt; visited = new HashSet&amp;lt;ListNode&amp;gt;(); while (head != null) { if (visited.contains(head)) { return true; } else { visited.add(head); } head = head.next; } return false; } //分析，时间复杂度是O（n），对链表中的每个元素最多访问一次，向哈希表中添加一个元素为O(1) //空间复杂度为O（n）,最多将链表中的所有元素均添加到哈希表中  //快慢指针法 public boolean hasCycle(ListNode head) { if (head == null || head.next == null) { return false; } ListNode slow = head; ListNode fast = head.</description>
    </item>
    
    <item>
      <title>什么是死锁？</title>
      <link>https://sin-coder.github.io/os/deadlock/</link>
      <pubDate>Sat, 02 Nov 2019 21:50:12 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/os/deadlock/</guid>
      <description>什么是死锁？ 一、死锁概念的介绍  以两个进程为例，每个进程正在申请的资源恰好是其他进程正在占用的资源； 当然这里的进程数也有
 可能是多个。但最终都是形成一个资源的依赖环
 简述：多个进程由于互相等待对方持有的资源而造成的谁都无法执行的情况
 二、死锁的必要条件  互斥：系统资源之间是互斥使用的，一旦某个进程占用，其他进程便无法使用
 占有并等待：一个进程占有了一些资源，但是又不去释放，同时再去申请其他的资源
 非抢占：每个进程所拥有的资源必须不能被其他进程所抢占
 循环等待：进程之间各自占有的资源和互相申请的资源形成了环路的等待
  三、死锁常用的处理方法 1、死锁预防  （1）简述：
破坏死锁形成的必要条件之一，可以通过限制如何申请这些资源的方法来预防死锁
（2）方法
  基于互斥条件来预防死锁：资源可以进行共享
 基于抢占的解决方案：如果一个进程占有资源并申请另一个不能立即分配的资源，则该进程所占用的资源
   即可被抢占
  基于占有并等待的解决方案：一个进程在申请其他资源之前必须要释放掉自己已有的资源
 基于循环等待的解决方案：对所有的资源进行完全排序，且要求每个进程按递增的顺序来申请资源，这样
   就不会出现环路的等待
 2、死锁避免  （1）简述
检测每个资源的请求，如果造成死锁就立刻拒绝
（2）银行家算法
  安全状态：如果系统中的所有进程存在一个可完成的执行序列P1，P2，P3，………Pn，则称系统处于安   全状态
  使用特定算法判断是否存在一个执行序列，当按照这种执行序列执行时，不会产生死锁
 银行家算法的执行方法：进程在执行的时候主要关注三种类型的资源：进程本身所占用的资源，进程需要
   申请的资源，系统中剩余的资源申请一个work变量（表示系统剩余的资源），need变量（系统正在申请
的资源），allocate(已经分配给进程的资源)按照特定的序列执行，在每个序列执行时，判断当前剩余资
源是否能够满足申请资源，如果能，则将剩余资源减去申请资源在加上释放资源。但是时间复杂度：
T（n）=O(mn^2),执行的代价非常大</description>
    </item>
    
    <item>
      <title>CDN技术简介</title>
      <link>https://sin-coder.github.io/network/cdn/</link>
      <pubDate>Thu, 10 Oct 2019 12:05:48 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/network/cdn/</guid>
      <description>CDN技术简介 一、概述 1.问题背景  不同地理区域的用户访问同一个网站时会产生高延迟，导致用户的访问速度较慢，对个别服务器造成的
 压力也比较大，网站的稳定性和安全性也不是很高，CDN的出现就是用来解决这一问题的
2.什么是CDN  CDN即Content Delivery Network,内容分发网络，具体内容为将源站内容发布到最接近用户的边缘节点，
 使用户可就取得所需内容，提高用户访问的响应速度和成功率。解决了因分布、带宽、服务器能力带来的访
问延迟高的问题，提供了一系列加速解决方案
3.CDN的应用场景  网站服务的客户群体从独立的区域扩张到了全国范围，而自身服务器不足以覆盖全网用户，导致部分地区用   户访问网站速度变慢，到达率不高
  网站已经实现了静动态资源分离，且静态资源服务器的能力已经达到极限，需要增加服务器硬件设才能够   解决问题的
  网站频繁遭到DDOS攻击，CC攻击，DNS劫持，导致用户体验差，网络阻塞，无法提供正常服务 当用户   无访问某一个节点时，CDN会给用户提供更多的节点以供访问
  当网站用户跨多个ISP（电信、联通、移动、铁通、长城），而自身的服务器只在其中一个机房的减少因   运营商通道阻塞而导致的访问失败
 二、CDN的工作原理 1.CDN的工作过程  步骤一：将内容推送到边缘的节点上，以此产生一个副本，（WEB原始服务器推送到各CDN镜像服务器）   原始服务器上的内容拷贝到其他镜像服务器上
  步骤二：引导用户就近进行访问（DNS解析的原理）  2.CDN的加速过程(智能DNS解析)  用户在浏览器中输入域名后，请求DNS服务器解析该域名
 DNS服务器并不能直接解析到该域名所对应的IP地址，而是将该请求发送给智能DNS服务器
   （网站的服务商需要将原来的解析地址转换到智能DNS服务器的IP）
  智能DNS服务器（GSLB调度系统）判断用户访问离某区域最近，就返回该区域服务器的IP地址   （智能DNS服务器是CDN加速服务商所提供的服务器）
  用户拿到IP地址后即可访问该区域的服务器    3.</description>
    </item>
    
    <item>
      <title>端口镜像和链路聚合小结</title>
      <link>https://sin-coder.github.io/network/portlink/</link>
      <pubDate>Wed, 07 Aug 2019 21:26:25 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/network/portlink/</guid>
      <description> 端口镜像和链路聚合 一、端口镜像 1.背景需求  监控交换机特定端口的入站或出战报文，流量监测和故障定位
 2.镜像的分类  （1）基于端口的镜像
指定端口的所有数据复制到指定的端口，交换机可以指定入站和出站；以太网交换机支持多对一的镜
 像，即是将多个端口的报文复制到某一个监控端口上
 本地端口镜像：监控主机和观察端口进行直接相连。
远程端口镜像 : 监控主机和观察端口之间通过二层网络或三层网络相联
 二层端口镜像：交换机将镜像端口的报文封装成VLAN、然后通过观察端口将该报文在此VLAN中进行广播
三层端口镜像：GRE报文头来封装和解封装镜像报文，穿透三层网络
 （2）基于流的镜像
只是将匹配访问控制列表的业务流量复制到指定的监控端口。具体可分为流镜像到端口和流镜像到CPU
 二、链路聚合 1.问题背景  网络中某些链路承载的流量非常大，链路存在带宽瓶颈；链路存在端口故障 。而链路聚合就是将多条
 以太网链路进行捆绑，链路冗余、负载分担来解决这些问题的
2.工作模式  （1）手工负载分担模式
允许在聚合组中手工加入多个成员接口，所有接口均处于转发状态，分担负载的流量。Eth-Trunk的
 创建、成员接口的加入都需要手工配置来完成，没有LACP协议报文的参与，通常运用在对端设备不支
持LACP协议的情况之下 该工作模式下的所有接口均处于转发状态
 （2）静态LACP
M：N模式 :M条链路处于活动状态 N条线路非活动状态作为备份链路；当M条链路中出现故障后，系
 统会从N条链路中选择优先级较高的链路接替出现故障的链路同时实现链路负载分担和链路冗余备份的功
能 。利用LACP协议进行聚合参数的协商、确定活动的接口和非活动的接口的链路聚合方式
 静态：手工配置Eth-Trunk成员接口、由LACP协议协商确定活动接口和非活动接口
（3）动态LACP模式
从ETH-TRunk的创建到加入到成员接口都不需要人工的干预，由LACP协议自动协商来完成
 </description>
    </item>
    
    <item>
      <title>STP生成树</title>
      <link>https://sin-coder.github.io/network/stp/</link>
      <pubDate>Tue, 06 Aug 2019 16:12:20 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/network/stp/</guid>
      <description>STP生成树简介  STP:Spanning Tree Protocol ,生成树协议，为什么要生成树呢，因为有环的存在
 1.利用STP可以解决的问题  消除环路：阻塞冗余链路消除网络中可能存在的通信环路 链路备份：当前活动的路径发生故障之后，激活冗余链路备份，进而恢复网络的连通性   STP的正常工作依赖于网桥协议数据单元(BPDU报文)的泛洪
 2.BPDU报文的介绍  其中比较重要的参数有
  ROOT ID：发送此配置BPDU的交换机所认为的根交换机的标识
 ROOT Path Cost： 从发送此配置BPDU的交换机到达根交换机的最短路径总开销，含交换机根端口的开
   销和不发送此配置BPDU的端口的开销
  Bridge Identifier : 发送此配置BPDU的交换机的STP交换机标识
 Port ID : 发送此配置BPDU的交换机端口的STP端口标识
   比较顺序为：RID&amp;gt;RP&amp;gt;BID&amp;gt;PID，且对应的值越小越优先
  桥ID（Bridge ID）: 是交换机的STP标示符，一共8个字节，由2个字节的优先级和6个字节的MAC   地址构成：桥优先级缺省为32768，可以手工修改，MAC地址为交换机的背板MAC网络中Bridge ID最小
的交换机将成为根桥
  路径开销：Path COST，端口路径开销的默认值和取值范围由选定的路径开销算法决定，路径开销与带宽成反比
 端口ID （2字节）= 端口优先级（1字节）+ 端口编号（1字节），缺省优先级128，范围0-255，越小越优。
  3.STP的缺点  STP的短板：所有的vlan都只能使用单侧的链路，这将导致被阻塞端口所在的链路带宽资源浪费</description>
    </item>
    
    <item>
      <title>Vxlan技术简介</title>
      <link>https://sin-coder.github.io/network/vxlan/</link>
      <pubDate>Tue, 06 Aug 2019 15:45:16 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/network/vxlan/</guid>
      <description>Vxlan技术简介 一、Vxlan技术的产生背景  网络隔离的限制：802.1Q中标准中最多支持的4094个VLAN，数量已无法满足在二层网络中虚拟机数量增   长的需求
  虚拟机规模的限制：在大二层网络里，报文通过MAC地址进行转发，MAC地址表容量限制了虚拟机的数量
 虚拟机的迁移受到限制，虚拟机从一台主机上迁移到另一台主机时，也必须依靠二层网络来进行传输
  二、名词解释  VTEP：Virtual TUNNEL END POINTS ，VXLAN隧道的端点，主要用于VXLAN报文的封装和解封装，直   连物理网络，分配的地址为物理网络IP
  VM：虚拟机，虚拟机之间的访问可分为相同VNI下的不同VM、不同VNI下的跨网访问和VXLAN与非VXLAN   之间的跨网访问
  VNI: VXLAN的网络标识,用于区分VXLAN段，一个VNI表示一个租户  三、技术实现  VXLAN的通信原理是将逻辑网络中的数据帧封装在物理网络中进行传输，封装和解封装的过程由VTEP
 节点来完成。VXLAN将逻辑网络中的数据帧添加在VXLAN头部之后就封装在物理网络中的UDP报文进行数
据的传送
四、VXLAN的报文格式 注释：
 OUTER 的UDP端口使用4798，但是可以进行修改
 OUTER的IP头封装：源IP为发送报文的虚拟机所属的VTEP的IP地址，目的IP为目的虚拟机所属的
   VTEP IP地址
  OUTER:SA为发送报文的虚拟机所属的VTEP MAC地址，DA为目的虚拟机所属的VTEP上路由表中的   下一跳MAC地址
  VXLAN header: 24位的VNI，一共可表示2^24个不同的局域网 16777216个不同的网络  参考文章：https://www.cnblogs.com/hbgzy/p/5279269.html</description>
    </item>
    
    <item>
      <title>Vlan详解</title>
      <link>https://sin-coder.github.io/network/vlan/</link>
      <pubDate>Fri, 02 Aug 2019 14:06:13 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/network/vlan/</guid>
      <description>Vlan详解  最近在学习网络时总是卡在了二层交换上，尤其对一些概念不是很理解，在公司里实际上去配置一些设
 备总是出现各种问题，所以下定决心搞透二层vlan中的一些技术，下面是最近总结的一些知识
一、相关概念解释  VLAN: 虚拟局域网，VLAN所指的LAN特指使用路由器分割的网络-也就是指广播域
 MAC地址分类：MAC地址可分为单播、组播和广播三大类，单播MAC地址全球唯一
 MAC地址泛洪：内网中的一台PC向交换机发送大量的伪造的数据帧，当伪造的目的MAC将交换机的MAC
   地址表填充满之后，MAC地址表无法学习到新的MAC导致交换机瘫痪
附：MAC地址表是交换机工作的核心，如果MAC地址表紊乱，则交换机就不能正常工作。
  广播域：指的是广播帧（目标的MAC地址全部为1）所能传递到的范围，也指能够直接通信的范围，不仅   仅是广播帧、多播帧和目标不明的单播帧也能在同一个广播域中通行
  ARP请求：建立IP地址和MAC地址的映射关系
 DHCP：用于自动设置IP地址的协议，当客户机请求DHCP服务器分配IP地址的时候，必须要发出DHCP广播
 RIP协议：是一种路由协议,每隔30秒路由器都会对临近的其他路由器广播一次路由信息，RIP以外的其他路由
   协议使用多播传输路由信息，这也会被交换机泛洪
 二、二层交换机简介 1、主要功能  终端用户的接入、维护自己的MAC地址表、数据帧的转发和过滤、二层环路的避免和链路的冗余性
 2、工作原理  在收到数据帧之后，交换机学习帧的源MAC地址，然后在MAC地址表中查询该帧的目的MAC地址，并
 将数据帧转发出去
3、具体过程  初始情况下，交换机的MAC地址表是空的
 PC1发送数据帧给PC2（PC1已经通过ARP请求获取了PC2的MAC地址）
 交换机在1口接受到该数据帧后，在MAC地址表中查询该帧的目的MAC地址
 MAC地址表中没有对应匹配的MAC地址，则将这个数据帧进行泛洪，同时交换机学习到该帧的源MAC地址
   并创建表项;将源MAC地址与接收该帧的1口进行关联
  除目的主机外的其他的主机会丢弃该数据帧，目的主机回复数据，将自己的MAC地址发往交换机
 此时该数据帧的MAC地址为源主机的MAC地址，交换机在查询到该表项之后，就将数据帧从1口转发出去
 同时交换机学习到目的主机的MAC地址，并在MAC表项中将其与2口进行关联
  4.为什么要使用VLAN  二层交换机只能构建单一的广播域，但是在使用VLAN之后，它能够将网络分割成多个广播域。未分割</description>
    </item>
    
  </channel>
</rss>