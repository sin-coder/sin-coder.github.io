<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sin-coder</title>
    <link>https://sin-coder.github.io/</link>
    <description>Recent content on sin-coder</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Apr 2020 19:55:33 +0800</lastBuildDate>
    
	<atom:link href="https://sin-coder.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Linux文本处理命令总结</title>
      <link>https://sin-coder.github.io/linux/text/</link>
      <pubDate>Fri, 24 Apr 2020 19:55:33 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/linux/text/</guid>
      <description>一、概述  Linux中的有关文本处理和分析的命令有很多，本节主要介绍几个使用比较频繁的命令：
 grep、sed、find、awk。其中每个命令的使用方式都是比较灵活的，命令的参数很多，选
项也很多，但我们只需记住些常用的即可
二、grep 1、用途简介  grep用于查找文件中符合条件的字符串，比较多地用于日志行为分析
 2、命令格式  grep match_pattern file
 3、常用参数  -o:只输出匹配的文本行
 -v:只输出没有匹配的文本行
 -c:统计文件中包含文本的行数
 -n:打印匹配的行号
 -i:搜索时忽略大小写
 -l:只打印文件名
 -e:指定字符串作为查找文件内容的样式
 -r:递归的搜索
  4、使用示例  （1）匹配多个字符串模式
 grep -e &amp;quot;mode1&amp;quot; -e &amp;quot;mode2&amp;quot; filename
 （2）在多级目录中对文本递归搜索
 grep &amp;quot;mode&amp;quot; . -r -n
 （3）在当前目录下查找以file为后缀的文件名并且包含test字符串的文件
 grep test file
 （4）在日志文件夹中查找包含docker字符串的日志
 grep -n docker /var/log/log
  三、sed 1、用途简介  sed命令主要是利用脚本来处理文本文件，主要用来自动编辑一个或多个文件、简化</description>
    </item>
    
    <item>
      <title>名字服务简介</title>
      <link>https://sin-coder.github.io/database/newconcept/</link>
      <pubDate>Fri, 24 Apr 2020 14:25:08 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/database/newconcept/</guid>
      <description>  最近在学习MDB平台操作的过程中，遇到了像L5、名字服务等一些不熟悉的平台或者
 服务，为了不影响在MDB申请实例的配置过程，特地了解了一下对应平台或者服务的基
本功能，日后有时间再去进行深入学习，本节主要介绍名字服务
一、名字服务 1、服务调用的几种常见模式  对于一个分布式系统来说，服务是部署在多台主机上的，如何让调用者找到一个被
 调用者，可以使用下面几种模式
（1）HardCode模式  将要访问的后端服务和端口写死在代码中，显然这是愚蠢的做法
 （2）配置文件模式  这是最通行和最简单的模式，一般会在一个配置文件中（ini/conf），配置文件是一种
 静态管理的模式，需要对配置进行操作修改，成本非常大
（3）DNS模式  DNS是公网访问的常见模式，但是DNS服务发现模式粒度比较大，只能到IP级别，端
 口依然需要自己去管理
（4）类zk模式  zookeeper基于zab强一致性协议来实现，chubby是基于Paxos协议来实现的。为了
 实现Zookeeper的高可用性，集群必须是奇数节点，一般建议5个。这有利于leader的选举，
偶数个节点是无法公平投票的；集群的强一致性，使得当一个写请求递交到zk集群中时，
此时可以保证写入到左右的节点， 当读取时，读取任意一个节点的结果都是相同的
（5）类etcd模式  Raft一致性协议的Go语言的实现，是docker容器服务注册和服务发现的标准实现
 2、名字服务中心需要解决的问题 （1）调用方能够访问到的实例是  服务注册，即对外宣告某服务的实例有哪些
 服务发现，调用方能够访问哪些程序，通过某种方式找到这些服务实例
  （2）调用方最好去访问谁？  能够访问的最优服务实例
 （3）调用方访问的服务实例出现问题的时候  服务实例能否容错，后端的服务架
 3、L5模式  L5是一套容错系统，它通过收集后台服务器集群的空闲状态 ，对发送到后台服务器
 群的请求提供负载均衡的访问。此外，L5提供过载的保护，根据后台服务回包的状态判
断是否对后台服务发起请求，防止后台服务因压力过大而产生故障，防止服务故障后继
续对其发请求而引发雪崩
 L5 : 其中L指的是Load Balance; 5是指的5个9的可用性，即99.999%
 </description>
    </item>
    
    <item>
      <title>TiDB-调度原理简介</title>
      <link>https://sin-coder.github.io/database/tidbschedu/</link>
      <pubDate>Fri, 24 Apr 2020 00:53:48 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/database/tidbschedu/</guid>
      <description>一、TiKV概述  TiKV是TiDB的数据库的分布式存储引擎，数据以Region为单位进行复制和管理，每个
 Region为单位进行复制和管理
 每个Region会有多个Replica，这些Replica会分布在不同的TiKV节点上，其中leader负
 责读和写，Follower负责同步Leader发过来的Raft log
二、关键问题  如何保证同一个Region的多个Replica分布在不同的节点上？一台机器上启动多个TiKV   的实例存在的问题？
  TiKV集群进行跨机房部署用于容灾的时候，如果一个机房掉线，如何保证不会丢失Raft   Group的多个Replica?
  添加一个节点进入TiKV集群之后，如何将其他节点的数据搬过来？
 如果一个节点短暂掉线时如何处理，如果节点长时间掉线，如何处理？
 如何调接Replica副本的个数
 并不是所有的Region都被经常访问，可能热点数据只在少数的几个Region上
 集群在做负载均衡的时候，需要搬迁数据，这种数据的迁移能否不占用大量的网络带
   宽、磁盘IO和CPU
 三、系统调度需求 1、分布式高可用存储系统的要求  副本数量不能多也不能少
 副本需要分布在不同的机器上
 新增加节点之后，其他节点上的副本如何迁移过来
 节点下线时，需要将该节点的数据迁移走
   满足这些需求后系统具有多副本的容错、动态的扩容/缩容、容忍节点掉线和自动故
 障恢复的功能
2、需要优化的需求  整个集群leader的均匀分布
 维持每个节点的存储容量均匀
 维持热点分布均匀
 管理节点的状态，手动上线/下线节点、自动下线失效节点
   满足这些需求后，系统的负载更加均匀，且更加方便的管理
 四、系统调度的方案  满足3.</description>
    </item>
    
    <item>
      <title>TiDB-存储原理简介</title>
      <link>https://sin-coder.github.io/database/tidbstorage/</link>
      <pubDate>Fri, 24 Apr 2020 00:53:20 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/database/tidbstorage/</guid>
      <description>一、数据存储的要求 1、数据库应该怎么存储数据  数据库最根本的功能就是把数据存下来，保存数据的方法有很多
 （1）直接使用数组  最简单的就是在内存中直接构建一个数据结构（比如可以使用一个数组），保存用户
 发来的数据。这个方案非常简单，性能也是非常好的。但是存在很大的缺点：数据完全在
内存中，一旦停机或者服务重启，数据就永远丢失
（2）数据丢失如何解决  为了解决数据丢失的问题，可以将数据存储在非易失性的介质中，比如硬盘这时我们
 可以在磁盘上创建一个文件，收到一条数据就在文件中Append一行，这样持久化存储
数据
（3）磁盘出现故障如何解决  为了防止磁盘出现坏道，我们可以做RAID,单机冗余存储
 （4）单机出现故障如何解决  但是如果机器挂了呢？我们还可以将存储改为网络存储，或者是通过硬件或者软件
 进行存储复制，数据安全了
2、数据存储的其他需求  跨数据中心的容灾
 写入速度如何提高
 数据保存下来后是否方便读取
 保存的数据如何修改，如何支持并发的修改
 原子性地修改多条记录
  二、TiKV的设计思想 1、TiKV的数据存储模型  TiDB是Key-Value的模型，并且提供有序遍历的方法，TiKV的主要特点就是:
  TiKV可以看做一个巨大的Map
 这个Map中的Key-Value是按照Key的二进制顺序有序排列的
   我们可以找到某一个Key的位置，然后不断的调用Next方法以递增的顺序获取比这
 个Key大的Key-Value。这里的存储模型和SQL中的Table无关，TiKV是一个巨大的分
布式Map
2、TiKV数据的持久化机制  TiKV没有选择直接向磁盘上写数据，而是将数据保存在RocksDB中，具体的数据落
 地由RocksDB完成。RocksDB是一个非常优秀的开源的单机存储引擎，通过使用它TiKV
已经实现了高效可靠的本地存储
 但是如何保证单机失效的情况下，数据不会丢失和出错，所以我们需要将数据复制
 到多台机器上，这样一台机器挂了，在其他机器上还有副本，，所以还需要一个可靠，
高效且能处理副本失效的情况
3.TiKV的一致性设计思想-优化的Raft算法  Raft的主要就是一个一致性的协议，主要的功能是Leader选举、成员变更、日志复制</description>
    </item>
    
    <item>
      <title>TiDB-计算原理</title>
      <link>https://sin-coder.github.io/database/tidbcompute/</link>
      <pubDate>Fri, 24 Apr 2020 00:53:05 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/database/tidbcompute/</guid>
      <description>一、关系表到KV存储的映射 1、原理  TiDB的存储引擎是一个全局有序的分布式Key-Value引擎TiDB对于每一个表分配一
 个TableID,每一个索引都会分配一个IndexID,每一行分配一个RowID，TableID在整个集
群中唯一，IndexID/RowID在表内唯一，这些ID都是int64类型
2、具体实现 （1）每行数据按照如下规则进行编码 Key:tablePrefix{tableID}_recordPrefixSep{rowID} Value:[col1,col2,col3,col4] #tablePrefix和recordPrefixSep都是特定的字符串常量 #用于在KV空间中 区分其他的  （2）Unique Index数据的编码 Key:tablePrefix{tableID}_indexPrefixSep{indexID}_indexedColumnsValue  (3)对于非Unique Index的编码  可能有多行数据的ColumnsValue一样，所以应该这样去编码：
 Key:tablePrefix{tableID}_indexPrefixSep{IndexID}_indexedColumnsValue_rowID Value:null #Key里面的Prefix都是字符串常量，作用都是区分命名空间， #以避免不同类型数据之间的相互冲突   每一个Table内部的所有Row都有相同的前缀，一个Index的数据也是有相同的数据的
 所以可以非常方便的将Row或者Index数据有序的保存在TiKV中，即一个表中的所有Row
数据就会按照RowID的顺序排列在TiKV的Key空间中，某一个Index的数据也会按照Index
的顺序排列在Key空间内
3、元信息的管理  Database/Table都有元信息，就是表的定义和各项属性，这些信息需要持久化的存
 储在TiKV中，每个Database/Table都被分配了一个唯一的ID。这个ID作为唯一的标识，
并且在编码为Key-Value，这个ID都会编码到Key中。这样可以构造出一个Key信息，
Value存储的是序列化后的元信息。除此之外，还有一个专门的Key-Value来存储当前
的Schema信息
二、TiDB的整体结构 1、TiKV Cluster  主要的作用就是作为KV引擎存储数据
 2、TiDB Servers  这一层就是无状态的节点，本身并不会去存储数据，节点之间完全对等；TiDB
 Server这一层主要是处理用户的请求，执行SQL逻辑运算
三、SQL层运算  TiDB将SQL查询映射为KV的查询，再通过KV的接口获取对应的数据
 1、查询方案的简介  以select count(*) from user where name = &amp;quot;TiDB&amp;quot;为例</description>
    </item>
    
    <item>
      <title>TiDB架构原理简介</title>
      <link>https://sin-coder.github.io/database/tidbinfr/</link>
      <pubDate>Fri, 24 Apr 2020 00:52:37 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/database/tidbinfr/</guid>
      <description>一、TiDB主要特性  TiDB是一个开源分布式关系型数据库，它主要用来应用在全部的OLTP的场景和大部
 分的OLAP场景。TiDB作为一个开源的分布式数据库主要有以下特点：
 1、高度兼容MySQL MySQL迁移到TiDB是非常容易的，无论是单机迁移还是集群的迁移
2、支持无限的水平弹性扩展 新增节点实现TiDB的水平扩展，轻松地应对高并发、海量数据的场景
3、强一致性和高可用 基于Raft的多数派选举协议可以提供100%的数据强一致性，可以实现故障的自动恢复
4、分布式事务 支持ACID事务
TiDB这些特性使它成为业界认可的优秀数据库产品，但是我们要想深入理解这些特性，
 还要从架构原理的角度学习
二、TiDB的架构原理简介  TiDB集群主要包括三个核心组件：TiDB Server,PD Server,TiKV Server
具体的架构原理图如下所示：
  1、TiDB Server TiDB Server 负责接收SQL请求，处理SQL相关的逻辑，并通过PD找到存储计算所需
 数据的TiKV地址，与TiKV交互数据，最终返回结果。
 TiDB Server 是无状态的，其本身并不存储数据，只负责计算，可以无限水平扩展，
 可通过负载均衡的组件(LVS、HAProxy或者F5)对外提供统一的接入地址
 2、PD Server(Placement Driver) PD是整个集群的管理模块，具体的工作职能是：
  存储这个集群的原信息(某个Key具体存储在哪个TiKV的节点)
 对TiKV集群进行调度和负载均衡(数据迁移、Raft Group leader)
 分配全局唯一且递增的事物ID
   PD通过Raft协议保证数据的安全性,Raft的leader Server负责处理所有操作，其余的PD
 Server仅用于保证高可用性。一般情况下建议部署奇数个节点
 3、TiKV Server TiKV Server是TiDB中的数据存储引擎，存储的数据的基本单位是Region
TiKV使用Raft做协议复制，保证数据的一致性和容灾。副本以Region为单位进行管理，
 不同节点上的多个Region构成一个Raft Group，互为副本</description>
    </item>
    
    <item>
      <title>Linux文件系统目录结构</title>
      <link>https://sin-coder.github.io/linux/filesys/</link>
      <pubDate>Fri, 24 Apr 2020 00:45:56 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/linux/filesys/</guid>
      <description>一、Linux文件系统目录概述  Linux下的文件系统为树形结构，入口为 / (根目录)。树形结构下的文件目录，具体如
 下图所示，不同的Linux发行版有较大差异，但是主体的目录都是比较相似的
二、具体目录功能简介 1、 / (根目录)  这是文件系统的统一入口，是最高一级的目录
 2、/bin和/sbin  这些目录下存放着可执行文件的链接，基础系统所需的命令位于此目录，如cp、chmod、
 ls等命令；对于/bin下的命令任何用户均可执行或者配置，但是/sbin下的命令，普通用户无
权限执行该目录下的命令
3、/boot  这里存放Linux内核以及系统引导程序，你可以看到grub文件夹(常见的开机引导程序)，
 千万不懂乱动这些文件
4、/dev  dev即是device，这里存放着所有的设备文件，Linux中所有的东西都是以文件的形式
 存在的，也包括硬件设备，比如说硬盘、U盘、鼠标等设备
5、/etc  存放系统程序或者一般工具的配置文件
 6、/lib  系统程序所需要的所有共享库文件、类似于Windows平台下的共享库DLL文件
 7、/lost+found  系统以外崩溃或者机器意外关机时，在该目录下产生一些文件碎片；在系统启动时，
 文件系统会检查这里，尝试修复破损的文件系统
8、/media  即插即用型存储设备的挂载点自动在这个目录下创建，比如USB盘系统自动挂载后
 或者CDROM自动挂载后便会在这个目录中创建一个目录
9、/mnt  media文件夹是系统自动挂载设备的地方，而这个目录是用户手动挂载设备的地方
 比如可以将dev文件夹中的设备通过命令挂载到mnt的目录进行操作的
 挂载是由操作系统使一个存储设备上的计算机文件和目录可供用户通过计算机的文件
 系统访问的一个过程。Windows系统中的挂载通常指给磁盘分区分配一个盘符，想当于打开
一个文件系统的入口；Linux系统的挂载是指将一个设备，挂接到一个已存在的目录上，Linux
操作系统将所有的设备都看作文件，它将整个计算机的资源整合成一个大的文件目录，要想
访问存储设备中的文件，必须将文件所在的分区挂载到一个已经存在的目录上了，然后通过
这个目录来访问存储设备
 常用的命令就是：
mount [-参数] [设备名称] [挂载点] 对应的解挂命令就是umonut
 10、/opt  options可选择，有些软件的安装包也会被安装在这里，比如Chrome浏览器等软件包</description>
    </item>
    
    <item>
      <title>Linux系统性能分析命令总结</title>
      <link>https://sin-coder.github.io/linux/perfcommand/</link>
      <pubDate>Fri, 24 Apr 2020 00:43:15 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/linux/perfcommand/</guid>
      <description>一、概述  操作系统的资源主要包括以下几种：CPU、内存、硬盘IO、网络IO，熟练地对这些资
 源的使用进行分析可以帮助我们排查一些服务器使用过程中遇到的问题
二、CPU使用分析 1、CPU性能指标简介  CPU使用时间主要分为用户态时间、系统态时间和空闲态时间，分别表示CPU处于用
 户态执行的时间、系统内核执行的时间和空闲系统进程执行的时间，三者之和就是CPU的
总时间。
 当用户没有用户进程和系统进程需要执行的时候，CPU就执行系统缺省的空闲进程,
 CPU的利用率就是指非空闲进程占用时间的比例，即CPU执行非空闲进程 / CPU总的执行
时间
 CPU方面的主要性能指标如下几项：
  CPU的使用率
 上下文切换
 运行队列长度
   下面分别介绍几个CPU的性能指标
 1、CPU_IDLE  CPU_IDLE就是基于/proc/stat计算出来的，运行cat /proc/stat后的结果如下：
  可以看出cpu的核数，比如cpu0-cpu7便是表是系统有8个核，截取cpu0的参数
 如下：cpu0 32736 0 51047 48473626 33879 0 142 0 0 0，这些参数含义分别为：
 user(32736) 系统从启动开始累计到当前时刻，用户态的CPU时间，不包含nice值为负   的进程
  nice(0) : 系统从启动开始累计到当前时刻，nice值为负的进程所占用的CPU时间
 sysytem(51047) 系统启动开始累计到当前时刻，内核时间
 IDLE(48473626) 从系统启动开始累计到当前时刻，除IO等待时间以外其它等待时间</description>
    </item>
    
    <item>
      <title>常见的排序算法总结</title>
      <link>https://sin-coder.github.io/datastructure/sort/</link>
      <pubDate>Sat, 04 Apr 2020 23:04:00 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/datastructure/sort/</guid>
      <description>经典排序算法的总结  之前总是听一些大牛说学会了排序就相等于学会了算法，能手写个快速排序基本就能通过面试了，这一
 点我是很不理解的；后来慢慢地发现这是有道理的，常见的几种排序算法中蕴含了许多经典的算法思想，
比如说递归、分治、迭代、双指针、空间换时间等，算法的问题很多，但是计算机处理问题的方式却只
有那一种。所以要归根溯源，从简单的排序算法中去学习算法思想也是一种很有效的方法
一、算法描述  对一个无序的数组进行排序 (从小到大或者从大到小)
 二、算法分类标准  划分排序算法的主要标准有稳定性、内外排序、时空复杂度、是否比较排序等
1.稳定性 如果数组中有两个元素是相等的，在经过某个排序算法之后，原来前面的那个元素仍然在另一个元素的
 前面，那这个排序算法就是稳定的；相反如果在原来两个相等元素中前面的一个元素被移到了后面，那就
是不稳定的
 2.内外排序 内排序是所有的排序操作都在内存中完成；
外排序是由于数据太大，因此把数据放入磁盘中，排序需要经过磁盘和内存的数据传输才能进行
3.是否比较排序 比较排序： 一个算法在排序的过程中使用比较操作来判断两个元素的大小关系，那么这个算法
 就是比较排序，常见的排序算法都是比较排序算法，比如冒泡排序、插入排序、堆排序，这些排序
算法的平均时间复杂度最快也只能是O(nlogn)
 非比较排序比较典型的算法有计数排序、桶排序和基数排序，这类排序的时间复杂度可以达到
 O(n)的级别
 4.时空复杂度 就是时间复杂度和空间的复杂度了
 三、常见的排序算法  1.冒泡排序(Bubble Sort)  （1）算法描述：冒泡排序是将相邻元素进行比较,大数慢慢地沉底，小数放置到前面
（2）算法特点：
 内排序，所有操作在原来的数组中就可以完成了，不需要额外的空间
 时间复杂度是O(n^2),空间的复杂度是O(1)
 稳定排序: 如果两个元素的位置相同，他们的位置是不会进行交换的
  （3）代码实现
#冒泡排序 Python的版本 def bubble_sort(nums): n = len(nums) for i in range(n): for j in range(1,n-i): if nums[j] &amp;lt; nums[j-1]: nums[j-1],nums[j] = nums[j],nums[j-1] return nums  //冒泡排序 Java版本 private void swap(int[] nums,int i,int j){ int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; } public void bubbleSort(int[] nums){ for(int i = nums.</description>
    </item>
    
    <item>
      <title>服务器并发模型的总结</title>
      <link>https://sin-coder.github.io/post/server/</link>
      <pubDate>Wed, 26 Feb 2020 15:59:05 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/server/</guid>
      <description> 服务器常用并发模型 1.单线程同步模型  单线程同步模型是最简单的服务器模型，每次只能处理一个客户端的连接，其他连接必须要等到前面的
 连接关闭后才能得到服务器的处理，否则发过来的请求会悬挂住，没有任何响应；服务端是串行地处理客
户端的连接的
 一个客户端必须要等到另外一个客户端运行结束后才可以运行，这也太慢了吧
 2.多线程同步模型  服务器可以并行地处理多个客户端的连接，没来一个连接就开启一个新的线程单独进行处理，每个线程
 都是同步读写客户端的连接的
3.多进程同步模型  Java使用者很少能够体会多进程的魅力，他们都是使用多线程。但是在Python中并不常见，因为Python
 的GIL只能使单个进程占满一个CPU核心，多线程不能利用多核的优势，所以Python服务器可以使用多进程
模型
4.PreForking同步模型  进程在操作系统中是非常耗资源的，所以要对服务器开辟的进程数量进行限制，避免系统的负载过重，
 这就是多进程PreForking模型。
 这种模型预先产生多个子进程，共同对服务器套接字竞争资源，但是最终只能有一个进程获取到。
 如果并行的连接数超过了prefork的数量，那么后来的客户端请求将会阻塞。但是这样也可以通过子进程
的单线程同步模型改成多进程同步模型的方式解决
5.单进程异步模型  上述的服务器模型都是同步的，而现代的服务器一般都是异步的，效率是比较高的，它是一种非阻塞的
 服务器模型，实现了对进程和线程的解放，再加上事件轮询机制的配合使得它的性能比同步高出了许多
 像Nignx、Nodejs、Redis都是基于异步模型构建出来的，性能非常高
 6.PreForking 异步模型  单进程的IO并发能力有限，虽然使用了事件轮询和异步读写功能，但是还不能应对高并发的需求，所以
 需要使用多进程，这样也可以对我们的CPU最大限度的利用
 开源的Tornado服务器和Nignx就是采用了多进程PreForking模型达到了超高并发的处理能力
 </description>
    </item>
    
    <item>
      <title>Redis中的RPC协议结构</title>
      <link>https://sin-coder.github.io/post/redisrpc/</link>
      <pubDate>Mon, 24 Feb 2020 16:59:37 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/redisrpc/</guid>
      <description>Redis中的RPC协议结构  Redis的客户端和服务器之间进行RPC通信时，使用的是其开发者专门设计的文本通讯协议RESP。它的
 开发者认为数据库系统的性能瓶颈一般不在于网络流量，而是数据库自身内部的逻辑处理上。所以Redis使
用了浪费流量的文本协议。但是，依然可以取得很高的访问性能
 下面主要介绍RESP协议的相关内容
 一、RESP协议简介  RESP（Redis Serialization Protocol）,就是Redis的序列化协议，这是一种对人友好的文本协议。它将
 传输的结构数据分为5种最下单元的类型，单元结束时统一加上回车换行符\r\n，具体如下
 单行字符串以+符号开头
+hello world\r\n  多行字符串以$符号开头，后跟字符串的长度
$11\r\nhello world\r\n #长度加上字符串  整数值以：符号开头，后跟整数的字符串形式
:1024\r\n  错误的消息以 - 开头
-WRONGTYPE Operation against a key holding the wrong kind of value\r\n  数组以*开头，后面跟数组的长度
*3\r\n:1\r\n:2\r\n:3\r\n #先是数组长度，依次再是每个内容，表示数组[1,2,3]  NULL用多行字符串表示，不过长度要写成-1
$-1\r\n  空串用多行字符串表示，长度填0
$0\r\n\r\n #两个\r\n之间隔的是空串  客户端向服务器发送指令使用多行字符串数组，比如一个简单的set指令 set author codehole会被序列化为
   下面的字符串
 *3\r\n$3\r\nset\r\n$6\r\nauthor\r\n$8\r\ncodehole\r\n   服务端向客户端回复的响应要支持多种数据结构，基本上都是上述5种基本类型的组合
#单行字符串响应 &amp;gt;set author codehole OK #这里的OK就是单行响应，没有使用引号括起来 #错误响应 -ERR .</description>
    </item>
    
    <item>
      <title>分布式RPC设计思想</title>
      <link>https://sin-coder.github.io/post/ditrirpc/</link>
      <pubDate>Mon, 24 Feb 2020 15:59:05 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/ditrirpc/</guid>
      <description>分布式RPC设计思想  分布式所要解决的问题就是当系统中的个别节点发生故障后整个系统依然能够稳定的对外提供服务，对于
 RPC框架来说同样也是；多线程和多进程解决的都是并发的问题，无论怎样都只能算是单点的设计，要想保证
系统的高可用性，分布式的设计必不可少。下面就介绍一些RPC框架设计中关于分布式的一些思想
一、客户端连接池  如果RPC的服务端部署在多个节点上时，客户端得出的是一个服务列表，有多个IP端口对，客户端的
 连接池可以随机挑出任意的RPC服务节点进行连接，而且每个服务节点都应该有个权重值，如果所有节点
的权重值一样时，它们的流量分配就是均匀的，如果每个节点的权值较小，它被客户端选中的概率也会比
较小。设计示例代码如下：
class RPCNode{ String addr; //服务端的地址 int weight; //节点权重 } class RPCCluster{ RPCNode[] nodes; //节点的列表 Node random(); //按权重随机挑选节点 }  二、容灾 Failover  如果有一个服务节点挂掉时，客户端需要采取一定的策略避免请求失败，比如可以重试，但是不能进行无
 线的重试，要有一定的重试策略
 一个可行的方案是当节点挂掉时，将失效的节点摘除，放置的失效的节点列表中；然后每隔一段时间检查
 失效的节点是否恢复了，如果恢复了，那就从失效的节点中移出，重新加入有效节点的列表中；当然也不能仅
依据一次的检测就判断节点是否有效，可以通过检测一个时间段内的出现的错误数量判断，如果错误数量过多
那就说明了真的失效了，这也是为了避免部分网络问题的原因
三、降权法  我们可以为每个服务端节点赋一个权值，改变权值就可以改变节点的相对流量了；如果某个节点出现了一次
 错误就对该节点进行降权，错误次数越多，降权降得越快，最终可以到达一个最小值，但是无论如何，每个节
都还有翻身的机会。被降权的节点只要有一次调用成功，权值就会恢复正常
 一个非常简单的策略就是当服务端节点错误时进行权重减半，比如从1024开始减半，一直到1，当恢复时
 可以进行权重翻倍
四、服务发现  如果服务端可以支持动态扩容，那么它的稳定性和高可用性就会更高。当系统的负载比较高的时候，我们
 可以通过添加节点的方式减轻压力。但是就像前面设计的静态RPC服务地址列表，当节点增加时，必须要修改
客户端的配置重启才能生效，但是生产环境怎么可能重启配置这时候服务发现的技术就上台了
 服务发现技术就是服务裂变变更时，客户端可以快速地收到这些信息，从而调整自己的工作状态，这样无
 需进行重启就可以完成服务的扩容和缩容
 示例代码如下：
 class ServiceDiscovery(object): def register_service(self,name,addr): pass def get_services(self,name): pass def on_services_changed(self,name): pass   服务发现技术依赖于服务之间中间节点，它接受服务的注册、提供服务的查找、以及服务列表变更的实时</description>
    </item>
    
    <item>
      <title>RPC框架中的消息传递和协议</title>
      <link>https://sin-coder.github.io/post/rpcjiaohu/</link>
      <pubDate>Sun, 23 Feb 2020 14:22:56 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/rpcjiaohu/</guid>
      <description>RPC框架中的消息传递和协议  RPC是两个子系统之间进行的直接信息交互，它使用操作系统提供的套接字来作为消息的载体，以特定
 的消息格式来定义消息的内容和边界；客户端和服务端都是通过文件描述符的读写API来访问操作系统内核
中的网络模块为当前的套接字分配的发送（send buffer）和接收（recv buffer）缓存
 具体在这个过程中消息的内容是什么就需要我们深入RPC的协议进行学习了
 协议设计的整体思想  对于一串消息流，我们必须能确定消息边界，提取出单条消息的字节流片段，然后对这个片段按照一
 定的规则进行反序列化来生成相应的消息对象；消息的表示就是序列化后的消息字节流在直观上的表现
形式，文本的形式对人类比较友好，二进制的形式对计算机比较友好
 每个消息都有其内部字段的结构，结构构成了消息内部的逻辑规则，程序要按照结构的规则来决定字段
 序列化后的顺序
一、消息边界  RPC需要在一条TCP链接上进行多次消息传递，在连续的两条消息之间必须有明确的分隔符规则，以便
 接受端可以将消息分割开来；基于TCP连接之上的单条消息如果过大，就会被网络协议栈拆分成多个数据包
进行传送，而如果消息过小，协议栈就有可能将多个消息合成一个数据包进行发送。对于接收端来说，它看
到的只是一串串的字节数组，如果没有明确的消息边界规则，接收端就不知道这一串字节数组包含了多少消息
 比较常用的两种分割方式是特殊分隔符法和长度前缀法，分别如下图所示
  特殊符分割法就是在每条消息的末尾追加一个特殊的分隔符，并且保证消息中间的数据不能包含特殊分
 割符。比如最常见的分隔符是“ \r\n ”，当接受端遍历字节数组时发现了“\r\n”，就可以确定这个分隔符之前的
字节数组是一条完整的消息。在HTTP和Reids协议中就大量了使用“\r\n”分隔符，这种应用场景要求消息体的
内容是文本消息
 这种方法的优点是消息的可读性比较强，可以直接看到消息的文本内容，但是不适合传递二进制消息，
 因为二进制的字节数组中很容易出现“\r\n”分隔符的ASCII值，如果非要传递的话需要对二进制进行base64
编码转换成文本消息再进行传送
 消息发送端在每条消息的开头再增加4字节长度的整数值，标记消息体的长度，这样消息的接受者就会
 首先读取长度信息，然后再读取相应长度的字节数组就可以将一个完整的消息分离出来，常用于二进制消息
 这种方法的优缺点与特殊分割符法正好相反。长度前缀法可读性很差，但是适用于二进制协议，但是
 对于文本和内容都可以进行传递
 HTTP协议是上述两种法的混合型协议，因为HTTP的消息头采用的是纯文本外加“\r\n”分隔符，而消息
 体是通过消息头中的Content-length的值来决定长度的。HTTP协议可以传输文本协议，也可以传输二进制
数据，比如常见的音视频图像，所以被称为超文本传输协议
二、消息结构  每条消息都有着包含它的语义结构信息，有些消息协议的结构信息是显示的，还有些是隐式的。JSON
 消息的结构就可以直接通过它的内容体现出来，可读性非常高，但是它有太多的冗余信息，比如每个字符
串都使用双引号界定边界，键值对之间必须有冒号进行分割，对象之间必须使用大括号进行分割；而且连
续的多条json消息即使结构完全一样，仅是value值不同，也需要发送同样的key字符串
 消息的结构在同一条消息通道上是可以进行复用的，比如建立在链接的开始的ＲＰＣ的客户端和
 服务端之间先互相告知消息的结构，后续发送消息时只需要按照这个消息的模板发送消息就可以了，
接收端会自动将value值与相应位置的key关联起来，这样的模式可以节省比较多的流量</description>
    </item>
    
    <item>
      <title>RPC框架中客户端的实现</title>
      <link>https://sin-coder.github.io/post/distri_client/</link>
      <pubDate>Fri, 21 Feb 2020 16:08:30 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/distri_client/</guid>
      <description>RPC框架中客户端的实现  RPC客户端实现的难点在于客户端一般都不是单线程的，需要考虑在多线程的情况下如何流畅的使用客
 户端而不会出现并发的问题，交互过程的模型图如下：
 就如上面的模型图所示，在多线程的客户端中，客户端与数据库之间会维护一个连接池。当线程中的代码
 需要访问数据库时，先从数据库中获取一个连接，与数据库交互完成后再将这个连接归还给线程池。所以对
于业务线程来说，拿到的连接不会同时被其他的线程所共享，这样就可以避免并发的问题
 此外，服务器的性能往往随着并发连接数量的增加而下降，所以必须严格控制有效连接的数量；连接池的
 数量上限也是数据库的一层壁垒，下面将介绍一些客户端设计中的主要机制
一、安全锁  连接池是为多线程而设计的，每个线程都会访问线程池的对象，所以线程池需要使用锁来控制数据结构
 的安全。安全锁会使线程安全，但是也会导致性能受损。锁的临界区代码要尽量避免耗时的计算和I/O操作，
而且锁的粒度还要尽可能的细，但是代码实现不易
 增大锁的粒度可能在某些程度上使代码实现更为容易，因为连接都是用来进行相对缓慢的I/O操作的，锁
 是基于内存操作的，相比于I/O操作可以忽略不记
二、懒惰连接  连接池的连接多为懒惰连接，在需要的时候才会向数据库中申请。因为一个系统非常闲置，以前开辟了
 太多的连接是对资源的浪费；懒惰的连接池可以保证只会对单线程的程序开辟一个连接
 当然懒惰连接也有不好的地方，比如服务器的代码需要经过一个热身的过程，早来的请求需要额外付出
 一次建立连接的耗时代价、如果数据库连接参数不正确，需要在收到用户的请求进行显式数据访问时才能发现
三、健康检查和性能追踪  连接池中管理的连接可能或因为网络原因而损坏断开连接，连接池需要保持内部管理的连接是健康可用
 具体实现的机制如下：
 线程从连接池中申请连接返回之前，线程池需要对连接进行检查，确定连接是通常的
 线程将连接归还给连接池时，线程池对连接进行检查，确定连接没有被搞坏
 线程池定时对管理的连接进行检查
   如果检查发现连接有问题时，一般的做法两种：
  抛弃当前的连接连接池的连接数量减1，如果是在线程的borrow方法中，那就再重新去连接池申请一个
 修复当前连接，一般也就是执行重连
   此外，好的连接池还应该考虑到性能的可追踪性，当用户通过线程池分配的连接去访问数据库时，
 它的消息执行时间应该是可以被统计和追踪的。所以连接池往往还需要对原生的连接进行一定程度的
包装，在关键的函数代码调用前后增加性能统计代码，并对外提供监听端口，以便将统计信息传递给
外部的监控模块
四、超时策略  当业务线程繁忙的时，连接池内部的连接可能会出现不够用的场景，一个线程请求的borrow方法
 在长时间的等待后仍然等不到空闲的连接，这就是超时问题，主要有以下是3种解决方案：
 永不超时，等不到就一直接着等 一定的时间拿不到后，就像外部抛出超时异常，中断业务逻辑 如果发现连接池没有空闲连接，就去申请一个新的连接给调用方。当调用方归还连接的时候，连接池计算当前   缓存的连接数量，如果超过了最大的连接数，就将当前的连接销毁，否则就保存</description>
    </item>
    
    <item>
      <title>搭建自己的VPN服务器实现科学上网</title>
      <link>https://sin-coder.github.io/post/skipwall/</link>
      <pubDate>Thu, 20 Feb 2020 22:31:32 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/skipwall/</guid>
      <description>搭建自己的VPN服务器实现科学上网  最近不知道怎么了，自己原先够买的VPN服务莫名其妙的无法使用了，自己部署在github上的网站也无
 法访问了，这日子真的过不下去了，VPN不断地被墙也不是一天两天的事了。因此自己便一直想着能否搭建
自己的VPN服务，只供自己使用被墙的风险不就是大大降低了嘛！
 在写这篇博客之前，自己也想到一个笑话，在Git问世之前，Linux社区的开发人员由于私自破解由
 BitMover开发的版本控制软件，致使BitMover公司收回了Linux社区对版本控制软件的使用权。本来觉
得由Linux之父Linus之父向BitMover公司道个谦，这事就过去了，可实际上是不可能的。大神终究是大神
，Linus自己花了两周的时间就用C写了一个分布式的版本控制系统，就是Git，之后Linux的内核代码已经
开始由Git进行管理了。所以对于技术领域而言，哪里有压迫，哪里就有反抗
 好了，废话少说，进入正题
 一、前期准备  要想搭建一个专属VPN服务来实现翻墙，首先必须要有一台海外的服务器（香港的也可以），否则你服
 务的流量也出不去啊！那么问题来了，国内的云服务商对于海外的服务器卖的还都是挺贵的，恐怕经济上
难以承受。那有没有白嫖的海外服务器呢，有！请看下图
 百度的广告有时还是挺好的，让我发现了AWS还提供免费的云主机服务，但是哪有天上掉馅饼的，提供免费
 服务的前提是你要先注册吧，注册的时候竟然需要VISA或者Master的卡号（就是那种能付美元的银行卡了），这
种卡我还真的没有。然后发现某宝上有卖卡号的，自己就去买了一个（大概30元，相比于VPN的费用算是便宜了）
。注册使用银行卡号不是需要扣费，而是需要检测银行卡中是否有剩余的1$，从而验证卡号的可用性
 在这里简要说明一下，AWS为每个用户提供了每月750小时的运行实例时间，持续12个月。也就是说我们
 在一个账户上可以运行多个虚拟机的实例，总共时间不能超过750个小时，这足够我们持续使用一年的了
二、创建虚拟主机 1.切换地理区域  在具体创建实例之前，需要将区域设置为东京（推荐，网络延迟最小），当然也可以设置为其他的地区
 2.创建实例  选择EC2服务后就可以开始创建实例了，可以看到免费套餐中可选的系统类型是比较多的，Linux的各种
 版本、Windows Server等，这里我们就选用推荐的第一个吧（放在第一个肯定有它的理由）。选择第一个进
入即可
 然后是选择一个实例类型，审核并启动即可，其他的先不需要配置
  点击启动后，会有一个创建密钥对的界面，这里选择创建新的密钥对即可，再输入密钥对名称后一定注意要
 下载保存密钥对（非常重要，不然你用客户端就登不上去了），之后选择启动实例即可；
 启动完成后点击实例号即可进入虚拟机控制台界面，注意这时我们需要关注的虚拟机信息: 公有DNS，
 这个就相当于这台虚拟机的公网地址，由于IP地址经常会变动，所以可以用公有DNS来指向IP地址，实现
一个动态的绑定
 那么这时我们可以ping通这个ip地址吗？来试一下，可以发现是ping不同的
  具体原因就是我们还未对虚拟机的安全策略配置，它是拒绝被ping的。我们进入安全组，编辑入栈规则，
 添加一条放通规则保存即可
 这时我们再进行ping测试，就发现可以ping通了
 三、连接虚拟主机  这里我们使用MobaXterm客户端连接虚拟机，其他工具像Xshell、Putty客户端均可，在新建会话中，将刚才</description>
    </item>
    
    <item>
      <title>RPC的简介和使用</title>
      <link>https://sin-coder.github.io/post/intro_rpc/</link>
      <pubDate>Wed, 19 Feb 2020 16:08:30 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/intro_rpc/</guid>
      <description>RPC的简介和使用 一、RPC出现的背景  当单台服务器无法满足用户的请求，就需要多台服务器联合起来构成一个集群共同对外提供一个服务，这
 也是我们常说的分布式。同时业务服务或随着产品需求的增多愈发变得臃肿，架构上必须进行服务的拆分，一
个完整的大型服务会分成许多独立的小服务，每个小服务都会有独立的进程去管理对外的提供服务，这就是我
们常说微服务
 当用户请求到来的时候，需要将其分散到多个服务去各自的处理，然后又需要将这些子服务的结果汇总
 起来呈现给用户。那么服务之间如何进行交互？这就是RPC要解决的问题
二、什么是RPC?  RPC（Remote Procedure Call）即远程过程调用，是分布式系统中一中常见的通信方法。当然除了RPC
 外，常见的多系统数据交互方案还有分布式消息队列、HTTP请求调用、数据库和分布式缓存。如下图
 其中可以明显的看到RPC和HTTP调用都是没有经过中间件的，它是端到端系统的直接数据交互。关于
 RPC和HTTP的主要区别接下来会阐述
三、RPC的应用  RPC是分布式系统进行通信的基础，像Nignx/Redis/MuSQL/Dubbo/Spark/Tensorflow都是基于RPC技术
 发展起来的，似乎每一个分布式的软件或者系统实现上都有它的身影
 Nginx和后端服务之间的交互本质上属于RPC数据的交互   Hadoop的文件系统HDFS中NameNode和多个DataNode之间通过二进制的RPC协议通讯   TensorFlow Cluster的RPC的通讯框架使用了Google自研的gRPC框架  四、HTTP和RPC的区别与联系  HTTP1.0协议时，HTTP的调用还只是短链接调用，一个请求来回之后连接就会关闭。HTTP1.1在HTTP
 1.0协议的基础上进行了改进，引入了KeepAlive特性可以保持HTTP连接长时间不会断开，以便在同一个连接
上进行多次连续的请求，使的HTTP进一步地接近了RPC
 当HTTP进化到2.0版本时，Google开源了一个建立在HTTP2.0协议上的RPC框架:gRPC, 这时的HTTP
 和RPC之间已经没有明显的界限了。
 所以我们可以将HTTP看成一种特殊的RPC
 五、广义上的RPC  在分布式系统中我们经常使用的数据库、消息队列和缓存本质上也可以看成RPC技术的一种应用，比如
 像下面的分布式数据库模型图：
 可以看出子系统和数据库时间的交互也是通过RPC进行的，只不过这里是三个子系统之间进行的交互，
 而且这里的数据库是具备主从复制功能的数据库。一般情况为了提升系统的性能，都会使用这种主从读写
分离的数据库。一个业务系统将数据写往主库，主库再将数据同步到从库，然后另一个业务子系统又从库
里将数据取出来</description>
    </item>
    
    <item>
      <title>分布式一致性</title>
      <link>https://sin-coder.github.io/post/consistency/</link>
      <pubDate>Mon, 17 Feb 2020 08:04:41 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/consistency/</guid>
      <description>分布式一致性概述 一、什么是分布式一致性 1.CAP 理论  对于分布式一致性，最直观的理解就是分布式系统中的不同节点不能产生矛盾。比较著名的理论就是
 CAP Theorem，即在一个分布式系统中，不能同时满足以下三点：一致性（Consistency）、可用性
（Availability）、分区容错性（Partition Tolerance）
 一致性（C）：在分布式系统中的所有数据备份，同一时刻是否有同样的值
 可用性（A）：在集群中一部分节点故障后，集群整体能否响应客户端的读写请求
 分区容忍性（P）：大多数的分布式系统都分布在多个子网络，每个网络都叫做一个区，分区容错的意思即是
    区间通信可能失败；比如一个分布式系统有5个节点，有3个在美国，有两个在中国，这就是两个区
它们之间可能无法通信
   CAP原则的核心就是只能实现AP、CP、AC，不会存在CAP，从上图中也可以看到典型的一些数据库
 产品也只是满足了CAP的部分特性
2.一致性模型  （1）弱一致性（最终一致性）
关于弱一致性，通俗的解释就是当一个节点向数据库写入数据时，其他的节点可能无法立即读到该数据，
 但是它们最终一定会读到该数据，下面是一些典型的实例
 DNS （Domain Name System）
 Gossip（Cassandra 的通讯协议）
   （2）强一致性
对于分布式系统的容错性最关注的问题就是数据不能存储在单个的节点上，一般的解决方案就是state
 machine replication（状态机复制共识算法）,具体的实现算法有以下几种：
 同步
 Paxos
 Raft（multi-paxos）
 ZAB（multi-paxos）
  二、强一致性算法 1.主从同步  主从同步复制的工作过程如下，Master接受写请求、Master复制日志到slave、Master等待，直到
 所有从库返回；但是这样存在一个问题：一个节点失败，Master阻塞，导致整个集群不可用，保证了
一致性，但是可用性却大大降低了
 解决上述问题的方法：多数派的算法，每次写都保证写入大于N/2个节点，每次读保证从大于N/2个</description>
    </item>
    
    <item>
      <title>Docker 镜像详解</title>
      <link>https://sin-coder.github.io/post/docker-image/</link>
      <pubDate>Sun, 02 Feb 2020 22:17:53 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/docker-image/</guid>
      <description>Docker 镜像详解  镜像是Docker三大核心概念中最为重要的。Docker运行容器前需要本地存在对应的镜像，如果镜像不
 存在，Docker会从Docker Hub中下载，当然用户也可以配置自定义的镜像仓库
关键问题  使用pull命令从Docker Hub中下载镜像到本地 查看本地已有的镜像信息、管理镜像标签 使用search命令在远端仓库进行搜索和过滤 删除镜像标签和镜像文件 创建用户定制的镜像并保存为外部文件 向Docker Hub仓库中推送自己的镜像s  一、获取镜像  docker [image] pull NAME[:TAG] #直接从Docker Hub镜像源来下载镜像  其中 [] 中的内容为可选项，NAME为镜像仓库名称（用来区分镜像），TAG为镜像的标签，一般用来
 表示版本信息，描述一个镜像需要“名称+标签”；如果不显式地指定TAG，则默认会选择latest标签，会下
载仓库中的最新镜像。不过，镜像的仓库名称中还应该添加仓库地址（即注册服务器）作为前缀，默认情
况下使用官方的Docker Hub服务（前缀可以忽略的），如果从非官方的仓库下载，则必须指定完整的仓库
地址
 从下载镜像的过程中，可以看到镜像文件一般是由若干层组成的，Docker下载中会获取并输出镜像
 的各层信息，每一层都有一个简写的唯一id。当不同的镜像包括相同的层时，本地仅存储了层的一份内
容，这样可以减少存储空间
 $ docker pull ubuntu Using default tag: latest latest: Pulling from library/ubuntu 5c939e3a4d10: Pull complete c63719cdbe7a: Pull complete 19a861ea6baf: Pull complete 651c9d2d6c4f: Pull complete Digest: sha256:8d31dad0c58f552e890d68bbfb735588b6b820a46e459672d96e585871acc110 Status: Downloaded newer image for ubuntu:latest docker.</description>
    </item>
    
    <item>
      <title>Python之美</title>
      <link>https://sin-coder.github.io/program/beauty/</link>
      <pubDate>Sat, 01 Feb 2020 16:08:30 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/program/beauty/</guid>
      <description>Python之美  新建一个Python文件，写入下面语句 &amp;quot;import this&amp;quot; 执行下看看发生了什么
终端会打出这样的信息：
 The Zen of Python, by Tim Peters
Beautiful is better than ugly.
Explicit is better than implicit.
Simple is better than complex.
Complex is better than complicated.
Flat is better than nested.
Sparse is better than dense.
Readability counts.
Special cases aren&#39;t special enough to break the rules.
Although practicality beats purity.
Errors should never pass silently.
Unless explicitly silenced.
In the face of ambiguity, refuse the temptation to guess.</description>
    </item>
    
    <item>
      <title>容器技术的前世今生</title>
      <link>https://sin-coder.github.io/post/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E7%9A%84%E5%8F%91%E5%B1%95/</link>
      <pubDate>Sat, 01 Feb 2020 03:23:01 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E7%9A%84%E5%8F%91%E5%B1%95/</guid>
      <description>容器技术的前世今生 概述  什么是容器，在Docker官方网站中，特地地对这个名词进行了定义，容器是一个标准化的软件单元。
 进一步的解释为容器是打包代码及其所有依赖项的软件的标准单元，它将软件和其运行环境隔离开来，
因此应用程序可以从一个计算环境快速可靠地运行到另一个计算环境。
 可以说Docker是当今最知名的容器平台之一，它于2013年开源，但是容器化和隔离的技术却有很长
 的历史，了解这部分的历史将有助于我们对容器技术的理解
容器发展简史  1979年，Unix7在开发过程中引入了Chroot Jail和Chroot系统调用，它允许用户将进程及其子进程与操作   系统的其余部分隔离开来。但是这种隔离未考虑安全机制，根进程可以轻松地退出chroot
那问题便来了，chroot jail是什么，jail为监狱的意思，似乎要把什么东西锁起来。在类UNIX的操作系统
 上，默认的根目录均为“ / ”，而chroot的作用就是改变正在运行的进程及它的子进程的根目录。例如，将某
个程序的根目录从原先的默认的系统根目录更改为“ /home/ ”，则这个/home目录就变成了这个程序的逻辑
根目录，与此同时，这个被修改了根目录环境的程序就不能再进入这个逻辑根目录之外的路径了。所以这就
相当于限制某个程序能进入的目录树，称为监狱也是情有可原了
 2000年，FreeBSD Jail被引入到FreeBSD OS中，旨在为简单的Chroot文件隔离带来更多的安全性，此   外FreeBSD还实现了将进程及其活动隔离到文件系统的特定视图中（不懂，暂时略过）
  2001年，Linux VServer被推出，它使用了类似chroot的机制与“安全上下文”及操作系统虚拟化来提供虚   拟化解决方案，相比于chroot进步了许多，允许在单个Linux发行版（VPS）上运行多个Linux的发行版
VPS (Virtual Private Servers) ：虚拟专用服务器
  2004年，Oracle推出了Solaris Containers，这是一个用于X86和SPARC处理器的Linux-VServer版本   Solaris Containers是由系统资源控制和“区域”提供的边界隔离组合而成
SPARC是一套RISC（精简指令集）架构
  2005年，OpenVZ推出，它和Linux-VServer一样，使用操作系统级虚拟化，但是这样有一定的限制，容器   共享相同的体系结构和内核版本，当客户需要不同于主机的内核版本时就有点力不从心了；而且
OpenVZ未将一些用于创建隔离的控制机制的补丁集成到内核中
  2007年，Google发布了CGroups，这是一种机制，它能限制和隔离一系列进程的资源使用（如：CPU、   内存、磁盘I/O和网络等），而且被集成到了Linux内核中</description>
    </item>
    
    <item>
      <title>Learn Docker with a picture</title>
      <link>https://sin-coder.github.io/post/docker%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Sat, 01 Feb 2020 03:22:01 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/docker%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/</guid>
      <description> 一张图入门Docker  关于Docker我们在云计算、虚拟化基础概念和容器技术的前世今生两篇文章中已经介绍过其应用的场景
 和优点，在本篇文章我们将学习Docker的一些基础概念和用法，话不多说，赶紧上图
Docker三大基础概念：镜像、容器和仓库 一、镜像（Image）  镜像就类似于我们使用Virtual Box或者VMware创建虚拟机之前需要下载的系统镜像文件，比如iso文件、
 img文件之类的都称为镜像文件。我们可以将Docker镜像理解为一个面向Docker引擎的只读模板，它自身即
包含了文件系统
 镜像与容器的关系就类似于印钞模板与钞票之间的关系，当然我们可以通过Dockerfile来制作自己的镜像。
 制作好的镜像可以被封装在一个盒子中（保存为tar文件），当需要在另一个环境中使用镜像时，只需将盒子
搬过去，重新取出（Load）镜像即可。当然这些比喻并不十分严格，只是帮助理解而已。
 通过版本管理和增量的文件系统，Docker提供了一套十分简单的机制来创建和更新现有的镜像。用户在
 对容器进行修改并提交（commit）后，重新运行依然可以保持这个变化
 有关Docker镜像的操作详解，请参看Docker入门学习--镜像
 二、容器（Container）  容器是从镜像创建的运行实例，可以将其启动（run）、开始、停止和删除，而且这些容器都是相互隔离
 的，互相不可见的。用户可以将容器看做一个简易版的Linux系统环境（包括root用户权限、进程空间、用户
空间和网络空间），以及运行在其中的应用程序打包而成的应用盒子
 镜像本身是可读的，容器从镜像启动的时候，Docker会在镜像的最上层创建一个可写层，镜像本身并没
 有发生改变
 有关Docker镜像的操作详解，请参看Docker入门学习--容器
 三、仓库（Repository）  Docker仓库类似于代码的仓库，是Docker集中存放镜像文件的场所。Docker利用仓库来管理镜像，这
 种设计理念与Git十分相似。用户可以直接从仓库中拉取（pull）镜像来供自己使用，也可以将自行制作镜像
并上传（pull）到仓库中，等到在另外一台机器上使用该镜像时，再pull下来即可
 Docker仓库和注册服务器（Registry）不是同一个概念，注册服务器是存放仓库的地方，其上往往存
 放着多个仓库。每个仓库集中存放某一类的镜像，这些镜像通过Tag进行区分。
 根据所存储镜像的公开与否，Docker仓库可以分为公开仓库和私有仓库。Docker Hub是目前最大的公
 开仓库；当然Docker也支持用户在本地的网络内创建 一个只能自己访问的仓库
 有关Docker镜像的操作详解，请参看Docker入门学习--仓库
当然Docker的内容远不止这些，接下来会 一 一 介绍
 </description>
    </item>
    
    <item>
      <title>云计算和虚拟化基础概念简介</title>
      <link>https://sin-coder.github.io/post/%E4%BA%91%E8%AE%A1%E7%AE%97%E5%92%8C%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/</link>
      <pubDate>Fri, 31 Jan 2020 19:21:17 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/%E4%BA%91%E8%AE%A1%E7%AE%97%E5%92%8C%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/</guid>
      <description>云计算和虚拟化基础概念 一、虚拟化  虚拟化技术是一种资源管理优化技术，它是将计算机的各种物理资源（CPU、内存、磁盘、网卡）
 等I/O设备予以抽象、转换，然后呈现出来一个可供分割并任意组合为一个或多个（虚拟）计算机的配置
环境。虚拟化技术打破了计算机内部实体结构间不可切割的障碍，使得用户以比原来更好的方式来应用
这些计算机的硬件资源。
 虚拟化是一个广义的术语，具体可细分为以下三种：
  平台虚拟化（Platform Virtualization）：操作系统级别的虚拟化
 资源虚拟化（Resouce Virtualization）：特定系统资源的虚拟化，如CPU、内存、存储或者网络等
 应用程序虚拟化（Applocation Virtualization) ：仿真、模拟和解释技术等，如Java虚拟机
  二、虚拟机  虚拟机是一台计算机转换为多台计算机的基于物理硬件的抽象。虚拟机管理程序允许多个虚拟机
 在单台计算机上运行，它可以创建虚拟化硬件，其中包括虚拟磁盘、虚拟网络接口、虚拟CPU等，同
时它还具有可以与此虚拟硬件通信的内核。每个虚拟机都包含着操作系统、应用程序，这些文件可能
占用数十GB的存储空间。管理程序可以进行托管，这就意味着它是可以在主机操作系统上运行的软件、
还可以运行在裸机上，即直接在机器硬件上运行，替换真实的操作系统。
 虚拟机可以分为系统虚拟机或者是过程虚拟机，我们通常所说的是系统虚拟机，它是通过主机硬件
 来模拟整个操作系统的；而“进程虚拟机”是用于模拟执行单个进程的编程环境的，Java虚拟机便是这样
三、容器 1.问题背景  在过去的几年中，让运维人员最为头疼就是需要为各种迥异的开发语言安装相应的运行环境。
 但是Docker的横空出现解决了这一问题，Docker提供了让开发工程师可以将应用和依赖封装到一
个可移植的容器中的能力，这种集装箱式的封装方式，让运维人员和开发人员都能够以Docker所
提供的镜像分发的标准化方式发布应用，打破了异构语言在团队中形成的壁垒
2.容器简介  容器是包含应用程序代码、配置和依赖关系的软件包；它是通过在操作系统级别进行虚拟
 化来使应用程序可移植，从而创建基于内核的隔离的封装系统。容器化运行的应用程序可以放在
任何地方，消除了依赖关系
 当然，作为独立的单元，容器能够在任何操作系统，如Linux、Mac、甚至像Windows这样
 的非UNIX系统中运行。容器还可充当标准化的工作或者计算单元，比如每个容器运行单个Web
服务器、数据库的分片或者单个Spark工作程序，只需要扩展容器的数量就能够便捷地扩展应用
 每个容器都有一个固定的资源配置（CPU、内存、线程数），并且扩展应用程序只需要扩展
 容器的数量即可。容器也是实现微服务架构的一个很好的工具，每个微服务只是一组协作容器
3.容器和虚拟机的区别  容器和虚拟机具有相似的资源隔离和分配优势，但具体功能不同，因为容器虚拟化了操作系统，
 而不是硬件；容器的创建和停止十分迅速，而且对自身资源的需求十分有限，远远低于虚拟机，很
很多时候直接把容器当做应用本身也是没有任何问题的。传统意义上如果说在一台主机上运行一百
个虚拟机那肯定是天方夜谭，可是一台主机运行上千个容器却已经成为了现实
 二者关键性能的区别如下表格：
  容器和虚拟机架构的区别：</description>
    </item>
    
    <item>
      <title>消息队列简介</title>
      <link>https://sin-coder.github.io/post/messagequ/</link>
      <pubDate>Tue, 28 Jan 2020 01:22:22 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/messagequ/</guid>
      <description>消息队列简介 一、消息队列简介 1.概述  消息是指在应用间传送数据，消息可以只包含文本字符串、或者包含嵌入式对象。
消息队列是一种应用程序对应用程序的通信方法。它是是生产者-消费者模型的一个典型的代表，一端往消息
 队列中不断地写入消息，而另一端则可以读取队列中的消息。这样发布者和接受者都不知道对方的存在。
 消息队列也可以简单理解为：把要传输的数据放在队列中
 2.消息获取模式  消费者获取消息时有两种模式，点对点模式和发布订阅模式
 （1）点对点模式  点对点模型通常是一个基于拉取或者轮询的消息传递模型，这种模型从队列中请求消息，而不是将消息推送
 到客户端。这种模式的特点是一对一，发送到队列的消息被一个且只有一个接受者接收处理，即使有多
个消息监听者也是如此，消息被收到后即可清除
 点对点模式的优点是队列发送数据和客户端接收数据的速度是相匹配的，缺点是客户端需要实时监控队列中
 是否有消息存在
（2）发布/订阅模式  发布订阅模型是一个基于推送的消息传送模型，该种模型下订阅者有临时订阅者和持久订阅者之分，临时订
 阅者只在主动监听主题时才接收消息；而持久订阅者则监听主题的所有消息，即使当前订阅者不可用，
处于离线状态。这种模型的特点是一对多，数据生产后，推送给所有的订阅者
 发布/订阅模式的优点是客户端不需要实时监控队列中是否有消息存在，缺点是队列发送数据的速度无法和多
 个客户端接收数据的速度是相匹配
二、消息队列作用  解耦：客户端与客户端之间或者客户端和服务器 之间不需要直接连接，而是通过中间件来进行连接。而且允许你    独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束
  冗余：消息队列可以对数据进行持久化（本地备份）直到它们已经被处理，这样就规避了数据的丢失。许多消息   队列均采用“插入-获取-删除”的范式，即在把一个消息从队列中删除之前，需要你的系统明确的指出该消息已
经被处理完毕
  峰值处理：可以组建集群，进而增大消息入队和处理的频率。在访问量剧增的情况下，应用仍然需要继续发挥作   用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的
浪费。消息队列基于它的可扩展性使其本身可以顶住突发的访问压力，而不会因为突发的超负荷的请求而使
系统完全崩溃
  数据可恢复：当系统的一部分组件失效时，不会影响到整个的系统 。消息队列降低了进程间的耦合度，即使一个   处理消息的进程挂掉，加入队列中的消息仍可在系统恢复后被处理
  顺序保证：消息队列本来就是排好序的，并且也能够保证数据按照特定的顺序来进行处理
 缓冲：消息队列可以控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况</description>
    </item>
    
    <item>
      <title>Git&amp;Github 学习笔记</title>
      <link>https://sin-coder.github.io/post/git/</link>
      <pubDate>Mon, 27 Jan 2020 00:52:28 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/git/</guid>
      <description>一、版本控制 1.版本控制工具的功能  协同修改：多人互不影响地修改服务器端的同一个文件
 数据备份：不仅要保存文件的当前状态，还能够保存每一个提交过的历史状态
 版本管理：在保存每一个版本的文件信息时，能够做到不保存重复的数据，节省存储空间，提高运行效率;
     SVN采取的是增量式管理的方式，Git采取了文件系统快照的方式
    权限控制：对团队中参与开发的人员进行权限控制，Git还可以对团队外开发者贡献的代码进行审核
 历史记录：查看修改人、修改时间、修改内容、日志信息；将本地文件恢复至某一个历史状态
 分支管理：允许开发团队在工作过程中多条生产线同时推进任务，提高效率
  2.常见版本控制工具  （1）集中式版本控制工具：CVS、SVN、VSS等
 集中式的版本控制中每个开发者是一个客户端，文件和版本信息存储在服务端，开发者们都直接与
 服务器进行交互，集中式的版本控制具有单点故障的问题
（2）分布式版本控制工具：Git、Mercurial、Bazaar等
 分布式版本控制相比于集中式最大的优点就是能够避免单点故障的问题
  二、Git 简介 1.Git的发展历史  Git是一个免费、开源的分布式版本控制工具。在2005年，由Linus基于C语言开发完成，开发的初衷是
 管理Linux社区中提交的代码, 而这位Linus正是是开发Linux系统内核的大神，它的个人语录也是我的座右铭
&amp;quot;Talk is cheap, Show me the Code&amp;quot;，少废话我只看代码。
2.Git的特性简介  从Git的图标中就可以看到分支是其最引以为傲的特点，实际上Git的优点还有很多
  大部分操作在本地完成版本控制，不需要联网
 对数据进行完整性保证，基于Hash算法
 尽可能添加数据而不是删除或者修改数据
 与Linux命令全面兼容，这个当然了，都是由Linus开发的
    3.Git 的结构  Git的本地结构图</description>
    </item>
    
    <item>
      <title>分布式系统学习笔记</title>
      <link>https://sin-coder.github.io/post/distri/</link>
      <pubDate>Mon, 27 Jan 2020 00:44:13 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/distri/</guid>
      <description>一、分布式系统概述 1.什么是分布式系统？ ​ 分布式系统主要由网络、分布式存储与分布式计算等部分构成的，分布式存储侧重于数据的读写存取及一致性等方面，而分布式计算则侧重于资源、任务的编排和调度
2.分布式系统的特点 ​ 没有强制性的中心控制、次级单位具有自治的特质、次级单位之间彼此高度链接、点对点之间的影响通过网络形成了非线性的因果关系
3.传统架构面临的难题: 系统的扩展 ​ 高并发的访问要求我们的后端系统架构弹性且可扩展
​ 三维扩展：
​ X轴扩展：水平复制，即在负载均衡服务器后增加多个Web服务器，
​ Y轴扩展：对数据库的扩展，即进行分库分表，分库是将关系紧密的表放在一台数据库服务器上，分表是因为一张表的数据太多，需要将一张表的数据通过hash放在不同的数据库服务器上
​ Z轴扩展：业务方向的扩展，才能将巨型应用分解为一组不同的服务，将应用进一步分解为微服务
​ 4.CAP定理
​ 在分布式系统中，系统的一致性(Consistency)、可用性（Availability）、分区容忍性(Partion tolerance)。这三者不能同时保证，由于网络通信的不确定性，分区的容忍性是必须要保证的，而且互联网应用比企业级应用更加偏向于保持可用性，通常用最终一致性代替传统事务的ACID强一致性
​
二、分布式计算 1.概述 ​ 分布式计算核心的思路就是系统架构无单点，让整个系统可以扩展。分布式计算环境下的节点分为有状态存储节点和无状态存储节点。
​ 无状态存储节点，不存储数据，请求分发可以采取很简单的随机算法或者是轮询的算法就可以了，如果需要增加机器，则只需要把对应的运算代码部署到一些机器上然后启动起来，引导流量到那些机器即可实现动态的扩展了。简单来说就是某台机器承担了某种角色后，能够快速的广播给需要这个角色提供服务的机器。
​ 而针对有状态节点，扩容难度较大，因为每台Server中均有数据，所以请求分发的算法不能够随机或者轮询，一般来说常见算法就是哈希或者使用Tree来做一层映射，增加机器时需要经历一个复杂的数据迁移过程------》自动化扩容和迁移的工具
2.数据处理的发展过程
GFS-------------》HDFS
BigTable--------》HBase
​ MapReduce----》MapReduce
​ （Hadoop技术栈）
MapReduce(离线处理)-----》Spark(高性能批处理技术)------》Storm(流处理)----》Flink
3.批处理（Batch Processing）与流处理（Stream Processing） 主要区别：每一条数据在到达时是被处理的（流处理），还是作为一组新数据的一部分稍后进行处理（批处理）
批处理：在批处理中新到达的数据元素被收集到一个组中，整个组在未来的时间内进行处理。至于何时处理每个组可以选择多种方式来确定，可以基于预定的时间间隔（如每隔5分钟）、或者在某些触发的条件下（只要包含5个元素/拥有超过1MB的数据）。传统的数据仓库和Hadoop就是专注于批处理的。批处理示意图如下：
缺点：具有延迟性、新数据的到达与该数据的处理之间的延迟将取决于直到下一批处理窗口的时间
流处理：流处理设计的目的是为了在数据到达时对其进行响应，这就要求它们实现一个由事件驱动的体系架构，也可以说是在系统的内部工作流在接收到数据后立即连续监视新数据和调度处理。
应用：Flink、Beam等都支持“流式处理优先，将批处理视为流式处理的特殊情况”，但是流式处理器的出现并没有让批处
​ 理器变得过时。因为纯流式处理系统在批处理工作负载时其实是非常慢的。
​ Apache Beam: 这样统一的API通常会根据数据是持续的（无界）、还是固定的（有界）将工作负载委托给不同的
​ 运行机制
​ Flink: 提供的流式API，可以处理有界或者无界的场景，同时任然提供了单独的DataSet API用于批处理
​
三、分布式调度 1.概述
经典资源调度器（Yarn）-----》数据调度（Data Placement）、资源任务调度（Resource Management）、计算调度（Application Manager）、本地微（自治）调度
2.资源调度</description>
    </item>
    
    <item>
      <title>同步/异步、阻塞/非阻塞辨析</title>
      <link>https://sin-coder.github.io/post/syn/</link>
      <pubDate>Sun, 26 Jan 2020 21:35:45 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/syn/</guid>
      <description>关键词：同步、异步、阻塞、非阻塞 相关概念：网络编程、进程与线程、I/O模型 一、问题背景  同步和异步，以及阻塞和非阻塞都是网络编程中经常遇到的概念，单看文字上的解释确实有些晦涩
 难懂。接下来我们将从一个通俗的例子出发阐述它们的区别与联系
二、一个简单的例子  隔壁老王爱好茶艺，每天都会煮开水来泡茶
 场景一：老王将水壶放在火上，坐在旁边等待水开 （同步阻塞）
 但是这样很耽搁时间，又不自由，效率很低，老王想换种方法
 场景二：老王将水壶放在火上，自已去隔壁了，每隔3分钟来看下水开没有 （同步非阻塞）
 但是这样依旧很麻烦，老王就买了一个自动报警的水壶
 场景三： 老王用新买的水壶进行烧水，坐在旁边等待水开 （异步阻塞）
 老王便想没有必要在水壶旁边坐着啊
 场景四： 老王新买的水壶放在火上，自己去隔壁了，等着报警再回来 （异步非阻塞）
 这种方式是最让老王省心的
 小结： 同步和异步关注的焦点在于我们是否需要不断地去看水壶是否开了，同步时，需要老王不断
地去轮询水壶是否开了，效率是比较低下的。而异步时，水壶告警提醒老王它开了
 阻塞和非阻塞 关注的焦点在于老王是否需要坐在水壶旁边等待，在水壶旁边等待老王就是阻
 塞的，去做其他事的老王就是非阻塞的
 这个例子可以帮助我们初步地理解同步异步、阻塞和非阻塞之间的联系和区别，但是如果详细
 的“追究”起来，还有许多未解释的细节
三、理论阐述 1.同步与异步  同步和异步（syn &amp;amp; asyn），描述的是在单线程中一次方法调用后，执行者是否具备主动通知
 的功能。同步时调用者会等到方法调用返回后才能继续后面的行为，异步时调用者不需要等到方法返回，
方法执行完毕后会主动通知调用者
2.阻塞和非阻塞  阻塞和非阻塞关注是调用者是否可以执行多个任务，描述的是调用者的多个线程是否可以同时执
 行。阻塞时，多个线程不能同时进行；非阻塞时，多个线程可以同时进行
3.二者的区别与联系  同步和阻塞完全是在单线程和多线程这两个维度上的概念，它们之间并没有强制的联系。但是从
 实际的意义来看确实有一定的绑定关系，比如对于单线程来说，不管是同步还是异步，肯定是阻塞的，非
阻塞只有多线程而且异步的时候才能发挥作用。
 回来继续看烧水的例子，老王在烧水的同时去隔壁，也即在烧水这个线程之中，又开启了去隔壁
 这个线程，所以使用异步非阻塞才更加有意义</description>
    </item>
    
    <item>
      <title>虚拟机的网络连接方式</title>
      <link>https://sin-coder.github.io/post/virtualnetwork/</link>
      <pubDate>Fri, 31 Jan 2020 12:00:31 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/virtualnetwork/</guid>
      <description> 虚拟机和主机的网络连接方式  最近在使用VirtualBox安装虚拟机组建集群时，总是会遇到各种网络问题，具体包括虚拟机
 之间的访问、虚拟机和主机之间的访问、虚拟机访问外网等，搞得晕头转向的，所以在此总结
一下虚拟机和主机之间的网络连接方式，以便更进一步的画出集群的网络拓扑图
 在VirtualBox的配置界面，可以看到虚拟机和主机间的网络连接方式有以下几种：网络地址
 转换（NAT）、NAT网络、桥接网卡、内部网络、仅主机（Host-only）网络、通用驱动等，下
面便一一详解
1. NAT模式  NAT方式借助网络地址转换的功能，通过宿主机所在的网络来访问互联网。此种方式下，虚拟
 机的网卡和物理网卡的网络不是在同一个网络中。虚拟机的网卡只是VirtualBox所提供的一个
虚拟网络，并不真实存在于网络中，所以宿主机无法ping通虚拟机，虚拟机彼此间也不通，但
是通过NAT虚拟机可以访问主机、和主机同网络的其他主机和互联网
 不过这里的网络连接方式中有网络地址转换（NAT）和NAT网络，这二者之间又有什么区别呢？
 其实这二者本质是相同的，不过后者是提前创建好的网络，在主界面的管理---&amp;gt;全局设定--&amp;gt;网络
我们可以提前设置一个NAT网络供虚拟机来选用
 总结起来，NAT模式可以节省网段中的IP地址，适合仅需自己使用的虚拟机配置
 2.桥接模式  桥接方式下，虚拟机需要桥接到宿主机的一块网卡上（有线或者无线均可），虚拟机和宿主机
 处于同一网段，真实存在于网络中。虚拟机之间可以互通、虚拟机和网络中的主机也可以互通、
只要主机能上网，虚拟机也可上网，但是这样占用网络中的IP地址
3.host-only模式  host-only模式应该是最为复杂的网络连接模式了，其他几种网络的连接方式通过这种模式的合
 适配置均可实现。我们可以理解为VirtualBox在主机中模拟出一张专供虚拟机使用的网卡，所
有的虚拟机都是连接到网卡上的，我们可以通过设置这张网卡来实现上网和其他功能。
 虚拟机和主机关系，默认不能相互访问，因为不属于同一个IP地址段。但是通过网卡共享、网卡
 桥接等，可以实现虚拟机和主机的相互访问
 虚拟机和虚拟机的关系，默认同一个网段中的虚拟机是可以相互访问的
 4.内部网络  内部网络模式，虚拟机与外网完全断开，虚拟机和主机之间无法相互访问只用于虚拟机
 与虚拟机之间的访问，但前提是在虚拟机在同一网络中，实际配置时两台虚拟机设置为
同一网络名称即可，如下图的配置中使用intnet
5.通用驱动  运行用于选择网卡驱动，实际上很少用到，可忽略
 6.未指定  相当于虚拟机有网卡，但是没有插线，只能ping自己才会通的
 </description>
    </item>
    
    <item>
      <title>基于Hugo框架搭建个人博客</title>
      <link>https://sin-coder.github.io/post/hugo/</link>
      <pubDate>Tue, 07 Jan 2020 14:08:20 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/hugo/</guid>
      <description>关键词：Hugo 、Git、Github、域名解析 概述 1.Hugo简介  Hugo是基于Go语言开发的静态网站生成器，简单、易用、快速部署，主要用于构建个人博客
 2.Git简介  Git是目前主流的分布式版本控制工具，有关Git的使用请查看Git的来龙去脉这篇文章
 3.Github简介  Github是在外网环境下的一个代码托管库，有关Github的介绍请查看开始玩起Github这篇文章
 具体过程 1.准备工作  下载Git并安装、配置环境变量   完成后在终端执行&amp;quot;git&amp;quot;命令来测试是否安装成功，有关git的安装请看Git的来龙去脉
  下载Hugo并安装、配置环境变量   完成后在终端执行&amp;quot;hugo version&amp;quot;命令来测试是否安装成功，终端提示如下信息表示安装成功
 C:\Users\Administrator&amp;gt;hugo version Hugo Static Site Generator v0.59.1-D5DAB232 windows/amd64 BuildDate: 2019-10-31T15:22:43Z   Hugo最好安装在英文目录下
下载时可能由于网络问题失败，附上Hugo、Git、主题m10c的下载包链接: 下载链接
  注册Github官网（已有账号请忽略）  2.生成个人站点 （1）在终端执行命令 C:\Users\Administrator&amp;gt;hugo new site E:\hugo\Sites\myblog   出现以下提示信息表示创建成功：
 C:\Users\Administrator&amp;gt;hugo new site E:\hugo\Sites\myblog Congratulations! Your new Hugo site is created in E:\hugo\Sites\myblog.</description>
    </item>
    
    <item>
      <title>高级数据结构(一) 字典树</title>
      <link>https://sin-coder.github.io/datastructure/trie/</link>
      <pubDate>Fri, 20 Mar 2020 12:41:41 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/datastructure/trie/</guid>
      <description> 高级数据结构(一) 字典树 </description>
    </item>
    
    <item>
      <title>Subseq</title>
      <link>https://sin-coder.github.io/leetcode/subseq/</link>
      <pubDate>Tue, 10 Mar 2020 19:19:05 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/leetcode/subseq/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Git向Github push时，连接超时</title>
      <link>https://sin-coder.github.io/post/git%E8%BF%9E%E6%8E%A5github%E5%A4%B1%E8%B4%A5/</link>
      <pubDate>Tue, 28 Jan 2020 17:10:44 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/git%E8%BF%9E%E6%8E%A5github%E5%A4%B1%E8%B4%A5/</guid>
      <description>Failed to connect to github.com port 443: Timed out 问题背景  最近在使用Git向Github提交时总是会出现以下报错：
 E:\hugo\Sites\blog\public&amp;gt;git push -u origin master fatal: unable to access &#39;https://github.com/sin-coder/sin-coder.github.io.git/&#39;: Failed to connect to github.com port 443: Timed out   而且还是偶尔出现的，特别让人心烦，目测为网络问题，折腾了许久在StackOverflow找到了答案
 问题原因  为了访问Github更加流畅，本地使用了Shadowsocks进行代理，可是Git并没有走代理访问
只需将Git配置为代理访问Github即可
 解决措施  打开Windows下的cmd命令行，在命令行中直接输入以下命令（已经配置Git的环境变量），或者
切换到Git的安装目录下执行命令（未配置环境变量）即可解决该问题
 E:\Program Files\Git\Git 的目录 2019/11/27 13:19 &amp;lt;DIR&amp;gt; . 2019/11/27 13:19 &amp;lt;DIR&amp;gt; .. 2019/11/27 13:18 &amp;lt;DIR&amp;gt; bin 2019/11/27 13:19 &amp;lt;DIR&amp;gt; cmd 2019/11/27 13:19 &amp;lt;DIR&amp;gt; dev 2019/11/27 13:19 &amp;lt;DIR&amp;gt; etc 2019/02/26 19:48 149,784 git-bash.</description>
    </item>
    
    <item>
      <title>Mapreduce</title>
      <link>https://sin-coder.github.io/post/mapreduce/</link>
      <pubDate>Mon, 27 Jan 2020 00:54:15 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/mapreduce/</guid>
      <description>1.什么是Map? 什么是Reduce?
Map是拆解 Reduce是组装 本治就是分治法
Input --&amp;gt; Split--&amp;gt;Map---&amp;gt;Shuffle（组装）---&amp;gt;Reduce ----&amp;gt;Finalize（高度并行的）
实现代码：
MapReduce如何实现统计单词出现的次数的
Map（string key, string value） #key : the id of a line #value: the content of the line for each word in value: OutputTemp(word,1) # Reduce 的过程 Reduce(string key,list valueList) #key : the name of a word #valueList: the appearance of this world int sum = 0 for value in valueList: sum+=value OutputFinal(key,sum)  MapReduce 如何实现倒排索引的？
MapReduce的整体结构？
总结：Map就是一个disassemble Reduce 就是一个assemble</description>
    </item>
    
    <item>
      <title>Bigtable</title>
      <link>https://sin-coder.github.io/post/bigtable/</link>
      <pubDate>Mon, 27 Jan 2020 00:53:53 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/bigtable/</guid>
      <description>1.如何在文件内进行快速查询？
关键点： 从File 到 Table Table = a list of sorted 
2.如何保存一个很大的表？
关键点： A table = a list of tables (小表)
A tablet = a list of sorted 
使用MetaData的形式保存每一个小表的位置
3.如何保存一个超大的表？
关键点：A table = a list of tablets （小表）
​ A tablet = a list of SSTables （小小表）
​ A SSTables = a list of sorted 
4.如何向表中写数据？
关键点：通过写入memTable（内存表）来加速
A tablet = memTable + a list of SSTables
5.内存表过大怎么办？如何避免内存丢失数据？</description>
    </item>
    
    <item>
      <title>Google File System</title>
      <link>https://sin-coder.github.io/post/gfs/</link>
      <pubDate>Mon, 27 Jan 2020 00:53:42 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/gfs/</guid>
      <description>Google File System 一、概述 Google的三篇论文：Google File System 、BigTable 、MapReduce的发表彻底拉开了云计算时代的序幕，同时这三篇论文也是想要入门云计算的学习人员必读的。最近读了这三篇论文，再参考了一些资料后写下自己的总结
HDFS 、HBase 、MapReduce
 GFS BigTable MapReducd  Google系统整体的架构图如下
GFS系统的优点：高可用性、自动负载均衡
系统的结构：文件系统（GFS）、数据模型（Bigtable）、算法（MapReduce）、应用
在本篇文章中我们着重去描述GFS
二、GFS系统的设计 1.设计思路
​ （1）组件失效是一种常态，而不是意外；因此持续的监控、错误的侦测、灾难冗余等机制必须集成在GFS
​ （2）存储的文件非常巨大，基本上为TB级的，I/O操作和Block、Chunk的尺寸都需要规划
​ （3）对文件的修改以在文件尾部追加数据为主，数据的追加对系统性能有重要的影响
​ （4）应用程序和文件系统的API协同设计可以大幅度提高系统的灵活性
2.系统的工作负载分析
3.GFS系统架构
三、系统工作原理 设计原则：最小化所有的操作和Master节点的交互
系统具体的工作过程：
3.文件系统的操作
4.Master节点的操作
名称空间管理和锁
副本的位置
创建、重新复制、重新负载均衡、垃圾回收、过期失效的副本检测
5.容错和诊断
高可用性、数据完整性、诊断工具
四、总结 3.Linux文件系统工作原理：
​ 保存一个小文件
​ 保存的每一个文件都有一个元数据Metadata，其中包括filename文件信息 文件名 创建时间 文件大小 index组成文件的每一个Block的索引 关键点为1block = 1024 Byte
​ 保存一个大文件：
​ 关键点为chunk : 1chunk = 64MB =64*1024 =65536 blocks
​ 优点：减少元数据 减少流量 缺点：小文件会浪费较多空间</description>
    </item>
    
    <item>
      <title>Go语言学习总结（一）</title>
      <link>https://sin-coder.github.io/post/go/</link>
      <pubDate>Mon, 27 Jan 2020 00:53:21 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/go/</guid>
      <description>Go语言学习总结（一） 一、Go语言简介 1. Go语言用途 ​ 搭载Web服务器，存储集群或类似用途的巨型中央服务器的系统编程语言
​ 在高性能的分布式系统领域，Go语言比其他语言有着更高的开发效率
2. Go语言特点 ​ 自动垃圾回收、丰富的内置类型、函数多返回值、错误处理、数组安全
​ 匿名函数和闭包、类型和接口、并发编程、反射、语言交互性等
3. 设计思想 ​ 目前主流的编程思想主要有面向对象编程、面向过程编程，但是Go语言在设计的过程中吸收了一些
​ 小众的编程哲学思想，比如函数式编程思想（支持匿名函数与闭包）， 面向消息编程思想（支持 goroutine
​ 和通道），因此Go推荐使用消息而不是共享内存来进行并发编程
二、Go语言基础语法 1. 程序组成元素 （1）包声明 ​ 源文件中非注释的第一行指明这个文件属于哪个包，如package main, package main表示一个可独立执行的
​ 程序，Go程序是通过package来进行组织的，只有package名称为main的源码文件可以包含main函数
（2）引入包 ​ 导入程序所要使用的包 fmt包格式化的输入输出
​ 导入包时可以通过import关键字来单个导入，也可以同时导入多个，如：
//单个导入 import &amp;quot;fmt&amp;quot; import &amp;quot;io&amp;quot; //同时导入多个 import ( &amp;quot;fmt&amp;quot; &amp;quot;math&amp;quot; )  ​ 文件名与包名没有直接关系、同一个文件夹下只能有一个包名，否则编译报错
​ 导入包时一般为 import &amp;quot;项目名/包名&amp;quot;
​ 调用函数时则是通过PackageName.FunctionName() 来进行调用
（3）函数 ​ fun main()是程序开始执行的函数，该函数也是每一个可执行程序所必须的，每个函数后都会有{}，但是 &amp;quot; { &amp;quot;</description>
    </item>
    
    <item>
      <title>Python高级容器数据结构</title>
      <link>https://sin-coder.github.io/program/pycollect/</link>
      <pubDate>Sat, 28 Dec 2019 20:44:56 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/program/pycollect/</guid>
      <description>Python高级容器数据结构  Python内置了4种数据类型，包括了list、tuple、set、dict，可以满足绝大部分程序使用的需求，但是在
 某些场景下使用这些数据结构的效率是比较低的，比如set和dict的无序、list的插入和删除操作复杂度较高，
这时Python内建的collections模块就派上用场了，下面分别介绍几种典型的高级数据结构
一、orderedDict  在Python3.6之前的字典是无序的，orderedDict解决了这一问题，它是可以记住字典插入的顺序。那么
 在3.6版本之后它是不是就没用了呢？不是的，orderedDict仍有它自己独特的一些特性是dict所无法达到的。
 经典的dict非常擅长映射操作，而orderedDict比较擅长重新排序操作，适合用于实现LRU算法，下面介
 绍其典型的方法
 popitem（last = True）： 有序字典的popitem（）方法移除并返回一个（key,value）键值对；如果last值为真   则按照后进先出的顺序返回键值对；否则就按照先进先出的顺序返回键值对
  move_to_end（key，last = True）： 将key移动到有序字典的任一端，如果last值为真，则将元素移至末尾，   否则则将元素移至开头，如果key不存在将会触发keyError
  具有reversed()的方法，可以返回一个反向的迭代器
 注意，orderedDict还有一个特性，如果新条目覆盖现有的条目，则原始插入位置将更改并移至末尾
   基于这些特性我们可以非常方便的实现一个LRU
 class LRU(OrderedDict): def __init__(self,maxsize = 128): self.maxsize = maxsize def __getitem__(self,key): if super().__getitem__(key): self.move_to_end(key) return value else: return None def __setitem__(self,key,value): super().__setitem__(key,value) if len(self) &amp;gt; self.maxsize: #获取开头的元素 iter()函数用来生成一个迭代器，next()返回迭代器中的下一项 oldest = next(iter(self)) del self[oldest] #删除开头的对象  二、deque  Python中的list可以用作队列，也可以被用作栈，但是它底层是基于数组实现的，查找容易，但是插入和删</description>
    </item>
    
    <item>
      <title>Python中的魔法方法</title>
      <link>https://sin-coder.github.io/program/magic/</link>
      <pubDate>Tue, 24 Dec 2019 21:14:28 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/program/magic/</guid>
      <description>Python中的魔法方法 一、什么是Python的魔法方法？  魔法方法就是Python的内置方法，不需要主动调用，存在的目的就是给Python的解释器进行调用，几乎每个
 魔法方法都有一个对应的内置函数或者运算符，它们经常是使用两个下划线包围来命名的，最为常见的就是
__ init __方法了。总的来说魔法方法就是让我们对类添加魔法的特殊方法（说跟没有说一样）
二、常见的魔法方法 1.构造方法  最为常用的魔法方法就是__ init __方法了，我们可以使用它来指明一个对象初始化的行为。实际上，
 当我们再实例化对象时，__ init __方法并不是第一个被调用的方法。事实上应该是new方法，当这个对
象的生命周期结束的时候，__ del __方法会被调用。下面具体阐述
 （1）__ new __(cls,[....])
__ new __是对象实例化第一个调用的方法，它只取下cls参数并把其他的参数传递给init方法，它很少使用
（2）__ init __(self,[....])
这是类的初始化方法，它能获取任何传给构造器的参数，这个方法在类的定义中使用到的是最多的
（3）__ del __(self)
new和init都是对象的构造器，__ del __是对象的销毁器，它不是实现了语句del x,而是定义了对象被垃圾
 回收时的行为。当对象需要销毁做一些处理的时候这个方法很有用，比如socket对象、文件对象。但是当
Python解释器退出但对象仍然存活的时候，__ del __并不会执行，所以要及时地手工清理对象
 下面是一个示例：
 from os.path import join class FileObject: #文件对象的装饰类，用来保证文件被删除时能够正确关闭 def __init__(self,filepath = &#39;~&#39;,filename = &#39;sample.txt&#39;): self.file = open(join(filepath,filename),&#39;r+&#39;) def __del__(self): self.file.close() del self.file  2.</description>
    </item>
    
    <item>
      <title>编辑距离</title>
      <link>https://sin-coder.github.io/leetcode/distance/</link>
      <pubDate>Mon, 23 Dec 2019 22:26:15 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/leetcode/distance/</guid>
      <description>从编辑距离问题学字符串的动态规划  解决两个字符串的动态规划问题，一般都是使用两个指针分别指向两个字符串的最后，然后一步一步地
 向前走，不断地缩小问题的规模，进而找出最优解，下面先看题吧：
一、问题描述  Leetcode 72 编辑距离 ，题目简述如下
两个单词 word1 和 word2，计算出将 word1 转换成 word2 所使用的最少操作数步数，你可以对一个单
 词进行如下三种操作：
 插入一个字符
 删除一个字符
 替换一个字符
   我想大部分人看到这个问题后，思考的方式和我是一样的，就是如何在word1中找到尽可能多的出现在
 word2中的字符，并尽可能保留住；但实际上单是找到重复的字符还是不够的，我们还必须关注它们出现的
顺序，顺序不一样该删就删，毫不留情。实际上我们所关注的只是步数，删除、插入和替换都是一样的
 其实这个问题已经露出了动态规划的马脚了，因为它给了我们三个选择，就是在比较两个字符串的字母
 时如何选择策略，那当然是哪种策略的转化步数最小就是哪种了，这不就是在寻找最优子问题嘛
二、算法思想的描述  1.初始化两个指针分别指向两个字符串的末尾
2.比较两个指针所指字符，如果字符相同，说明这个位置对编辑距离的结果不会造成影响
如果不相同，那么就选择3种策略中，所需转化步数最小的那种
3.还会出现两种基本的情况：
  指针已经遍历完word1时，word2还没有被遍历完，只能不断地向word1中插入元素了
 指针已经遍历完word2时，word1还没有被遍历完，只能不断地删除word1中的元素了
    三、代码实现  我们假设 i , j指针分别指向word1和word2中的最后一个字符，代码可以这样写的
 public int minDistance(String word1,String word2){ //分别初始化指向最后一个索引 return dp(word1.length() - 1,word2.</description>
    </item>
    
    <item>
      <title>Java面向对象之接口</title>
      <link>https://sin-coder.github.io/program/javaintf/</link>
      <pubDate>Sun, 22 Dec 2019 21:14:28 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/program/javaintf/</guid>
      <description>Java面向对象和接口  在Java编程语言中接口是一个抽象类型，是抽象方法的结合，一个类通过继承接口的方法来继承接口的
 抽象方法；除非实现接口的类是抽象类，否则该类要实现接口中的所有方法；接口无法被实例化，但是可以
被实现；在Java中，接口类型可以用来声明一个变量
一、接口和类的异同 1.接口和类的相似点  一个接口可以有多个方法
 接口文件保存在.java文件中，文件名使用接口名
 接口的字节码文件保存在.class文件中
 接口相应的字节码文件必须在与包名称匹配的目录中
  2.接口和类的主要区别  接口不能用于实例化对象
 接口没有构造方法
 接口的所有方法必须是抽象方法
 接口不能包含成员变量，除了static和final变量
 接口可以被类继承或者实现
  3.接口特性  接口中的方法会被隐式地指定为public abstract
 接口可以含有变量，但是会被隐式地指定为public static final
 接口中的方法是不能在接口中实现的，只能由实现接口的类来实现
  二、接口的操作 1.接口的声明 [可见度] interface 接口名称 [extends 其他的接口名]{ //声明变量 //声明方法 }  2.接口的实现  类使用implements关键字来实现接口，类声明中，implements关键字放在class声明后
 ...implements 接口名称[,其他接口名称,.....]   类实现接口的时候必须实现接口的所有方法，否则就要被定义为抽象类
重写接口中声明的方法时，有以下要求
  类实现接口中的方法时，不能抛出强制性的异常，只能在接口中，或者继承接口的抽象类中抛出
 类在重写方法时要保持一致的方法名，并且应该保持相同或者相兼容的返回值类型</description>
    </item>
    
    <item>
      <title>Java中的包(Package)</title>
      <link>https://sin-coder.github.io/program/package/</link>
      <pubDate>Sat, 21 Dec 2019 21:14:28 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/program/package/</guid>
      <description>Java中的包（Package） 一、Java中包的作用  在Java中为了更好的组织类，提供了包机制，可以看成是区别类名的命名空间，主要作用如下：
  把功能相似或者相关的类或接口组织在同一个包中，方便类的查找和使用
 包采用了类似文件夹一样的树形目录的存储方式，同一个包中类的名字是不同的，不同包中类的名字可以是
   相同的，当同时调用不同包中相同类名的类时，应该加上包名加以区分，避免冲突
  包限定了访问权限，拥有包访问权限的类才能访问某个包中的类  二、包的使用 1.包语句的格式  包语句的语法格式为
 package pkg1[.pkg2[.pkg3]] //示例如下 package net.java.util; //注意包声明语句后有分号 public class Test{} //那么这个文件的保存路径应该是这样的：net/java/util/Test.java   一个包可以定义为一组相互联系的类型，为这些类型提供访问保护和命名空间管理的功能；在实际的应用
 中，可以将自己完成的一组类或者接口等打包，方便管理和使用
2.创建包  包声明应该在源文件的第一行，每个源文件只能有一个包的声明，这个文件中的每个类型都应用于它；如
 果一个源文件没有包的声明，那么其中的类都将被放到一个无名的包中，创建包的包名应该最好使用小写的
3.使用包  为了能够使用某一个包的成员，需要在Java程序中明确导入该包，使用import语句即可完成；
 在Java源文件中的import语句应位于package语句之后，所有类的定义之前；格式如下：
import package1[.package2...](classname|*);   如果在一个包中一个类想要使用本包中的任何一个类，包名是可以忽略的
值得注意的是import是导入包所包含的类，而不能导入包，通常情况下，我们也不是只导入包中的某个类
 而是导入包下所有的类；Java编译器默认为所有的Java程序导入了JDK中java.lang包中的所有类，其中定义了
一些常用的类，如Objetc、Math等，因此我们可以直接使用这些类而不必显示导入，当使用其他类时必须导入
 并且import实际上导入的是每一个类的.class文件，并不是.java类型的文件
 4.Java中类的搜索路径  在安装JDK时，我们已经设置了环境变量CLASSPATH，在Windos下的cmd中可以通过set命令查看
 #一个CLASSPATH可能包含好几个路径，多路径应该使用分割符进行分开 C:\Users\Administrator&amp;gt;set CLASSPATH CLASSPATH=.;C:\Program Files\Java\jdk1.8.0_91\lib; C:\Program Files\Java\jdk1.</description>
    </item>
    
    <item>
      <title>Java面向对象之抽象类</title>
      <link>https://sin-coder.github.io/program/abstract/</link>
      <pubDate>Sat, 21 Dec 2019 21:14:28 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/program/abstract/</guid>
      <description> Java面向对象之抽象类  面向对象的设计原因中所有的对象都是通过类来进行描绘的，但是并不是所有的类都是用来描述对象的，
 如果一个类中没有包含足够的信息来描绘一个具体的对象，这样的就是抽象类
 抽象类正常类最大的区别就是不能实例化对象，所以抽象类必须被继承，才能被使用；但是抽象类的其
 它功能如：成员变量、成员方法和构造方法依然存在
一、抽象类的定义和使用  在Java语言中使用abstract class来定义抽象类，而且只能通过其他类来继承抽象类
 //文件名为Test.java public abstract class Test{} //文件名为smallTest public class smallTest extends Test{}  二、抽象方法  抽象方法必须是一个特别的成员方法，该方法的具体实现是由它的子类确定的，那么可以在父类中声明
 该方法是一个抽象方法；而且抽象方法所在的类一定是抽象类；
 abstract关键词同样可以用来声明抽象方法，抽象方法只包含一个方法名而没有方法体；抽象方法没有定
 义，方法名后面直接跟上一个分号，而不是花括号
public abstract class Employee{ public abstract int getMsg();//抽象方法 }   任何子类必须重写父类的抽象方法，或者声明自身是一个抽象类；
 三、其他规定  抽象类中不一定包含抽象方法，但是有抽象方法的类必定是抽象类
 抽象类中的抽象方法只是声明，不包含方法体，即不给出方法的具体实现
 构造方法和类方法（用static方法修饰的方法）不能声明为抽象的方法
  </description>
    </item>
    
    <item>
      <title>数据结构学习心得</title>
      <link>https://sin-coder.github.io/datastructure/summay/</link>
      <pubDate>Sat, 21 Dec 2019 14:01:10 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/datastructure/summay/</guid>
      <description>数据结构学习心得  学习数据结构和算法也有段时间了， 在此记录自己学习的过程，以及心得和体会
我不是计算机专业的，没有学过对应的课程，但我知道数据结构与算法是一个编程人员的核心能力。很
 长时间以来，我都因为自己不会这个而怀疑自己到底会不会编程。当然，从过往的经历来看，好像开发一个
实际的APP或者Web应用也没有用到很多相关的知识，我就一直在逃避学习，直到一次头条的面试彻底让我
清醒了过来
一、迷雾重重，被现实吊打  相比于数据结构来说，其他计算机的核心课程显然我要更熟悉一些，而且我也不觉得精通数据结构的人
 学习其他知识不吃力。但是从实际的面试中，遇到数据结构我就基本是卡住了，以至于有些时候似乎觉得
面试就无法聊下去了
 终于逃离了自己的舒适圈，开启一条煎熬之路，但我也很明确自己的目的，提高自己的逻辑思维和在面
 试中不会因为它被卡主，至于那些搞竞赛的同学我就只能投去羡慕的眼神了
 一开始，我找到了几个计算机的同学，问了一些课程的用书和一些推荐的学习资源。于是就从严蔚敏奶
 奶的那本紫皮书开始了，可以说看的一脸懵逼，找到了学习高数的那种感觉。而且书里面给出的都是一些伪
算法，没有具体的实现，感觉非常的苦恼。后来，又多方打听找到了高一凡大神写的数据结构算法实现，还
有点C/C++基础的我比着人家的思路开始把一些常用的数据结构实现了一遍，当然在这个过程中，自己也在
看B站上郝斌老师的视频课程，这一段时间总算把数组和链表给搞懂了，也认识了一些像队列、栈等一些更
级的数据结构
二、初现水面，站在数组和链表上眺望远方  其实这个时候，我还只是在学习数据结构，没有一点用它们解决实际问题的意识，似乎只是一些需要记住
 的知识点。但是从自己不断遇到的问题来看，如果只用数组和链表去存取数据的话，问题的解决方案会很麻烦
，但是也是可以解决的，所以应该得出第一个结论：
   数组和链表是数据结构中最底层的抽象
  为什么呢？数组和链表对于数据存储的结构逻辑和实际的物理逻辑是相关联的，那么后来学习到的队列、
 栈、哈希表、堆、树、图都跑哪去了呢？它们都可看做是数组或者链表的上层建筑，换用计算机语言来描述
就是对数组和链表进行封装。如果你需要的话，也可以自行封装，这就是我们常说的数据结构的设计。多样
化的数据结构本质上没什么差别，都是对数组和链表的不同操作而已
 很多高级的数据结构都可以用数组或链表来实现，但是具体用哪一种，就要从性能上考虑了，所以这个
 时候我又学习到了两个新的名词，时间复杂度和空间复杂度，从后来学习的情况来看，它们占据了数据结构
与算法的半壁江山。那就从数组和链表的特点来引入这复杂度的两个概念。
 数组在物理空间上是紧凑连续存储的，可以随机访问，通过索引很快的找到对应元素，而且数组中数据
 在物理空间中的密度是比较高的。但是正是因为是连续存储的，物理上的空间必须一次给够；如果不够的
话就要考虑扩容的问题，扩容时需要将原来的数据搬家到一个新的空间，从整体来说这样是比较复杂的。
此外，如果你想要在数组中进行插入或者删除，会惊动后面的许多元素，这样也是比较费劲的
 再来看看链表，似乎链表和数组是优劣互补的，比如数组元素连续，链表元素不连续，靠指针来保持自
 己前后同伴的关系；数组集中存储，链表则是分散存储，见缝插针，不会存在整体扩容的问题；当改动一个
元素时只会影响前后元素，不会像数组那样大动干戈。但是相比于数组的随机访问，链表则就显得吃力了许
多，它必须一个一个地找，同时由于多存储了地址，它占用的空间会更大
 所以复杂度最直观的理解就是对于数据结构的操作是否麻烦
 三、拨开乌云晴天日   应该用数组还是链表取决于数据结构具体的应用场景
 下面举一些典型的使用数组或者链表实现的数据结构</description>
    </item>
    
    <item>
      <title>技术博客分类目录</title>
      <link>https://sin-coder.github.io/category/content/</link>
      <pubDate>Fri, 20 Dec 2019 21:48:36 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/category/content/</guid>
      <description> 计算机网络  应用层协议、二层交换、三层路由、TCP/UDP，网络编程，运维  操作系统 数据结构与算法  leetcode、剑指offer；贪心、回溯、动态规划、分治、递归；树，图，堆、队列、栈、链表、数组；  数据库技术  MySQL、Redis、MongoDB、TiDB  编程语言  Python、Java、Go  Linux  Shell、运维  云计算  Docker、K8s、云原生  分布式  6.824、分布式数据库、分布式消息队列、分布式计算  个人随笔  技术之路、个人经历、生活体会  </description>
    </item>
    
    <item>
      <title>Python中的面向对象</title>
      <link>https://sin-coder.github.io/program/oop/</link>
      <pubDate>Fri, 20 Dec 2019 21:14:28 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/program/oop/</guid>
      <description>Python中的面向对象  说起面向对象，大家都不陌生，常用的Java就是一门面向对象的语言，但是很少人会觉得Python是一门
 面向对象的语言，习惯使用Python的人更会觉得它有点像面向过程的语言，毕竟那流程化的操作让人觉得
是从哪里冒出来的对象啊，今天是时候为Python平反了，Python和Java都是面向对象的语言
 但是我们所说的面向对象通常指的是编程的一种设计思想，更加准确的说应该是Python和Java都是支持
 面向对象的语言，而且Python和Java都不是纯碎的面向对象，当然我们也不必过于纠结什么是纯碎。这篇
讲解一些Python中面向对象的一些特性
一、面向对象的主要特性  在面向对象编程中，函数和变量被进一步的封装成类，类是程序的基本元素，类和类的实例是面向对象
 的核心概念，面向对象的主要编程框架如下：
 导入各种外部库
 设计各种全局变量
 决定你要的类
 给每个类提供完整的一组操作
 明确的使用继承来表现不同类的特点
 根据需要决定是否要写一个mian函数作为程序入口
   面向对象中一些基础的概念是多态、继承、封装、抽象、类、对象、实例、方法、重载，下面对一些主要
 的概念稍作解释
 类变量：所有实例公有的变量，类变量定义在类中，但是在方法体之外
 实例变量：是实例本身所拥有的变量，每个实例变量在内存都是不一样的
 静态方法：不需要实例化就可以由类指向的方法
 类方法：类方法是将类本身作为对象进行操作的方法
 重写：从父类继承的方法不能满足子类的需求，这个过程称为override
 封装：将内部实现包装起来，对外透明
 继承：子类继承父类的变量和方法
 多态：根据对象类型的不同以不同的方式进行处理
  二、类与对象 1.类和对象的创建  Python中类和对象的创建是这样进行的
 class test: classVar = &amp;quot;Test&amp;quot; #类变量 def __init__(self,para1,para2): #理解为构造函数 self.para1 = para1 self.</description>
    </item>
    
    <item>
      <title>Java面向对象总结</title>
      <link>https://sin-coder.github.io/program/javaoop/</link>
      <pubDate>Fri, 20 Dec 2019 00:14:28 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/program/javaoop/</guid>
      <description>Java面向对象总结 一、类和对象  Java中的类可以包含局部变量、成员变量、类变量
  局部变量：在方法、构造方法中定义的变量
 成员变量：定义在类中，方法体之外的变量。可以被类中的各种方法使用
 类变量：定义在各种类中，方法体之外。必须声明为static类型
   构造方法 : 如果没有显式地为类定义构造方法，Java编译器会为该类提供一个默认的构造方法。在创
 建一个对象的时候，至少要调用一个构造方法
 Java中import语句执行的过程，import语句主要是提供一个合理的路径，使得编译器能够找到某个类
Java中的类有若干访问级别：抽象类、final类、内部类、匿名类
Java中强制要求类名和文件名相同，是因为在引用其他类的时候无需显式的声明，在编译时会根据类
 名去寻找同名文件
 Java中包的作用就是防止名字相同的类产生冲突。编译器在编译时直接根据package指定的信息直接
 将生成的class文件生成到对应文件的目录中，比如package com.util.Test，编译器就将生成的.java文件
放于./com/util/Test/这个目录下
 import的作用是为了简化使用package之后的实例化的代码，就是将new java.net.Socket()简化成
 new Socket（）
 一个Java文件中只能包含一个Public的类
this是指向对象本身的指针，super是指向父类对象的一个指针
new关键字的一个作用，为对象分配内存空间、引起对象构造方法的调用，为对象返回一个引用
对象和引用的区别，对象是具体的一个实例，使用new创建一个对象时，是在堆内存中开辟一块空间
 引用名称存放的对象的地址
二、Java中的继承  在Java中可以通过extends关键字可以声明一个类是从另外一个类继承而来的
Java中不支持多继承，但是支持多重继承
子类可以拥有父类非private的属性和方法，子类可以用自己的方式实现父类的方法
Java中所有的类都是继承于java.lang.Object这个祖先类，如果一个类没有显示继承，则默认情况
 下继承Object 祖先类
 implements关键字可以变相的使Java具有多继承的特性，同时实现多个接口
final关键字声明类可以把类定义为不能继承的，即是最终类。或者用于修饰方法，该方法不能被子类重写
final修饰类中的属性或者变量时，无论是基本类型还是引用类型
Java文件被编译成class文件时，在子类的所有构造函数中的第一行会默认添加super()语句，在执行子类
 的构造函数前，总是会先执行父类的构造函数，执行父类构造函数的语句只能放在函数内语句的首句，不然
报错；如果父类不含默认的构造函数，子类中的super()语句就会执行失败
 Object类是所有类的根父类，可以用于参数的传递，当你不清楚函数需要的参数是什么类型的，可以使
 用Object类来代替，Object可以代替任何类
三、重写和重载 1.重写（Override）  重写是子类对父类的允许访问的方法的实现过程进行重新编写，返回值和参数都不能变</description>
    </item>
    
    <item>
      <title>技术成长之路</title>
      <link>https://sin-coder.github.io/personal/introduce/</link>
      <pubDate>Wed, 18 Dec 2019 21:47:34 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/personal/introduce/</guid>
      <description>一个半路出家的怪孩子是如何折腾计算机的：
 那一年，我的C++考了97分，我觉得计算机的世界不过如此。呵呵，年幼无知
 那一年，为了刷网课时界面不会锁住，我想着用Java写一个按键精灵，再也不用守在那按鼠标
 那一年，我看到20行的C代码用一行Python就完成时，毫不犹豫地上了Python的贼船
 那一年，在学长的帮助下，我开始进军Django，独立地完成了自己第一个Web应用
 那一年，感叹于Bootstrap的强大，甚至想一心做前端；后来发现自己不会审美
 那一年，阴差阳错地被送去做网工，第一次走出大学的象牙塔，不能再以学生自居
 那一年，通宵呆在服务器轰鸣的机房，即使是炎热的夏天依然被冻的无处可逃
 那一年，为了不暴露自己是实习生，脸不红心不跳的撒慌已经工作了一年，真实年龄比身份证大3岁
 那一年，看看窗外的广州塔是多么繁华，再看看眼前的网线是如此的邋遢
  

 那一年，不会数据结构的我在面试中被虐得体无完肤，从此下定决心痛改前非
 那一天，我又在这篇文章中多写了一行</description>
    </item>
    
    <item>
      <title>为什么要用ConcurrentHashMap</title>
      <link>https://sin-coder.github.io/datastructure/concurrent/</link>
      <pubDate>Tue, 17 Dec 2019 16:05:44 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/datastructure/concurrent/</guid>
      <description>为什么要用ConcurrentHashMap 一、HashMap的线程安全问题 1、线程安全  在我刚开始接触并发的时候，对于线程安全这个词语很不理解，线程有什么安全性可言呢！后来慢慢地发
 现线程安全实际上指的是线程的内存安全，多个线程在对共享数据进行操作时，可能会出现数据不一致的情况
 所以HashMap的线程安全问题，我们可以理解为多个线程在HashMap这种数据结构中的数据进行操作可能
 会出现的数据不一致的情况；显然HashMap不是线程安全的，在并发插入元素时，有可能出现环形链表，让下
一次读操作出现死循环，下面会进行详细的阐述
2、ReHash的问题  HashMap的容量是有限的，当经过多次元素插入时，HashMap达到一定的饱和度时，Key映射位置发生冲突
 的几率会逐渐提高的，这个时候HashMap需要扩展它的长度，也就是Resize，ReHash就是Resize过程中的一个
步骤，影响Resize的因素主要有两个：
 Capacity : HashMap的当前长度，HashMap的长度一定是2的幂次方
 LoadFactor：HashMap的负载因子，默认值为0.75f
   判断HashMap是否进行Resize的条件如下：HashMap.Size &amp;gt;= Capacity*LoadFactor
Resize的具体过程：
  扩容：创建一个新的Entry数组，长度是原数组的2倍
 ReHash：遍历原数组，将所有的Entry重新Hash到新数组（在长度改变后，Hash规则也随之改变），
   Hash的具体公式如下： index = HashCode（Key）&amp;amp; （Length - 1）,当原数组长度为8的时候,
Hash之后的结果是和111B做运算；新数组的长度为16，Hash运算是和1111B做运算，结果不同
 //ReHash的源码如下 public void transfer(Entry[] newTable,boolean rehash){ int newCapacity = newTable.length; for(Entry&amp;lt;K,V&amp;gt; e:table){ while(e!= null){ Entry&amp;lt;K,V&amp;gt; next = e.next; if(rehash){ e.hash = null == e.</description>
    </item>
    
    <item>
      <title>从LRU开始学习缓存</title>
      <link>https://sin-coder.github.io/leetcode/cache/</link>
      <pubDate>Sun, 15 Dec 2019 14:01:10 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/leetcode/cache/</guid>
      <description>从LRU开始学习缓存  缓存相信大家已经不陌生了，用个通俗的比方来说一下就是，如果把你的家比作一个仓库，那么你每天出
 门时背的包就是你的缓存，你会把最近经常使用的东西放入到背包中，如果背包中没有你需要的，就只能回家
去拿了。
 这篇文章从一道Leetcode的题目开始引入缓存的设计方式，然后介绍一些常见的缓存策略，最后简单介绍
 一些经典的缓存系统和经常遇到的缓存问题
一、Leetcode 146 LRU缓存机制 1.题目描述  设计一个LRU缓存机制，支持获取数据get和写入数据put，具体含义如下：
  获取数据get：如果key存在于缓存中，获取key的值value并且将这个数据放到数据结构的最前面，否则返回-1
 写入数据put：如果key不存在，写入数据值，并且将新写入的数据放到数据结构的最前面；如果缓存的容量已
   经达到了上限，应该在写入新数据之前删除最近最少使用的数据值，这也是LRU的核心思想,这里我们可以
将排在数据结构最后的位置的元素视为最近最少使用的元素
  get和put操作的时间复杂度要求是O（1）   如果还没有明白，可以看看这个缓存是怎么工作的
 //假设这个缓存的容量为2 LRUCache cache = new LRUCache(2); //先将cache理解成一个数组，左边是头部，右边是尾部，最近使用的排在对头，最久未使用的排在队尾 cache.put(1,1); //此时缓存中的数据是[(1,1)] cache.put(2,2); //此时缓存中的数据是[(2,2),(1,1)] 新加入的数据应该放在头部 cache.get(1); //查询key为1的值，返回1，最近访问了键1，移动到头部,缓存中的数据是[(1,1),(2,2)] cache.put(3,3) //缓存已满，出去尾部元素(2,2)，[(3,3),(1,1)] cache.get(2) //未找到该元素，返回-1  2.解题思路  要想在O(1)的时间复杂度内完成上述操作，存储缓存的数据结构应该具备这样的特点：查找是O(1)、插入
 是O（1）、删除是O（1）、而且元素之间还要有一定的顺序；查找O(1)和删除O(1)这个比较好办，哈希表就
可以满足了，但是它没有顺序啊，实际在应用的时候需要将数据插入头部和从尾部进行删除，这是哈希表无法
做到的；这个时候就轮到链表上场了，链表是有顺序的，只需将哈希表和链表结合即可
 但是这个时候又有问题了，链表是使用单向链表还是双向链表呢？我们可以从删除操作的执行过程来分析
 单向链表要想删除一个节点，必须要知道它的前驱节点，也就是多用一个指针，你可以通过哈希表来找到当前
节点，但是如何找到前一个节点，但是如何找找到前一个节点呢？所以只能使用双向链表，最终我们将这种数
剧结构称为哈希链表，话不多说，赶紧上图
3.缓存使用的数据结构  Python和Java都有内置的哈希链表和类似LRU功能的库函数，比如Java中的LinkedHashMap，关于
 关于它在容器数据结构这篇文章中有介绍；Python中可以使用OrderedDict实现LRU，但是推荐使用一个</description>
    </item>
    
    <item>
      <title>使用堆解决常见TOPK问题</title>
      <link>https://sin-coder.github.io/leetcode/topkheap/</link>
      <pubDate>Wed, 11 Dec 2019 14:01:10 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/leetcode/topkheap/</guid>
      <description>使用堆解决常见的TOK问题  关于常见的TOPK问题，都可以使用堆这种数据结构来巧妙的解决，除了去统计最大的或者最小的K个元素
 之外，还有一些变形的问题，比如统计出现频率TOPK的问题，这种问题一般需要进行排序。下面列出leetcode
上一些典型的例题：
 数组中的第K最大的元素
 根据字符出现的频率进行排序（堆排序）
 前K个高频元素 leetcode 347
 前K个高频单词 leetcode 692
   理解了堆的特点后，解决这些问题并不难，但是我们要熟悉一些堆的基本操作，比如如何生成一个堆、对
 堆中的元素进行排序等。此外，在满足复杂度要求的前提下，如何写出更加简练的代码也是一个关注点。毫无
疑问的是在对数据的处理上，python比Java有着先天的优势，在代码编写方面会更加简洁，下面是例题
一、前K个高频元素  给定一个非空的整数数组，返回其中出现频率前 *k* 高的元素
对于这种求TOPK频率的问题，与以往的求最大的K个元素不同，我们需要用哈希表来存放每个元素及其出
 现的频率，再用堆这种数据结构去按照升序排列，代码如下：
//构建一个哈希表用来存放每个元素及其出现的频率 private HashMap&amp;lt;Integer,Integer&amp;gt; map = new HashMap(); //构建一个小顶堆，并且该堆要对map中的元素出现的频率进行排序 private PriorityQueue&amp;lt;Integer&amp;gt; heap = new PriorityQueue&amp;lt;&amp;gt;((n1,n2) -&amp;gt; map.get(n1) map.get(n2)); //返回的列表 private List&amp;lt;Integer&amp;gt; topK = new LinkedList(); public List&amp;lt;Integer&amp;gt; topKFrequent(int[] nums, int k) { //先统计每个元素及其出现的频率，当然还有更简单的写法，请看拓展内容 for(int n : nums){ if(map.</description>
    </item>
    
    <item>
      <title>Java中的ArrayDeque和LinkedList的使用</title>
      <link>https://sin-coder.github.io/datastructure/deque_linked/</link>
      <pubDate>Tue, 10 Dec 2019 16:10:36 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/datastructure/deque_linked/</guid>
      <description> Java中的ArrayDeque和LinkedList的使用  在Java的集合框架中，ArrayDeque和LinkdedList是实现栈和队列的两种不同方式，那么应该如何使用，
 才能使自己构造的数据结构解决问题时性能更好呢，先上一张继承关系表 
 从上图中我们可以看到，ArrayDeque是继承于Deque接口，LinkedList继承于List接口和Deque接口，看
 起来功能要更加强大，那么我们从几个方面来进行比较
 从这张表格可以看出ArrayDeque和LinkedList的主要区别就是数组和链表的区别，二者都能用作双向队列、
 栈；但是使用ArrayDeque当数据不断插入时，底层数组可能扩容，对性能的影响是比较大的；LinkedList底层
是使用的双向链表，不存在扩容的问题，但由于链表，占用的存储空间更大。二者各有优劣，所以综合来看：
 当做队列或栈使用并且数据量比较少时，使用ArrayDeque，占用的存储空间更小
 当做队列或栈使用并且数据量很大时，使用LinkjedList，这样不用扩容对性能的影响
 当需要随机访问时，使用ArrayDeque，数组有先天的优势
  </description>
    </item>
    
    <item>
      <title>滑动窗口解题总结</title>
      <link>https://sin-coder.github.io/leetcode/slidingwind/</link>
      <pubDate>Mon, 09 Dec 2019 15:50:27 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/leetcode/slidingwind/</guid>
      <description>滑动窗口解题总结 一、算法简介  滑动窗口是一种高级双指针技巧的算法框架，代码模板可以按照如下表示
 int left = 0,right = 0; //1.初始化双指针，建立一个索引闭区间，也就是窗口 //2.定义求解目标的初始值 while(right &amp;lt; s.length()){ window.add(s[right]); //3.通过增加right指针不断地扩大窗口 （找到可行解） //并同时更新求解的目标值 right++; while(valid){ //4.判断当前窗口是否满足要求 window.remove(s[left]); //5.停止增加right指针，转而增加left指针，直至窗口中的数据不符合要求 // 并同时更新求解的目标值 left++; //6.继续循环 } }   其中的window的数据类型一般为哈希表，当然在存储英文字母时也可以使用数组；代码的关键点如何判断
 滑动窗口是有效的
二、典型例题 1.Leetcode 3  给定一个字符串，找出其中不含有重复字符的最长子串的长度
 class Solution { private Map&amp;lt;Character,Integer&amp;gt; window = new HashMap&amp;lt;&amp;gt;(); //定义存储元素出现次数的哈希表 public int lengthOfLongestSubstring(String s) { if(s.length() == 0) return 0; int left = 0,right = 0; //初始化左右指针 int maxLen = 0; //初始化最大长度 while(right &amp;lt; s.</description>
    </item>
    
    <item>
      <title>回溯算法解题总结</title>
      <link>https://sin-coder.github.io/leetcode/backtrack/</link>
      <pubDate>Thu, 05 Dec 2019 22:26:15 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/leetcode/backtrack/</guid>
      <description>回溯算法解题总结 一、什么是回溯？  回溯算法实际上就是一个类似于枚举的搜索尝试过程，主要就是在搜索尝试的过程中寻找问题的解，当
 发现已不满足求解条件的时候，就“回溯”返回，尝试别的路径。
 用一句通俗的话来说就是：从一条路向前走，能进则进，不能进则退回来，换一条路再走
 二、解决回溯问题的通用模板  解决一个回溯问题，实际上就是一个决策树的遍历过程，主要思考三个关键点
  路径：也就是已经做出的选择
 选择列表：也就是当前可以做的选择
 结束条件：也就是到达决策树的底层，无法再做选择的条件
   回溯算法的整体框架
 result = [] def backtrack(路径,选择列表): if 满足结束条件: result.add(路径) return for 选择 in 选择列表: 做选择 backtrack(路径，选择列表) 撤销选择 #for循环的细节如下 for 选择 in 选择列表: //做选择 将该选择从选择列表中移除 路径.add(选择) backtrack(路径，选择列表) //撤销选择 路径.remove(选择) 将该选择再加入选择列表   其核心就是for循环里面的递归，在递归调用之前做选择，在递归调用之后撤销选择；这种递归前的选择和
 递归调用后的选择其实与树的前序遍历和后续遍历非常相似，而所谓的前序遍历和后续遍历可以理解为两个有
用的时间点而已，前序遍历的代码在进入某一个节点之前的那个时间点进行，后续遍历代码在离开某个节点之
后的那个时间节点执行。遍历和选择的示意图可以参考如下：
 回溯算法的时间复杂度是O(N!) ，因为穷举整颗决策树是无法避免的，不像动态规划存在重叠子问题
 回溯算法就是纯暴力穷举，复杂度一般都比较高
三、典型例题（全排列和N皇后） 1.Leetcode 46 全排列  以全排列问题来示例回溯框架算法的使用</description>
    </item>
    
    <item>
      <title>动态规划解题思想总结</title>
      <link>https://sin-coder.github.io/leetcode/dp/</link>
      <pubDate>Tue, 03 Dec 2019 22:26:15 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/leetcode/dp/</guid>
      <description>动态规划解题思想总结 一、动态规划和递归、分治的关系 1.递归  关于递归其实就是一个函数调用它自己，它和分治和回溯等算法没有完全隔离开来，它们都可以看做是
 描述一个问题的不同方面。使用递归方法解题时都是有模板的：
public void recur(int level,int param){ //terminator if(level &amp;gt; MAX_LEVEL){ //process result return; } //process current logic process(level,param); //drill down recur(level:level + 1,newParam) //restore current status }   这里上一道经典的使用递归解决的算法题来说明这个框架的使用
经典的汉诺塔问题：原题链接
 public void hanota(List&amp;lt;Integer&amp;gt; A, List&amp;lt;Integer&amp;gt; B, List&amp;lt;Integer&amp;gt; C) { int len = A.size(); //汉诺塔的数量 Hanota(len,A,B,C); } //递归函数 public void Hanota(int n,List&amp;lt;Integer&amp;gt; X,List&amp;lt;Integer&amp;gt; Y,List&amp;lt;Integer&amp;gt; Z){ if(n == 1){ //终止条件 Z.add(0,X.remove(0)); //处理结果 }else{ Hanota(n - 1,X,Z,Y); //向下递归 Z.</description>
    </item>
    
    <item>
      <title>Java和Python中如何使用大顶堆</title>
      <link>https://sin-coder.github.io/program/javapqueue/</link>
      <pubDate>Tue, 03 Dec 2019 21:14:28 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/program/javapqueue/</guid>
      <description>Java和Python中如何使用大顶堆  在数据结构之容器的那篇文章中，我们对于优先队列即堆这种数据结构的底层实现进行了剖析，在实际的
 应用中我们不必自己去实现一个堆，主流的编程语言都提供了相关的集合模块，比如Java中的PriorityQueue
类，Python中的heapq模块。但是这两种语言中实现的堆都是小顶堆（根节点的元素小于左右节点元素的值），
当需要使用大顶堆时该如何解决呢？比如典型的最大的K个元素需要用小顶堆解决，但是最小的K个元素不就
是需要使用一个大顶堆来解决了吗！
 具体的解决方案如下：
 一、通用的方法: 取反  通用的解决方法就是跟语言没有关系的解法，想要构造一个大顶堆，只要保证根节点大于左右节点即可，
 所以我们可以将数据取成相反数再添加到小顶堆中去，取出时再对数据进行取反即可实现大顶堆的效果
二、针对Java的方法  优先队列中存放的是基本数据类型的包装类（Integer、Long）或者自定义的包装类。对于基本数据类型
 的包装器类，优先队列中元素默认排列顺序是升序排列的，也就是说是小顶堆，但是既然是默认的就可以进
行更改。此外，对于自定义的类来说，需要自己定义比较器，比如：
//自定义比较器，降序排列 public static Comparator&amp;lt;Integer&amp;gt; cmp = new Comparator&amp;lt;Integer&amp;gt;(){ public int compare(Integer e1,Integer e2){ return e2 - e1; } } //声明对象时 Queue&amp;lt;Integer&amp;gt; pqueue = new PriorityQueue&amp;lt;Integer&amp;gt;(); //不使用比较器，默认升序排列，即小顶堆 Queue&amp;lt;Integer&amp;gt; pqueue = new PriorityQueue&amp;lt;Integer&amp;gt;(cmp); //使用比较器，降序排列，即为大顶堆 //比较器升降序的声明 Comparator&amp;lt;Object&amp;gt; cmp = new Comparator&amp;lt;Object&amp;gt;(){ public int compare(Object o1,Object o2){ return o1 - o2 //升序 return o2 - o1 //降序 } }   所以在实际解决问题的过程中如果需要使用大顶堆可以这样声明</description>
    </item>
    
    <item>
      <title>贪心算法集锦</title>
      <link>https://sin-coder.github.io/leetcode/greedy/</link>
      <pubDate>Mon, 02 Dec 2019 22:26:15 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/leetcode/greedy/</guid>
      <description>贪心算法解题总结 一、引例  某天你在超市购物后，总共消费了782元，这时假设你有1元、5元、10元、20元、100元和200元的钞票
 无穷多张，那么最少需要多少张钞票足够支付？
 直觉告诉我们：要尽可能多地使用面值较大的钞票，其实这就是一种贪心的思想
 二、贪心算法简介  由引例我们已经大概了解了什么是贪心，在这儿对它下个定义：贪心算法是指在对问题求解时，总是做
 出在当前看来是最好的选择；也就是说不从整体最优上加以考虑，它所做出的是在某种意义上的局部最优解
 贪心算法不是对所有的问题都能得到整体的最优解，关键是贪心策略的选择，具体的贪心策略中某个状
 态以前的过程不会影响以后的状态，只与当前的状态有关
三、Leetcode典型例题 1.455分发饼干  (1) 题目描述
假设你是一位很棒的家长，想要给你的孩子们一些小饼干。但是，每个孩子最多只能给一块饼干。对每
 个孩子 i ，都有一个胃口值 gi ，这是能让孩子们满足胃口的饼干的最小尺寸；并且每块饼干 j ，都有一个尺
寸 sj 。如果 sj &amp;gt;= gi ，我们可以将这个饼干 j 分配给孩子 i ，这个孩子会得到满足。你的目标是尽可能满足
越多数量的孩子，并输出这个最大数值。一个小朋友最多能拥有一块饼干
 (2)解题思想
根据让更多的孩子得到满足这个目标，可以分析出如下贪心规律：
  某块饼干不能满足某个孩子的胃口，则它也一定不能满足胃口更大的孩子
 某个孩子的胃口可以用更小的饼干来满足，则没有必要用更大的饼干满足，更大的饼干留给胃口更大的孩子
 孩子的胃口越小，则其更容易被满足，所以优先从胃口小的孩子尝试
   (3)算法思路
  按照胃口大小和饼干大小对两个数组进行从小到大的排序
 按照从小到大的顺序用饼干来尝试是否可以满足某个孩子的胃口，每个饼干只尝试一次，如能够满足，接着
   用下一块饼干继续尝试能否满足下一个孩子的胃口；否则，抛弃该饼干，用下一块饼干继续尝试满足当前
的孩子。直到没有更多的孩子或者没有更多的饼干，算法结束
(4)代码实现</description>
    </item>
    
    <item>
      <title>Python中的sort()和sorted</title>
      <link>https://sin-coder.github.io/program/sort_sorted/</link>
      <pubDate>Thu, 28 Nov 2019 21:14:28 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/program/sort_sorted/</guid>
      <description>Python中sort和sorted的区别和使用 一、函数介绍  sort函数和sorted函数的功能是非常强大的，在有些leetcode题目中，使用了这些函数，几行代码就可以
 搞定了（只要你不怕被面试官打死），下面我们先看看这两个函数的介绍吧
&amp;gt;&amp;gt;&amp;gt; help(list.sort) Help on method_descriptor: sort(self, /, *, key=None, reverse=False) Stable sort *IN PLACE*. #inplace &amp;gt;&amp;gt;&amp;gt; help(sorted) Help on built-in function sorted in module builtins: sorted(iterable, /, *, key=None, reverse=False) Return a new list containing all items from the iterable in ascending order. #new list A custom key function can be supplied to customize the sort order, and the reverse flag can be set to request the result in descending order.</description>
    </item>
    
    <item>
      <title>BFS &amp; DFS算法</title>
      <link>https://sin-coder.github.io/datastructure/bfs-dfs/</link>
      <pubDate>Thu, 28 Nov 2019 17:01:10 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/datastructure/bfs-dfs/</guid>
      <description>深度优先和广度优先算法详解 一、DFS 和 BFS 算法概述 1.什么是DFS和BFS？  DFS （Depth-First-Search）,称为深度优先搜索；BFS（Breadth-First-Search），称为广度优先搜索。
 这二者都是在树和图的遍历中应用非常广泛的算法，那么再来看下遍历的定义：从初始点出发，按照某种
搜索方法对树或图中的每个节点均做一次且仅做一次的访问，访问具体节点所做的操作依赖于具体的问题。
 在树的遍历算法中，我们经常会看到前序遍历、中序遍历、后续遍历、层序遍历等方法，其实前序遍历
 就是深度优先搜索的一种实现，层序遍历就是对广度优先搜索的一种实现。树也可以看做是一种特殊的图，
树和图的遍历主要的区别就是树有根节点（指定的），而图需要我们自身指定开始遍历的节点。
2.DFS和BFS算法的核心思想  BFS和DFS都是图的遍历方法。它们具有一些共性的问题，比如都要避免节点的重复访问，具体的实践
 中可以设置一个访问数组，数组中的每个元素代表一个节点，当节点被访问后数组中对应的元素赋一个特定
的值进行标记即可
 DFS的搜索过程是这样的：
  先访问初始节点V
 从V未被访问的邻接点中选取一个W，从W出发进行DFS
 重复上述步骤即可
   BFS的搜索过程是这样的：
  先访问图的初始节点V
 依次访问V节点的所有邻接节点V1，V2，V3...
 按照V1，V2，V3被访问的次序依次访问与它们相邻接的未被访问的节点
 重复上述过程
  3.DFS和BFS算法效率分析  DFS和BFS的时间复杂度只与数据的底层存储结构相关，而与搜索的路径无关。当使用邻接矩阵存
 储时，对于每一个被访问的节点，都要循环检测矩阵中的整整一行（n个元素），时间复杂度为O（n^2）
当使用邻接表来存储时，有2e个表节点，但只需要扫描e个节点即可完成遍历，加上访问n个头节点的
时间，时间复杂度为O（n+e）
 DFS和BFS算法的空间复杂度相同，都是借用了堆栈或队列，为O（n）。递归在本质上也属于栈
 二、DFS 和BFS 的算法实现  图在底层都是以邻接表或者邻接矩阵的方式来存储的，在Java、C++都可以使用表或者矩阵来进行定义
 的，Python中可以使用字典来进行定义。解决图的BFS问题就是利用队列的先进先出的思想，队列可以保存
图中未遍历的节点；解决图的DFS问题是利用栈这种数据结构，递归和非递归的实现本质上都是先进后出。
1.DFS的算法实现  假设有这样一张图：
  （1）Python的实现</description>
    </item>
    
    <item>
      <title>数据结构之容器</title>
      <link>https://sin-coder.github.io/datastructure/container/</link>
      <pubDate>Thu, 28 Nov 2019 17:01:10 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/datastructure/container/</guid>
      <description>一、概述 1.什么是数据结构中的容器？  容器是一种把多个元素组织在一起的数据结构，也可以理解为一种可以包含其他类型对象作为元素的
 的对象。容器是仅仅用来存放数据的，本身没有取出元素这种能力，大多数情况下是通过可迭代对象来
操作容器
 容器这种数据结构在各种编程语言中都有相应的实现，比如我们经常会比较熟悉的C++的标准模板库
 （Standard Template Library，STL）、Java的集合框架（Java Collections Framework，JCF）、而在
Python中更是将容器类型的数据结构作为其基本数据类型、Go语言也有内建的容器和相应的标准库，
本篇博客便是在总结各种容器使用及原理的基础上，对Java、Python中相同的类型的容器做一个横向的
对比，以便于日后的总结和复习
2.Java集合框架简介  （1）泛型的机制
Java中的容器就是可以容纳其他Java对象的对象，且Java容器中只能存放对象，对于一些基本的数据
 类型（比如int、long、float、double等），需要将其包装成对象类型之后（Interger、Long、Float、Double
等）才能放到容器里，很多时候拆包装和解包装使能够自动完成的
 Java容器能够容纳任何类型的对象，表面上是通过泛型机制完成的。事实上，所有容器的内部存放的都
 是Object类的对象，所有的对象都是Object类型的子类。泛型机制只是简化了编程，由编译器自动帮助我们
完成了强制类型的转换而已，示例代码如下
ArrayList&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;String&amp;gt;(); //参数化类型 list.add(new String(&amp;quot;csuyzz&amp;quot;)); String name = list,get(0); //容器中存放的Object类的对象隐式转换成为String类型的对象   此外，Java里的对象都在堆上，且对象只能通过引用（reference）来访问，容器里存放的其实是对
 象的引用而不是对象的本身
 （2）接口和实现（Interfaces and Implementations）
在Java 的集合框架中共定义了14种容器的接口，关系图如下所示，Map接口没有继承自Collection的
 接口，因为Map接口是关联式的容器而不是集合，但也可以从Map转换到Coolection；Stack已经被Deque
所取代

 接口的实现如下表所示
 ImplementationsHash TableResizable ArrayBalanced TreeLinked ListHash Table + Linked ListInterfacesSetHashSetTreeSetLinkedHashSetListArrayListLinkedListDequeArrayDequeLinkedListMapHashMapTreeMapLinkedHashMap &amp;gt; (3) 迭代器</description>
    </item>
    
    <item>
      <title>布隆过滤器的原理及使用</title>
      <link>https://sin-coder.github.io/datastructure/bloomfilter/</link>
      <pubDate>Sun, 24 Nov 2019 17:01:10 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/datastructure/bloomfilter/</guid>
      <description>布隆过滤器的原理及使用 一、BloomFilter简介  BloomFilter是大数据领域中经常使用到的算法，主要用于在海量的数据中判断一个数据是否已经存在，但
 如果不存在，判断结果一定是正确的。如果存在判断结果可能出现错误；这种数据结构的速度是非常快的，内
存消耗得比较小，使用很方便，在各种编程语言中都有对应实现的类库
二、Bloom的原理  BloomFilter本身是一个非常长的二进制向量（可以看成一个位数组）和一个映射函数。这个位数组初始情
 况下内部全部是0，长度是m；对于每个新增的项，我们使用K种不同的hash算法对他计算hash值，可以得到K
个hash值，再使用这些hash值对m取模映射到数组范围内，假设取模后的结果是x，便会把x值对应的位置标记
为1，过程图如下：
 但是当插入的数据大幅提升的时候，位数组中大部分的元素就会被置成１。此时如果查询一个元素，通过
 哈希函数映射到的位置可能已经被标记了，这时候就会出现误判；但是如果所有映射的位置中出现未被标记的
位置，那么这个元素一定是不存在的，原理示意图如下：
 我们可以使用Python将Bloomfilter实现的原理用代码实现：
 #插入元素 def BloomFilter(filter,value,hash_functions): m = len(filter) for func in hash_functions: idx = func(value) % m #哈希映射取模 filter[idx] = True #对应的位置进行标记 return filter #判断元素 def MemberInFilter(filter,value,hash_functions): m = len(filter) for func in hash_functions: idx = func(value) % m if not filter[idx]: return False return True   　通过上面的代码实现我们可以看到BloomFilter插入数据和查询数据时的时间复杂度都是O（k）,其中k是哈</description>
    </item>
    
    <item>
      <title>从尾到头打印链表</title>
      <link>https://sin-coder.github.io/leetcode/printlistreverse/</link>
      <pubDate>Fri, 15 Nov 2019 14:01:10 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/leetcode/printlistreverse/</guid>
      <description>反转链表专题 No.1 问题描述  输入一个链表，从尾到头的顺序返回一个ArrayList
 解题思路 1.使用递归法 //1.解法一 public ArrayList&amp;lt;Integer&amp;gt; printListReverse(ListNode listnode){ ArrayList&amp;lt;Integer&amp;gt; arrayList = new ArrayList&amp;lt;Integer&amp;gt;(); if(listnode != null){ arrayList.addAll(printListReverse(listnode.next)); arrayList.add(listnode.val); } return arrayList; } //分析：时间复杂度为O（n）,相当于将每个元素均遍历了一遍 //空间复杂度为O（n^2）,创建的列表的合计元素个数1+2+3+4+n-1 //拓展内容：ArrayList中的addAll(Collection&amp;lt;? extends E&amp;gt; c) 方法 按照指定collection容器返回元素的 //顺序将所有的元素添加到列表的尾部  2.使用栈（推荐解法） //Java实现 public ArrayList&amp;lt;Integer&amp;gt; printListReverse(ListNode listnode){ ArrayDeque&amp;lt;Integer&amp;gt; stack = ArrayDeque&amp;lt;Integer&amp;gt;(); while(listnode != null){ stack.addFirst(listnode.val); listnode = listnode.next; } ArrayList&amp;lt;Integer&amp;gt; arrayList = new ArrayList&amp;lt;Integer&amp;gt;(); while(stack.pollFirst()) arrayList.add(stack.pollFirst()) return arrayList; } //Java中推荐使用ArrayDeque来实现一个栈 //当压栈时，调用addFirst()方法; 出栈时调用pollFirst()方法 //分析：时间复杂度O(n)，空间复杂度也是O（n）  #基于Python的实现 class Solution: def printListReverse(self,listnode): if not listnode: return [] result = [] while listnode: result.</description>
    </item>
    
    <item>
      <title>常见数据结构的定义</title>
      <link>https://sin-coder.github.io/datastructure/defindatastructure/</link>
      <pubDate>Fri, 15 Nov 2019 14:01:10 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/datastructure/defindatastructure/</guid>
      <description>常见数据结构的定义 一、链表（以singly-linked list为例） 1.Java public class ListNode{ int val; ListNode next; //如果是双向链表，则会为left or right ListNode(int x) { val = x; next = null; } }  2.Python class ListNode: def __init__(self,x): self.val = x self.next = Node  3.C struct ListNode{ int val; struct ListNode *next; };  4.Go type ListNode struct{ Val int Next *ListNode }  二、二叉树（Binary Tree Node） 1.Java //Definition for a binary tree node public class TreeNode{ int val; TreeNode left; TreeNode right; TreeNode(int x){val = x;} }  2.</description>
    </item>
    
    <item>
      <title>环形链表</title>
      <link>https://sin-coder.github.io/leetcode/circlelist/</link>
      <pubDate>Fri, 15 Nov 2019 14:01:10 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/leetcode/circlelist/</guid>
      <description>环形链表专题 一、问题1  给定一个链表，判断一个链表中是否有环
 1.算法思路  （1）判断是否存在重复节点
通过检查一个节点此前是否被访问来判断是否为环形链表，可以使用哈希表来存储访问过的节点
（2）快慢指针
通过快慢指针遍历链表，慢指针每次移动一步，而快指针每次移动两步；如果链表中不存在环，最终快
 指针将会最先达到尾部，此时返回Fasle即可；如果链表中存在环，最终快慢指针一定会相遇
2.代码实现 //元素判重法 public boolean hasCycle(ListNode head) { Set&amp;lt;ListNode&amp;gt; visited = new HashSet&amp;lt;ListNode&amp;gt;(); while (head != null) { if (visited.contains(head)) { return true; } else { visited.add(head); } head = head.next; } return false; } //分析，时间复杂度是O（n），对链表中的每个元素最多访问一次，向哈希表中添加一个元素为O(1) //空间复杂度为O（n）,最多将链表中的所有元素均添加到哈希表中  //快慢指针法 public boolean hasCycle(ListNode head) { if (head == null || head.next == null) { return false; } ListNode slow = head; ListNode fast = head.</description>
    </item>
    
    <item>
      <title>什么是死锁？</title>
      <link>https://sin-coder.github.io/os/deadlock/</link>
      <pubDate>Sat, 02 Nov 2019 21:50:12 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/os/deadlock/</guid>
      <description>什么是死锁？ 一、死锁概念的介绍  以两个进程为例，每个进程正在申请的资源恰好是其他进程正在占用的资源； 当然这里的进程数也有
 可能是多个。但最终都是形成一个资源的依赖环
 简述：多个进程由于互相等待对方持有的资源而造成的谁都无法执行的情况
 二、死锁的必要条件  互斥：系统资源之间是互斥使用的，一旦某个进程占用，其他进程便无法使用
 占有并等待：一个进程占有了一些资源，但是又不去释放，同时再去申请其他的资源
 非抢占：每个进程所拥有的资源必须不能被其他进程所抢占
 循环等待：进程之间各自占有的资源和互相申请的资源形成了环路的等待
  三、死锁常用的处理方法 1、死锁预防  （1）简述：
破坏死锁形成的必要条件之一，可以通过限制如何申请这些资源的方法来预防死锁
（2）方法
  基于互斥条件来预防死锁：资源可以进行共享
 基于抢占的解决方案：如果一个进程占有资源并申请另一个不能立即分配的资源，则该进程所占用的资源
   即可被抢占
  基于占有并等待的解决方案：一个进程在申请其他资源之前必须要释放掉自己已有的资源
 基于循环等待的解决方案：对所有的资源进行完全排序，且要求每个进程按递增的顺序来申请资源，这样
   就不会出现环路的等待
 2、死锁避免  （1）简述
检测每个资源的请求，如果造成死锁就立刻拒绝
（2）银行家算法
  安全状态：如果系统中的所有进程存在一个可完成的执行序列P1，P2，P3，………Pn，则称系统处于安   全状态
  使用特定算法判断是否存在一个执行序列，当按照这种执行序列执行时，不会产生死锁
 银行家算法的执行方法：进程在执行的时候主要关注三种类型的资源：进程本身所占用的资源，进程需要
   申请的资源，系统中剩余的资源申请一个work变量（表示系统剩余的资源），need变量（系统正在申请
的资源），allocate(已经分配给进程的资源)按照特定的序列执行，在每个序列执行时，判断当前剩余资
源是否能够满足申请资源，如果能，则将剩余资源减去申请资源在加上释放资源。但是时间复杂度：
T（n）=O(mn^2),执行的代价非常大</description>
    </item>
    
    <item>
      <title>CDN技术简介</title>
      <link>https://sin-coder.github.io/network/cdn/</link>
      <pubDate>Thu, 10 Oct 2019 12:05:48 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/network/cdn/</guid>
      <description>CDN技术简介 一、概述 1.问题背景  不同地理区域的用户访问同一个网站时会产生高延迟，导致用户的访问速度较慢，对个别服务器造成的
 压力也比较大，网站的稳定性和安全性也不是很高，CDN的出现就是用来解决这一问题的
2.什么是CDN  CDN即Content Delivery Network,内容分发网络，具体内容为将源站内容发布到最接近用户的边缘节点，
 使用户可就取得所需内容，提高用户访问的响应速度和成功率。解决了因分布、带宽、服务器能力带来的访
问延迟高的问题，提供了一系列加速解决方案
3.CDN的应用场景  网站服务的客户群体从独立的区域扩张到了全国范围，而自身服务器不足以覆盖全网用户，导致部分地区用   户访问网站速度变慢，到达率不高
  网站已经实现了静动态资源分离，且静态资源服务器的能力已经达到极限，需要增加服务器硬件设才能够   解决问题的
  网站频繁遭到DDOS攻击，CC攻击，DNS劫持，导致用户体验差，网络阻塞，无法提供正常服务 当用户   无访问某一个节点时，CDN会给用户提供更多的节点以供访问
  当网站用户跨多个ISP（电信、联通、移动、铁通、长城），而自身的服务器只在其中一个机房的减少因   运营商通道阻塞而导致的访问失败
 二、CDN的工作原理 1.CDN的工作过程  步骤一：将内容推送到边缘的节点上，以此产生一个副本，（WEB原始服务器推送到各CDN镜像服务器）   原始服务器上的内容拷贝到其他镜像服务器上
  步骤二：引导用户就近进行访问（DNS解析的原理）  2.CDN的加速过程(智能DNS解析)  用户在浏览器中输入域名后，请求DNS服务器解析该域名
 DNS服务器并不能直接解析到该域名所对应的IP地址，而是将该请求发送给智能DNS服务器
   （网站的服务商需要将原来的解析地址转换到智能DNS服务器的IP）
  智能DNS服务器（GSLB调度系统）判断用户访问离某区域最近，就返回该区域服务器的IP地址   （智能DNS服务器是CDN加速服务商所提供的服务器）
  用户拿到IP地址后即可访问该区域的服务器    3.</description>
    </item>
    
    <item>
      <title>端口镜像和链路聚合小结</title>
      <link>https://sin-coder.github.io/network/portlink/</link>
      <pubDate>Wed, 07 Aug 2019 21:26:25 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/network/portlink/</guid>
      <description> 端口镜像和链路聚合 一、端口镜像 1.背景需求  监控交换机特定端口的入站或出战报文，流量监测和故障定位
 2.镜像的分类  （1）基于端口的镜像
指定端口的所有数据复制到指定的端口，交换机可以指定入站和出站；以太网交换机支持多对一的镜
 像，即是将多个端口的报文复制到某一个监控端口上
 本地端口镜像：监控主机和观察端口进行直接相连。
远程端口镜像 : 监控主机和观察端口之间通过二层网络或三层网络相联
 二层端口镜像：交换机将镜像端口的报文封装成VLAN、然后通过观察端口将该报文在此VLAN中进行广播
三层端口镜像：GRE报文头来封装和解封装镜像报文，穿透三层网络
 （2）基于流的镜像
只是将匹配访问控制列表的业务流量复制到指定的监控端口。具体可分为流镜像到端口和流镜像到CPU
 二、链路聚合 1.问题背景  网络中某些链路承载的流量非常大，链路存在带宽瓶颈；链路存在端口故障 。而链路聚合就是将多条
 以太网链路进行捆绑，链路冗余、负载分担来解决这些问题的
2.工作模式  （1）手工负载分担模式
允许在聚合组中手工加入多个成员接口，所有接口均处于转发状态，分担负载的流量。Eth-Trunk的
 创建、成员接口的加入都需要手工配置来完成，没有LACP协议报文的参与，通常运用在对端设备不支
持LACP协议的情况之下 该工作模式下的所有接口均处于转发状态
 （2）静态LACP
M：N模式 :M条链路处于活动状态 N条线路非活动状态作为备份链路；当M条链路中出现故障后，系
 统会从N条链路中选择优先级较高的链路接替出现故障的链路同时实现链路负载分担和链路冗余备份的功
能 。利用LACP协议进行聚合参数的协商、确定活动的接口和非活动的接口的链路聚合方式
 静态：手工配置Eth-Trunk成员接口、由LACP协议协商确定活动接口和非活动接口
（3）动态LACP模式
从ETH-TRunk的创建到加入到成员接口都不需要人工的干预，由LACP协议自动协商来完成
 </description>
    </item>
    
    <item>
      <title>STP生成树</title>
      <link>https://sin-coder.github.io/network/stp/</link>
      <pubDate>Tue, 06 Aug 2019 16:12:20 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/network/stp/</guid>
      <description>STP生成树简介  STP:Spanning Tree Protocol ,生成树协议，为什么要生成树呢，因为有环的存在
 1.利用STP可以解决的问题  消除环路：阻塞冗余链路消除网络中可能存在的通信环路 链路备份：当前活动的路径发生故障之后，激活冗余链路备份，进而恢复网络的连通性   STP的正常工作依赖于网桥协议数据单元(BPDU报文)的泛洪
 2.BPDU报文的介绍  其中比较重要的参数有
  ROOT ID：发送此配置BPDU的交换机所认为的根交换机的标识
 ROOT Path Cost： 从发送此配置BPDU的交换机到达根交换机的最短路径总开销，含交换机根端口的开
   销和不发送此配置BPDU的端口的开销
  Bridge Identifier : 发送此配置BPDU的交换机的STP交换机标识
 Port ID : 发送此配置BPDU的交换机端口的STP端口标识
   比较顺序为：RID&amp;gt;RP&amp;gt;BID&amp;gt;PID，且对应的值越小越优先
  桥ID（Bridge ID）: 是交换机的STP标示符，一共8个字节，由2个字节的优先级和6个字节的MAC   地址构成：桥优先级缺省为32768，可以手工修改，MAC地址为交换机的背板MAC网络中Bridge ID最小
的交换机将成为根桥
  路径开销：Path COST，端口路径开销的默认值和取值范围由选定的路径开销算法决定，路径开销与带宽成反比
 端口ID （2字节）= 端口优先级（1字节）+ 端口编号（1字节），缺省优先级128，范围0-255，越小越优。
  3.STP的缺点  STP的短板：所有的vlan都只能使用单侧的链路，这将导致被阻塞端口所在的链路带宽资源浪费</description>
    </item>
    
    <item>
      <title>Vxlan技术简介</title>
      <link>https://sin-coder.github.io/network/vxlan/</link>
      <pubDate>Tue, 06 Aug 2019 15:45:16 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/network/vxlan/</guid>
      <description>Vxlan技术简介 一、Vxlan技术的产生背景  网络隔离的限制：802.1Q中标准中最多支持的4094个VLAN，数量已无法满足在二层网络中虚拟机数量增   长的需求
  虚拟机规模的限制：在大二层网络里，报文通过MAC地址进行转发，MAC地址表容量限制了虚拟机的数量
 虚拟机的迁移受到限制，虚拟机从一台主机上迁移到另一台主机时，也必须依靠二层网络来进行传输
  二、名词解释  VTEP：Virtual TUNNEL END POINTS ，VXLAN隧道的端点，主要用于VXLAN报文的封装和解封装，直   连物理网络，分配的地址为物理网络IP
  VM：虚拟机，虚拟机之间的访问可分为相同VNI下的不同VM、不同VNI下的跨网访问和VXLAN与非VXLAN   之间的跨网访问
  VNI: VXLAN的网络标识,用于区分VXLAN段，一个VNI表示一个租户  三、技术实现  VXLAN的通信原理是将逻辑网络中的数据帧封装在物理网络中进行传输，封装和解封装的过程由VTEP
 节点来完成。VXLAN将逻辑网络中的数据帧添加在VXLAN头部之后就封装在物理网络中的UDP报文进行数
据的传送
四、VXLAN的报文格式 注释：
 OUTER 的UDP端口使用4798，但是可以进行修改
 OUTER的IP头封装：源IP为发送报文的虚拟机所属的VTEP的IP地址，目的IP为目的虚拟机所属的
   VTEP IP地址
  OUTER:SA为发送报文的虚拟机所属的VTEP MAC地址，DA为目的虚拟机所属的VTEP上路由表中的   下一跳MAC地址
  VXLAN header: 24位的VNI，一共可表示2^24个不同的局域网 16777216个不同的网络  参考文章：https://www.cnblogs.com/hbgzy/p/5279269.html</description>
    </item>
    
    <item>
      <title>Vlan详解</title>
      <link>https://sin-coder.github.io/network/vlan/</link>
      <pubDate>Fri, 02 Aug 2019 14:06:13 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/network/vlan/</guid>
      <description>Vlan详解  最近在学习网络时总是卡在了二层交换上，尤其对一些概念不是很理解，在公司里实际上去配置一些设
 备总是出现各种问题，所以下定决心搞透二层vlan中的一些技术，下面是最近总结的一些知识
一、相关概念解释  VLAN: 虚拟局域网，VLAN所指的LAN特指使用路由器分割的网络-也就是指广播域
 MAC地址分类：MAC地址可分为单播、组播和广播三大类，单播MAC地址全球唯一
 MAC地址泛洪：内网中的一台PC向交换机发送大量的伪造的数据帧，当伪造的目的MAC将交换机的MAC
   地址表填充满之后，MAC地址表无法学习到新的MAC导致交换机瘫痪
附：MAC地址表是交换机工作的核心，如果MAC地址表紊乱，则交换机就不能正常工作。
  广播域：指的是广播帧（目标的MAC地址全部为1）所能传递到的范围，也指能够直接通信的范围，不仅   仅是广播帧、多播帧和目标不明的单播帧也能在同一个广播域中通行
  ARP请求：建立IP地址和MAC地址的映射关系
 DHCP：用于自动设置IP地址的协议，当客户机请求DHCP服务器分配IP地址的时候，必须要发出DHCP广播
 RIP协议：是一种路由协议,每隔30秒路由器都会对临近的其他路由器广播一次路由信息，RIP以外的其他路由
   协议使用多播传输路由信息，这也会被交换机泛洪
 二、二层交换机简介 1、主要功能  终端用户的接入、维护自己的MAC地址表、数据帧的转发和过滤、二层环路的避免和链路的冗余性
 2、工作原理  在收到数据帧之后，交换机学习帧的源MAC地址，然后在MAC地址表中查询该帧的目的MAC地址，并
 将数据帧转发出去
3、具体过程  初始情况下，交换机的MAC地址表是空的
 PC1发送数据帧给PC2（PC1已经通过ARP请求获取了PC2的MAC地址）
 交换机在1口接受到该数据帧后，在MAC地址表中查询该帧的目的MAC地址
 MAC地址表中没有对应匹配的MAC地址，则将这个数据帧进行泛洪，同时交换机学习到该帧的源MAC地址
   并创建表项;将源MAC地址与接收该帧的1口进行关联
  除目的主机外的其他的主机会丢弃该数据帧，目的主机回复数据，将自己的MAC地址发往交换机
 此时该数据帧的MAC地址为源主机的MAC地址，交换机在查询到该表项之后，就将数据帧从1口转发出去
 同时交换机学习到目的主机的MAC地址，并在MAC表项中将其与2口进行关联
  4.为什么要使用VLAN  二层交换机只能构建单一的广播域，但是在使用VLAN之后，它能够将网络分割成多个广播域。未分割</description>
    </item>
    
  </channel>
</rss>