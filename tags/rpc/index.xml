<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>RPC on sin-coder</title>
    <link>https://sin-coder.github.io/tags/rpc/</link>
    <description>Recent content in RPC on sin-coder</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Feb 2020 15:59:05 +0800</lastBuildDate>
    
	<atom:link href="https://sin-coder.github.io/tags/rpc/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>服务器并发模型的总结</title>
      <link>https://sin-coder.github.io/post/server/</link>
      <pubDate>Wed, 26 Feb 2020 15:59:05 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/server/</guid>
      <description> 服务器常用并发模型 1.单线程同步模型  单线程同步模型是最简单的服务器模型，每次只能处理一个客户端的连接，其他连接必须要等到前面的
 连接关闭后才能得到服务器的处理，否则发过来的请求会悬挂住，没有任何响应；服务端是串行地处理客
户端的连接的
 一个客户端必须要等到另外一个客户端运行结束后才可以运行，这也太慢了吧
 2.多线程同步模型  服务器可以并行地处理多个客户端的连接，没来一个连接就开启一个新的线程单独进行处理，每个线程
 都是同步读写客户端的连接的
3.多进程同步模型  Java使用者很少能够体会多进程的魅力，他们都是使用多线程。但是在Python中并不常见，因为Python
 的GIL只能使单个进程占满一个CPU核心，多线程不能利用多核的优势，所以Python服务器可以使用多进程
模型
4.PreForking同步模型  进程在操作系统中是非常耗资源的，所以要对服务器开辟的进程数量进行限制，避免系统的负载过重，
 这就是多进程PreForking模型。
 这种模型预先产生多个子进程，共同对服务器套接字竞争资源，但是最终只能有一个进程获取到。
 如果并行的连接数超过了prefork的数量，那么后来的客户端请求将会阻塞。但是这样也可以通过子进程
的单线程同步模型改成多进程同步模型的方式解决
5.单进程异步模型  上述的服务器模型都是同步的，而现代的服务器一般都是异步的，效率是比较高的，它是一种非阻塞的
 服务器模型，实现了对进程和线程的解放，再加上事件轮询机制的配合使得它的性能比同步高出了许多
 像Nignx、Nodejs、Redis都是基于异步模型构建出来的，性能非常高
 6.PreForking 异步模型  单进程的IO并发能力有限，虽然使用了事件轮询和异步读写功能，但是还不能应对高并发的需求，所以
 需要使用多进程，这样也可以对我们的CPU最大限度的利用
 开源的Tornado服务器和Nignx就是采用了多进程PreForking模型达到了超高并发的处理能力
 </description>
    </item>
    
    <item>
      <title>Redis中的RPC协议结构</title>
      <link>https://sin-coder.github.io/post/redisrpc/</link>
      <pubDate>Mon, 24 Feb 2020 16:59:37 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/redisrpc/</guid>
      <description>Redis中的RPC协议结构  Redis的客户端和服务器之间进行RPC通信时，使用的是其开发者专门设计的文本通讯协议RESP。它的
 开发者认为数据库系统的性能瓶颈一般不在于网络流量，而是数据库自身内部的逻辑处理上。所以Redis使
用了浪费流量的文本协议。但是，依然可以取得很高的访问性能
 下面主要介绍RESP协议的相关内容
 一、RESP协议简介  RESP（Redis Serialization Protocol）,就是Redis的序列化协议，这是一种对人友好的文本协议。它将
 传输的结构数据分为5种最下单元的类型，单元结束时统一加上回车换行符\r\n，具体如下
 单行字符串以+符号开头
+hello world\r\n  多行字符串以$符号开头，后跟字符串的长度
$11\r\nhello world\r\n #长度加上字符串  整数值以：符号开头，后跟整数的字符串形式
:1024\r\n  错误的消息以 - 开头
-WRONGTYPE Operation against a key holding the wrong kind of value\r\n  数组以*开头，后面跟数组的长度
*3\r\n:1\r\n:2\r\n:3\r\n #先是数组长度，依次再是每个内容，表示数组[1,2,3]  NULL用多行字符串表示，不过长度要写成-1
$-1\r\n  空串用多行字符串表示，长度填0
$0\r\n\r\n #两个\r\n之间隔的是空串  客户端向服务器发送指令使用多行字符串数组，比如一个简单的set指令 set author codehole会被序列化为
   下面的字符串
 *3\r\n$3\r\nset\r\n$6\r\nauthor\r\n$8\r\ncodehole\r\n   服务端向客户端回复的响应要支持多种数据结构，基本上都是上述5种基本类型的组合
#单行字符串响应 &amp;gt;set author codehole OK #这里的OK就是单行响应，没有使用引号括起来 #错误响应 -ERR .</description>
    </item>
    
    <item>
      <title>分布式RPC设计思想</title>
      <link>https://sin-coder.github.io/post/ditrirpc/</link>
      <pubDate>Mon, 24 Feb 2020 15:59:05 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/ditrirpc/</guid>
      <description>分布式RPC设计思想  分布式所要解决的问题就是当系统中的个别节点发生故障后整个系统依然能够稳定的对外提供服务，对于
 RPC框架来说同样也是；多线程和多进程解决的都是并发的问题，无论怎样都只能算是单点的设计，要想保证
系统的高可用性，分布式的设计必不可少。下面就介绍一些RPC框架设计中关于分布式的一些思想
一、客户端连接池  如果RPC的服务端部署在多个节点上时，客户端得出的是一个服务列表，有多个IP端口对，客户端的
 连接池可以随机挑出任意的RPC服务节点进行连接，而且每个服务节点都应该有个权重值，如果所有节点
的权重值一样时，它们的流量分配就是均匀的，如果每个节点的权值较小，它被客户端选中的概率也会比
较小。设计示例代码如下：
class RPCNode{ String addr; //服务端的地址 int weight; //节点权重 } class RPCCluster{ RPCNode[] nodes; //节点的列表 Node random(); //按权重随机挑选节点 }  二、容灾 Failover  如果有一个服务节点挂掉时，客户端需要采取一定的策略避免请求失败，比如可以重试，但是不能进行无
 线的重试，要有一定的重试策略
 一个可行的方案是当节点挂掉时，将失效的节点摘除，放置的失效的节点列表中；然后每隔一段时间检查
 失效的节点是否恢复了，如果恢复了，那就从失效的节点中移出，重新加入有效节点的列表中；当然也不能仅
依据一次的检测就判断节点是否有效，可以通过检测一个时间段内的出现的错误数量判断，如果错误数量过多
那就说明了真的失效了，这也是为了避免部分网络问题的原因
三、降权法  我们可以为每个服务端节点赋一个权值，改变权值就可以改变节点的相对流量了；如果某个节点出现了一次
 错误就对该节点进行降权，错误次数越多，降权降得越快，最终可以到达一个最小值，但是无论如何，每个节
都还有翻身的机会。被降权的节点只要有一次调用成功，权值就会恢复正常
 一个非常简单的策略就是当服务端节点错误时进行权重减半，比如从1024开始减半，一直到1，当恢复时
 可以进行权重翻倍
四、服务发现  如果服务端可以支持动态扩容，那么它的稳定性和高可用性就会更高。当系统的负载比较高的时候，我们
 可以通过添加节点的方式减轻压力。但是就像前面设计的静态RPC服务地址列表，当节点增加时，必须要修改
客户端的配置重启才能生效，但是生产环境怎么可能重启配置这时候服务发现的技术就上台了
 服务发现技术就是服务裂变变更时，客户端可以快速地收到这些信息，从而调整自己的工作状态，这样无
 需进行重启就可以完成服务的扩容和缩容
 示例代码如下：
 class ServiceDiscovery(object): def register_service(self,name,addr): pass def get_services(self,name): pass def on_services_changed(self,name): pass   服务发现技术依赖于服务之间中间节点，它接受服务的注册、提供服务的查找、以及服务列表变更的实时</description>
    </item>
    
    <item>
      <title>RPC框架中的消息传递和协议</title>
      <link>https://sin-coder.github.io/post/rpcjiaohu/</link>
      <pubDate>Sun, 23 Feb 2020 14:22:56 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/rpcjiaohu/</guid>
      <description>RPC框架中的消息传递和协议  RPC是两个子系统之间进行的直接信息交互，它使用操作系统提供的套接字来作为消息的载体，以特定
 的消息格式来定义消息的内容和边界；客户端和服务端都是通过文件描述符的读写API来访问操作系统内核
中的网络模块为当前的套接字分配的发送（send buffer）和接收（recv buffer）缓存
 具体在这个过程中消息的内容是什么就需要我们深入RPC的协议进行学习了
 协议设计的整体思想  对于一串消息流，我们必须能确定消息边界，提取出单条消息的字节流片段，然后对这个片段按照一
 定的规则进行反序列化来生成相应的消息对象；消息的表示就是序列化后的消息字节流在直观上的表现
形式，文本的形式对人类比较友好，二进制的形式对计算机比较友好
 每个消息都有其内部字段的结构，结构构成了消息内部的逻辑规则，程序要按照结构的规则来决定字段
 序列化后的顺序
一、消息边界  RPC需要在一条TCP链接上进行多次消息传递，在连续的两条消息之间必须有明确的分隔符规则，以便
 接受端可以将消息分割开来；基于TCP连接之上的单条消息如果过大，就会被网络协议栈拆分成多个数据包
进行传送，而如果消息过小，协议栈就有可能将多个消息合成一个数据包进行发送。对于接收端来说，它看
到的只是一串串的字节数组，如果没有明确的消息边界规则，接收端就不知道这一串字节数组包含了多少消息
 比较常用的两种分割方式是特殊分隔符法和长度前缀法，分别如下图所示
  特殊符分割法就是在每条消息的末尾追加一个特殊的分隔符，并且保证消息中间的数据不能包含特殊分
 割符。比如最常见的分隔符是“ \r\n ”，当接受端遍历字节数组时发现了“\r\n”，就可以确定这个分隔符之前的
字节数组是一条完整的消息。在HTTP和Reids协议中就大量了使用“\r\n”分隔符，这种应用场景要求消息体的
内容是文本消息
 这种方法的优点是消息的可读性比较强，可以直接看到消息的文本内容，但是不适合传递二进制消息，
 因为二进制的字节数组中很容易出现“\r\n”分隔符的ASCII值，如果非要传递的话需要对二进制进行base64
编码转换成文本消息再进行传送
 消息发送端在每条消息的开头再增加4字节长度的整数值，标记消息体的长度，这样消息的接受者就会
 首先读取长度信息，然后再读取相应长度的字节数组就可以将一个完整的消息分离出来，常用于二进制消息
 这种方法的优缺点与特殊分割符法正好相反。长度前缀法可读性很差，但是适用于二进制协议，但是
 对于文本和内容都可以进行传递
 HTTP协议是上述两种法的混合型协议，因为HTTP的消息头采用的是纯文本外加“\r\n”分隔符，而消息
 体是通过消息头中的Content-length的值来决定长度的。HTTP协议可以传输文本协议，也可以传输二进制
数据，比如常见的音视频图像，所以被称为超文本传输协议
二、消息结构  每条消息都有着包含它的语义结构信息，有些消息协议的结构信息是显示的，还有些是隐式的。JSON
 消息的结构就可以直接通过它的内容体现出来，可读性非常高，但是它有太多的冗余信息，比如每个字符
串都使用双引号界定边界，键值对之间必须有冒号进行分割，对象之间必须使用大括号进行分割；而且连
续的多条json消息即使结构完全一样，仅是value值不同，也需要发送同样的key字符串
 消息的结构在同一条消息通道上是可以进行复用的，比如建立在链接的开始的ＲＰＣ的客户端和
 服务端之间先互相告知消息的结构，后续发送消息时只需要按照这个消息的模板发送消息就可以了，
接收端会自动将value值与相应位置的key关联起来，这样的模式可以节省比较多的流量</description>
    </item>
    
    <item>
      <title>RPC框架中客户端的实现</title>
      <link>https://sin-coder.github.io/post/distri_client/</link>
      <pubDate>Fri, 21 Feb 2020 16:08:30 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/distri_client/</guid>
      <description>RPC框架中客户端的实现  RPC客户端实现的难点在于客户端一般都不是单线程的，需要考虑在多线程的情况下如何流畅的使用客
 户端而不会出现并发的问题，交互过程的模型图如下：
 就如上面的模型图所示，在多线程的客户端中，客户端与数据库之间会维护一个连接池。当线程中的代码
 需要访问数据库时，先从数据库中获取一个连接，与数据库交互完成后再将这个连接归还给线程池。所以对
于业务线程来说，拿到的连接不会同时被其他的线程所共享，这样就可以避免并发的问题
 此外，服务器的性能往往随着并发连接数量的增加而下降，所以必须严格控制有效连接的数量；连接池的
 数量上限也是数据库的一层壁垒，下面将介绍一些客户端设计中的主要机制
一、安全锁  连接池是为多线程而设计的，每个线程都会访问线程池的对象，所以线程池需要使用锁来控制数据结构
 的安全。安全锁会使线程安全，但是也会导致性能受损。锁的临界区代码要尽量避免耗时的计算和I/O操作，
而且锁的粒度还要尽可能的细，但是代码实现不易
 增大锁的粒度可能在某些程度上使代码实现更为容易，因为连接都是用来进行相对缓慢的I/O操作的，锁
 是基于内存操作的，相比于I/O操作可以忽略不记
二、懒惰连接  连接池的连接多为懒惰连接，在需要的时候才会向数据库中申请。因为一个系统非常闲置，以前开辟了
 太多的连接是对资源的浪费；懒惰的连接池可以保证只会对单线程的程序开辟一个连接
 当然懒惰连接也有不好的地方，比如服务器的代码需要经过一个热身的过程，早来的请求需要额外付出
 一次建立连接的耗时代价、如果数据库连接参数不正确，需要在收到用户的请求进行显式数据访问时才能发现
三、健康检查和性能追踪  连接池中管理的连接可能或因为网络原因而损坏断开连接，连接池需要保持内部管理的连接是健康可用
 具体实现的机制如下：
 线程从连接池中申请连接返回之前，线程池需要对连接进行检查，确定连接是通常的
 线程将连接归还给连接池时，线程池对连接进行检查，确定连接没有被搞坏
 线程池定时对管理的连接进行检查
   如果检查发现连接有问题时，一般的做法两种：
  抛弃当前的连接连接池的连接数量减1，如果是在线程的borrow方法中，那就再重新去连接池申请一个
 修复当前连接，一般也就是执行重连
   此外，好的连接池还应该考虑到性能的可追踪性，当用户通过线程池分配的连接去访问数据库时，
 它的消息执行时间应该是可以被统计和追踪的。所以连接池往往还需要对原生的连接进行一定程度的
包装，在关键的函数代码调用前后增加性能统计代码，并对外提供监听端口，以便将统计信息传递给
外部的监控模块
四、超时策略  当业务线程繁忙的时，连接池内部的连接可能会出现不够用的场景，一个线程请求的borrow方法
 在长时间的等待后仍然等不到空闲的连接，这就是超时问题，主要有以下是3种解决方案：
 永不超时，等不到就一直接着等 一定的时间拿不到后，就像外部抛出超时异常，中断业务逻辑 如果发现连接池没有空闲连接，就去申请一个新的连接给调用方。当调用方归还连接的时候，连接池计算当前   缓存的连接数量，如果超过了最大的连接数，就将当前的连接销毁，否则就保存</description>
    </item>
    
    <item>
      <title>RPC的简介和使用</title>
      <link>https://sin-coder.github.io/post/intro_rpc/</link>
      <pubDate>Wed, 19 Feb 2020 16:08:30 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/intro_rpc/</guid>
      <description>RPC的简介和使用 一、RPC出现的背景  当单台服务器无法满足用户的请求，就需要多台服务器联合起来构成一个集群共同对外提供一个服务，这
 也是我们常说的分布式。同时业务服务或随着产品需求的增多愈发变得臃肿，架构上必须进行服务的拆分，一
个完整的大型服务会分成许多独立的小服务，每个小服务都会有独立的进程去管理对外的提供服务，这就是我
们常说微服务
 当用户请求到来的时候，需要将其分散到多个服务去各自的处理，然后又需要将这些子服务的结果汇总
 起来呈现给用户。那么服务之间如何进行交互？这就是RPC要解决的问题
二、什么是RPC?  RPC（Remote Procedure Call）即远程过程调用，是分布式系统中一中常见的通信方法。当然除了RPC
 外，常见的多系统数据交互方案还有分布式消息队列、HTTP请求调用、数据库和分布式缓存。如下图
 其中可以明显的看到RPC和HTTP调用都是没有经过中间件的，它是端到端系统的直接数据交互。关于
 RPC和HTTP的主要区别接下来会阐述
三、RPC的应用  RPC是分布式系统进行通信的基础，像Nignx/Redis/MuSQL/Dubbo/Spark/Tensorflow都是基于RPC技术
 发展起来的，似乎每一个分布式的软件或者系统实现上都有它的身影
 Nginx和后端服务之间的交互本质上属于RPC数据的交互   Hadoop的文件系统HDFS中NameNode和多个DataNode之间通过二进制的RPC协议通讯   TensorFlow Cluster的RPC的通讯框架使用了Google自研的gRPC框架  四、HTTP和RPC的区别与联系  HTTP1.0协议时，HTTP的调用还只是短链接调用，一个请求来回之后连接就会关闭。HTTP1.1在HTTP
 1.0协议的基础上进行了改进，引入了KeepAlive特性可以保持HTTP连接长时间不会断开，以便在同一个连接
上进行多次连续的请求，使的HTTP进一步地接近了RPC
 当HTTP进化到2.0版本时，Google开源了一个建立在HTTP2.0协议上的RPC框架:gRPC, 这时的HTTP
 和RPC之间已经没有明显的界限了。
 所以我们可以将HTTP看成一种特殊的RPC
 五、广义上的RPC  在分布式系统中我们经常使用的数据库、消息队列和缓存本质上也可以看成RPC技术的一种应用，比如
 像下面的分布式数据库模型图：
 可以看出子系统和数据库时间的交互也是通过RPC进行的，只不过这里是三个子系统之间进行的交互，
 而且这里的数据库是具备主从复制功能的数据库。一般情况为了提升系统的性能，都会使用这种主从读写
分离的数据库。一个业务系统将数据写往主库，主库再将数据同步到从库，然后另一个业务子系统又从库
里将数据取出来</description>
    </item>
    
  </channel>
</rss>