<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>分布式系统 on sin-coder</title>
    <link>https://sin-coder.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/</link>
    <description>Recent content in 分布式系统 on sin-coder</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Feb 2020 16:08:30 +0800</lastBuildDate>
    
	<atom:link href="https://sin-coder.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>RPC框架中客户端的实现</title>
      <link>https://sin-coder.github.io/post/distri_client/</link>
      <pubDate>Fri, 21 Feb 2020 16:08:30 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/distri_client/</guid>
      <description>RPC框架中客户端的实现  RPC客户端实现的难点在于客户端一般都不是单线程的，需要考虑在多线程的情况下如何流畅的使用客
 户端而不会出现并发的问题，交互过程的模型图如下：
 就如上面的模型图所示，在多线程的客户端中，客户端与数据库之间会维护一个连接池。当线程中的代码
 需要访问数据库时，先从数据库中获取一个连接，与数据库交互完成后再将这个连接归还给线程池。所以对
于业务线程来说，拿到的连接不会同时被其他的线程所共享，这样就可以避免并发的问题
 此外，服务器的性能往往随着并发连接数量的增加而下降，所以必须严格控制有效连接的数量；连接池的
 数量上限也是数据库的一层壁垒，下面将介绍一些客户端设计中的主要机制
一、安全锁  连接池是为多线程而设计的，每个线程都会访问线程池的对象，所以线程池需要使用锁来控制数据结构
 的安全。安全锁会使线程安全，但是也会导致性能受损。锁的临界区代码要尽量避免耗时的计算和I/O操作，
而且锁的粒度还要尽可能的细，但是代码实现不易
 增大锁的粒度可能在某些程度上使代码实现更为容易，因为连接都是用来进行相对缓慢的I/O操作的，锁
 是基于内存操作的，相比于I/O操作可以忽略不记
二、懒惰连接  连接池的连接多为懒惰连接，在需要的时候才会向数据库中申请。因为一个系统非常闲置，以前开辟了
 太多的连接是对资源的浪费；懒惰的连接池可以保证只会对单线程的程序开辟一个连接
 当然懒惰连接也有不好的地方，比如服务器的代码需要经过一个热身的过程，早来的请求需要额外付出
 一次建立连接的耗时代价、如果数据库连接参数不正确，需要在收到用户的请求进行显式数据访问时才能发现
三、健康检查和性能追踪  连接池中管理的连接可能或因为网络原因而损坏断开连接，连接池需要保持内部管理的连接是健康可用
 具体实现的机制如下：
 线程从连接池中申请连接返回之前，线程池需要对连接进行检查，确定连接是通常的
 线程将连接归还给连接池时，线程池对连接进行检查，确定连接没有被搞坏
 线程池定时对管理的连接进行检查
   如果检查发现连接有问题时，一般的做法两种：
  抛弃当前的连接连接池的连接数量减1，如果是在线程的borrow方法中，那就再重新去连接池申请一个
 修复当前连接，一般也就是执行重连
   此外，好的连接池还应该考虑到性能的可追踪性，当用户通过线程池分配的连接去访问数据库时，
 它的消息执行时间应该是可以被统计和追踪的。所以连接池往往还需要对原生的连接进行一定程度的
包装，在关键的函数代码调用前后增加性能统计代码，并对外提供监听端口，以便将统计信息传递给
外部的监控模块
四、超时策略  当业务线程繁忙的时，连接池内部的连接可能会出现不够用的场景，一个线程请求的borrow方法
 在长时间的等待后仍然等不到空闲的连接，这就是超时问题，主要有以下是3种解决方案：
 永不超时，等不到就一直接着等 一定的时间拿不到后，就像外部抛出超时异常，中断业务逻辑 如果发现连接池没有空闲连接，就去申请一个新的连接给调用方。当调用方归还连接的时候，连接池计算当前   缓存的连接数量，如果超过了最大的连接数，就将当前的连接销毁，否则就保存</description>
    </item>
    
    <item>
      <title>RPC的简介和使用</title>
      <link>https://sin-coder.github.io/post/intro_rpc/</link>
      <pubDate>Wed, 19 Feb 2020 16:08:30 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/intro_rpc/</guid>
      <description>RPC的简介和使用 一、RPC出现的背景  当单台服务器无法满足用户的请求，就需要多台服务器联合起来构成一个集群共同对外提供一个服务，这
 也是我们常说的分布式。同时业务服务或随着产品需求的增多愈发变得臃肿，架构上必须进行服务的拆分，一
个完整的大型服务会分成许多独立的小服务，每个小服务都会有独立的进程去管理对外的提供服务，这就是我
们常说微服务
 当用户请求到来的时候，需要将其分散到多个服务去各自的处理，然后又需要将这些子服务的结果汇总
 起来呈现给用户。那么服务之间如何进行交互？这就是RPC要解决的问题
二、什么是RPC?  RPC（Remote Procedure Call）即远程过程调用，是分布式系统中一中常见的通信方法。当然除了RPC
 外，常见的多系统数据交互方案还有分布式消息队列、HTTP请求调用、数据库和分布式缓存。如下图
 其中可以明显的看到RPC和HTTP调用都是没有经过中间件的，它是端到端系统的直接数据交互。关于
 RPC和HTTP的主要区别接下来会阐述
三、RPC的应用  RPC是分布式系统进行通信的基础，像Nignx/Redis/MuSQL/Dubbo/Spark/Tensorflow都是基于RPC技术
 发展起来的，似乎每一个分布式的软件或者系统实现上都有它的身影
 Nginx和后端服务之间的交互本质上属于RPC数据的交互   Hadoop的文件系统HDFS中NameNode和多个DataNode之间通过二进制的RPC协议通讯   TensorFlow Cluster的RPC的通讯框架使用了Google自研的gRPC框架  四、HTTP和RPC的区别与联系  HTTP1.0协议时，HTTP的调用还只是短链接调用，一个请求来回之后连接就会关闭。HTTP1.1在HTTP
 1.0协议的基础上进行了改进，引入了KeepAlive特性可以保持HTTP连接长时间不会断开，以便在同一个连接
上进行多次连续的请求，使的HTTP进一步地接近了RPC
 当HTTP进化到2.0版本时，Google开源了一个建立在HTTP2.0协议上的RPC框架:gRPC, 这时的HTTP
 和RPC之间已经没有明显的界限了。
 所以我们可以将HTTP看成一种特殊的RPC
 五、广义上的RPC  在分布式系统中我们经常使用的数据库、消息队列和缓存本质上也可以看成RPC技术的一种应用，比如
 像下面的分布式数据库模型图：
 可以看出子系统和数据库时间的交互也是通过RPC进行的，只不过这里是三个子系统之间进行的交互，
 而且这里的数据库是具备主从复制功能的数据库。一般情况为了提升系统的性能，都会使用这种主从读写
分离的数据库。一个业务系统将数据写往主库，主库再将数据同步到从库，然后另一个业务子系统又从库
里将数据取出来</description>
    </item>
    
    <item>
      <title>分布式一致性</title>
      <link>https://sin-coder.github.io/post/consistency/</link>
      <pubDate>Mon, 17 Feb 2020 08:04:41 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/consistency/</guid>
      <description>分布式一致性概述 一、什么是分布式一致性 1.CAP 理论  对于分布式一致性，最直观的理解就是分布式系统中的不同节点不能产生矛盾。比较著名的理论就是
 CAP Theorem，即在一个分布式系统中，不能同时满足以下三点：一致性（Consistency）、可用性
（Availability）、分区容错性（Partition Tolerance）
 一致性（C）：在分布式系统中的所有数据备份，同一时刻是否有同样的值
 可用性（A）：在集群中一部分节点故障后，集群整体能否响应客户端的读写请求
 分区容忍性（P）：大多数的分布式系统都分布在多个子网络，每个网络都叫做一个区，分区容错的意思即是
    区间通信可能失败；比如一个分布式系统有5个节点，有3个在美国，有两个在中国，这就是两个区
它们之间可能无法通信
   CAP原则的核心就是只能实现AP、CP、AC，不会存在CAP，从上图中也可以看到典型的一些数据库
 产品也只是满足了CAP的部分特性
2.一致性模型  （1）弱一致性（最终一致性）
关于弱一致性，通俗的解释就是当一个节点向数据库写入数据时，其他的节点可能无法立即读到该数据，
 但是它们最终一定会读到该数据，下面是一些典型的实例
 DNS （Domain Name System）
 Gossip（Cassandra 的通讯协议）
   （2）强一致性
对于分布式系统的容错性最关注的问题就是数据不能存储在单个的节点上，一般的解决方案就是state
 machine replication（状态机复制共识算法）,具体的实现算法有以下几种：
 同步
 Paxos
 Raft（multi-paxos）
 ZAB（multi-paxos）
  二、强一致性算法 1.主从同步  主从同步复制的工作过程如下，Master接受写请求、Master复制日志到slave、Master等待，直到
 所有从库返回；但是这样存在一个问题：一个节点失败，Master阻塞，导致整个集群不可用，保证了
一致性，但是可用性却大大降低了
 解决上述问题的方法：多数派的算法，每次写都保证写入大于N/2个节点，每次读保证从大于N/2个</description>
    </item>
    
    <item>
      <title>消息队列简介</title>
      <link>https://sin-coder.github.io/post/messagequ/</link>
      <pubDate>Tue, 28 Jan 2020 01:22:22 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/messagequ/</guid>
      <description>消息队列简介 一、消息队列简介 1.概述  消息是指在应用间传送数据，消息可以只包含文本字符串、或者包含嵌入式对象。
消息队列是一种应用程序对应用程序的通信方法。它是是生产者-消费者模型的一个典型的代表，一端往消息
 队列中不断地写入消息，而另一端则可以读取队列中的消息。这样发布者和接受者都不知道对方的存在。
 消息队列也可以简单理解为：把要传输的数据放在队列中
 2.消息获取模式  消费者获取消息时有两种模式，点对点模式和发布订阅模式
 （1）点对点模式  点对点模型通常是一个基于拉取或者轮询的消息传递模型，这种模型从队列中请求消息，而不是将消息推送
 到客户端。这种模式的特点是一对一，发送到队列的消息被一个且只有一个接受者接收处理，即使有多
个消息监听者也是如此，消息被收到后即可清除
 点对点模式的优点是队列发送数据和客户端接收数据的速度是相匹配的，缺点是客户端需要实时监控队列中
 是否有消息存在
（2）发布/订阅模式  发布订阅模型是一个基于推送的消息传送模型，该种模型下订阅者有临时订阅者和持久订阅者之分，临时订
 阅者只在主动监听主题时才接收消息；而持久订阅者则监听主题的所有消息，即使当前订阅者不可用，
处于离线状态。这种模型的特点是一对多，数据生产后，推送给所有的订阅者
 发布/订阅模式的优点是客户端不需要实时监控队列中是否有消息存在，缺点是队列发送数据的速度无法和多
 个客户端接收数据的速度是相匹配
二、消息队列作用  解耦：客户端与客户端之间或者客户端和服务器 之间不需要直接连接，而是通过中间件来进行连接。而且允许你    独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束
  冗余：消息队列可以对数据进行持久化（本地备份）直到它们已经被处理，这样就规避了数据的丢失。许多消息   队列均采用“插入-获取-删除”的范式，即在把一个消息从队列中删除之前，需要你的系统明确的指出该消息已
经被处理完毕
  峰值处理：可以组建集群，进而增大消息入队和处理的频率。在访问量剧增的情况下，应用仍然需要继续发挥作   用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的
浪费。消息队列基于它的可扩展性使其本身可以顶住突发的访问压力，而不会因为突发的超负荷的请求而使
系统完全崩溃
  数据可恢复：当系统的一部分组件失效时，不会影响到整个的系统 。消息队列降低了进程间的耦合度，即使一个   处理消息的进程挂掉，加入队列中的消息仍可在系统恢复后被处理
  顺序保证：消息队列本来就是排好序的，并且也能够保证数据按照特定的顺序来进行处理
 缓冲：消息队列可以控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况</description>
    </item>
    
    <item>
      <title>Git&amp;Github 学习笔记</title>
      <link>https://sin-coder.github.io/post/git/</link>
      <pubDate>Mon, 27 Jan 2020 00:52:28 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/git/</guid>
      <description>一、版本控制 1.版本控制工具的功能  协同修改：多人互不影响地修改服务器端的同一个文件
 数据备份：不仅要保存文件的当前状态，还能够保存每一个提交过的历史状态
 版本管理：在保存每一个版本的文件信息时，能够做到不保存重复的数据，节省存储空间，提高运行效率;
     SVN采取的是增量式管理的方式，Git采取了文件系统快照的方式
    权限控制：对团队中参与开发的人员进行权限控制，Git还可以对团队外开发者贡献的代码进行审核
 历史记录：查看修改人、修改时间、修改内容、日志信息；将本地文件恢复至某一个历史状态
 分支管理：允许开发团队在工作过程中多条生产线同时推进任务，提高效率
  2.常见版本控制工具  （1）集中式版本控制工具：CVS、SVN、VSS等
 集中式的版本控制中每个开发者是一个客户端，文件和版本信息存储在服务端，开发者们都直接与
 服务器进行交互，集中式的版本控制具有单点故障的问题
（2）分布式版本控制工具：Git、Mercurial、Bazaar等
 分布式版本控制相比于集中式最大的优点就是能够避免单点故障的问题
  二、Git 简介 1.Git的发展历史  Git是一个免费、开源的分布式版本控制工具。在2005年，由Linus基于C语言开发完成，开发的初衷是
 管理Linux社区中提交的代码, 而这位Linus正是是开发Linux系统内核的大神，它的个人语录也是我的座右铭
&amp;quot;Talk is cheap, Show me the Code&amp;quot;，少废话我只看代码。
2.Git的特性简介  从Git的图标中就可以看到分支是其最引以为傲的特点，实际上Git的优点还有很多
  大部分操作在本地完成版本控制，不需要联网
 对数据进行完整性保证，基于Hash算法
 尽可能添加数据而不是删除或者修改数据
 与Linux命令全面兼容，这个当然了，都是由Linus开发的
    3.Git 的结构  Git的本地结构图</description>
    </item>
    
    <item>
      <title>分布式系统学习笔记</title>
      <link>https://sin-coder.github.io/post/distri/</link>
      <pubDate>Mon, 27 Jan 2020 00:44:13 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/distri/</guid>
      <description>一、分布式系统概述 1.什么是分布式系统？ ​ 分布式系统主要由网络、分布式存储与分布式计算等部分构成的，分布式存储侧重于数据的读写存取及一致性等方面，而分布式计算则侧重于资源、任务的编排和调度
2.分布式系统的特点 ​ 没有强制性的中心控制、次级单位具有自治的特质、次级单位之间彼此高度链接、点对点之间的影响通过网络形成了非线性的因果关系
3.传统架构面临的难题: 系统的扩展 ​ 高并发的访问要求我们的后端系统架构弹性且可扩展
​ 三维扩展：
​ X轴扩展：水平复制，即在负载均衡服务器后增加多个Web服务器，
​ Y轴扩展：对数据库的扩展，即进行分库分表，分库是将关系紧密的表放在一台数据库服务器上，分表是因为一张表的数据太多，需要将一张表的数据通过hash放在不同的数据库服务器上
​ Z轴扩展：业务方向的扩展，才能将巨型应用分解为一组不同的服务，将应用进一步分解为微服务
​ 4.CAP定理
​ 在分布式系统中，系统的一致性(Consistency)、可用性（Availability）、分区容忍性(Partion tolerance)。这三者不能同时保证，由于网络通信的不确定性，分区的容忍性是必须要保证的，而且互联网应用比企业级应用更加偏向于保持可用性，通常用最终一致性代替传统事务的ACID强一致性
​
二、分布式计算 1.概述 ​ 分布式计算核心的思路就是系统架构无单点，让整个系统可以扩展。分布式计算环境下的节点分为有状态存储节点和无状态存储节点。
​ 无状态存储节点，不存储数据，请求分发可以采取很简单的随机算法或者是轮询的算法就可以了，如果需要增加机器，则只需要把对应的运算代码部署到一些机器上然后启动起来，引导流量到那些机器即可实现动态的扩展了。简单来说就是某台机器承担了某种角色后，能够快速的广播给需要这个角色提供服务的机器。
​ 而针对有状态节点，扩容难度较大，因为每台Server中均有数据，所以请求分发的算法不能够随机或者轮询，一般来说常见算法就是哈希或者使用Tree来做一层映射，增加机器时需要经历一个复杂的数据迁移过程------》自动化扩容和迁移的工具
2.数据处理的发展过程
GFS-------------》HDFS
BigTable--------》HBase
​ MapReduce----》MapReduce
​ （Hadoop技术栈）
MapReduce(离线处理)-----》Spark(高性能批处理技术)------》Storm(流处理)----》Flink
3.批处理（Batch Processing）与流处理（Stream Processing） 主要区别：每一条数据在到达时是被处理的（流处理），还是作为一组新数据的一部分稍后进行处理（批处理）
批处理：在批处理中新到达的数据元素被收集到一个组中，整个组在未来的时间内进行处理。至于何时处理每个组可以选择多种方式来确定，可以基于预定的时间间隔（如每隔5分钟）、或者在某些触发的条件下（只要包含5个元素/拥有超过1MB的数据）。传统的数据仓库和Hadoop就是专注于批处理的。批处理示意图如下：
缺点：具有延迟性、新数据的到达与该数据的处理之间的延迟将取决于直到下一批处理窗口的时间
流处理：流处理设计的目的是为了在数据到达时对其进行响应，这就要求它们实现一个由事件驱动的体系架构，也可以说是在系统的内部工作流在接收到数据后立即连续监视新数据和调度处理。
应用：Flink、Beam等都支持“流式处理优先，将批处理视为流式处理的特殊情况”，但是流式处理器的出现并没有让批处
​ 理器变得过时。因为纯流式处理系统在批处理工作负载时其实是非常慢的。
​ Apache Beam: 这样统一的API通常会根据数据是持续的（无界）、还是固定的（有界）将工作负载委托给不同的
​ 运行机制
​ Flink: 提供的流式API，可以处理有界或者无界的场景，同时任然提供了单独的DataSet API用于批处理
​
三、分布式调度 1.概述
经典资源调度器（Yarn）-----》数据调度（Data Placement）、资源任务调度（Resource Management）、计算调度（Application Manager）、本地微（自治）调度
2.资源调度</description>
    </item>
    
    <item>
      <title>同步/异步、阻塞/非阻塞辨析</title>
      <link>https://sin-coder.github.io/post/syn/</link>
      <pubDate>Sun, 26 Jan 2020 21:35:45 +0800</pubDate>
      
      <guid>https://sin-coder.github.io/post/syn/</guid>
      <description>关键词：同步、异步、阻塞、非阻塞 相关概念：网络编程、进程与线程、I/O模型 一、问题背景  同步和异步，以及阻塞和非阻塞都是网络编程中经常遇到的概念，单看文字上的解释确实有些晦涩
 难懂。接下来我们将从一个通俗的例子出发阐述它们的区别与联系
二、一个简单的例子  隔壁老王爱好茶艺，每天都会煮开水来泡茶
 场景一：老王将水壶放在火上，坐在旁边等待水开 （同步阻塞）
 但是这样很耽搁时间，又不自由，效率很低，老王想换种方法
 场景二：老王将水壶放在火上，自已去隔壁了，每隔3分钟来看下水开没有 （同步非阻塞）
 但是这样依旧很麻烦，老王就买了一个自动报警的水壶
 场景三： 老王用新买的水壶进行烧水，坐在旁边等待水开 （异步阻塞）
 老王便想没有必要在水壶旁边坐着啊
 场景四： 老王新买的水壶放在火上，自己去隔壁了，等着报警再回来 （异步非阻塞）
 这种方式是最让老王省心的
 小结： 同步和异步关注的焦点在于我们是否需要不断地去看水壶是否开了，同步时，需要老王不断
地去轮询水壶是否开了，效率是比较低下的。而异步时，水壶告警提醒老王它开了
 阻塞和非阻塞 关注的焦点在于老王是否需要坐在水壶旁边等待，在水壶旁边等待老王就是阻
 塞的，去做其他事的老王就是非阻塞的
 这个例子可以帮助我们初步地理解同步异步、阻塞和非阻塞之间的联系和区别，但是如果详细
 的“追究”起来，还有许多未解释的细节
三、理论阐述 1.同步与异步  同步和异步（syn &amp;amp; asyn），描述的是在单线程中一次方法调用后，执行者是否具备主动通知
 的功能。同步时调用者会等到方法调用返回后才能继续后面的行为，异步时调用者不需要等到方法返回，
方法执行完毕后会主动通知调用者
2.阻塞和非阻塞  阻塞和非阻塞关注是调用者是否可以执行多个任务，描述的是调用者的多个线程是否可以同时执
 行。阻塞时，多个线程不能同时进行；非阻塞时，多个线程可以同时进行
3.二者的区别与联系  同步和阻塞完全是在单线程和多线程这两个维度上的概念，它们之间并没有强制的联系。但是从
 实际的意义来看确实有一定的绑定关系，比如对于单线程来说，不管是同步还是异步，肯定是阻塞的，非
阻塞只有多线程而且异步的时候才能发挥作用。
 回来继续看烧水的例子，老王在烧水的同时去隔壁，也即在烧水这个线程之中，又开启了去隔壁
 这个线程，所以使用异步非阻塞才更加有意义</description>
    </item>
    
  </channel>
</rss>